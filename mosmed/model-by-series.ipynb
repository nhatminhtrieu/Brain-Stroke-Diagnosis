{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5557228,"sourceId":9192599,"sourceType":"datasetVersion"},{"datasetId":5633589,"sourceId":9303618,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":15.8527,"end_time":"2024-09-12T08:06:44.513889","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-12T08:06:28.661189","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Library","metadata":{"papermill":{"duration":0.005824,"end_time":"2024-09-12T08:06:31.605274","exception":false,"start_time":"2024-09-12T08:06:31.599450","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport glob\n\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\n\nimport pandas as pd\nimport pydicom\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom skimage.transform import resize\nfrom typing import Dict, Tuple, List","metadata":{"papermill":{"duration":4.353893,"end_time":"2024-09-12T08:06:35.964394","exception":false,"start_time":"2024-09-12T08:06:31.610501","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T09:20:45.551066Z","iopub.execute_input":"2024-09-12T09:20:45.551359Z","iopub.status.idle":"2024-09-12T09:20:51.959778Z","shell.execute_reply.started":"2024-09-12T09:20:45.551327Z","shell.execute_reply":"2024-09-12T09:20:51.958801Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{"papermill":{"duration":0.004956,"end_time":"2024-09-12T08:06:35.974979","exception":false,"start_time":"2024-09-12T08:06:35.970023","status":"completed"},"tags":[]}},{"cell_type":"code","source":"DATASET_DIR = '/kaggle/input/mosmeddata-ct-hemorrhage-type-viii/MosMedData-CT-HEMORRHAGE-type VIII/' \nIMG_SIZE = (512, 512)\nBATCH_SIZE = 8\nMAX_IMAGES_PER_SERIES = 512\nSTART_IDX = 0\nNUM_CLASSES = 2  # 0: normal, 1: hemorrhage\nNUM_CHANNELS = 1  # Assuming grayscale images","metadata":{"papermill":{"duration":0.01543,"end_time":"2024-09-12T08:06:35.995571","exception":false,"start_time":"2024-09-12T08:06:35.980141","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T09:20:51.961649Z","iopub.execute_input":"2024-09-12T09:20:51.962432Z","iopub.status.idle":"2024-09-12T09:20:51.967363Z","shell.execute_reply.started":"2024-09-12T09:20:51.962389Z","shell.execute_reply":"2024-09-12T09:20:51.966246Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"papermill":{"duration":0.014918,"end_time":"2024-09-12T08:06:36.015675","exception":false,"start_time":"2024-09-12T08:06:36.000757","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T09:20:51.968847Z","iopub.execute_input":"2024-09-12T09:20:51.969539Z","iopub.status.idle":"2024-09-12T09:20:52.030293Z","shell.execute_reply.started":"2024-09-12T09:20:51.969499Z","shell.execute_reply":"2024-09-12T09:20:52.029458Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Read Image","metadata":{"papermill":{"duration":0.004712,"end_time":"2024-09-12T08:06:36.025663","exception":false,"start_time":"2024-09-12T08:06:36.020951","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def find_clinical_sheet(excel_file, keywords):\n    \"\"\"\n    Finds the sheet containing clinical data in an Excel file.\n\n    Parameters:\n    excel_file (pd.ExcelFile): The Excel file object.\n    keywords (list): List of keywords to identify the clinical sheet.\n\n    Returns:\n    str: The name of the sheet containing clinical data.\n\n    Raises:\n    ValueError: If no sheet with clinical data is found.\n    \"\"\"\n    for sheet in excel_file.sheet_names:\n        if any(keyword in sheet.lower() for keyword in keywords):\n            return sheet\n    \n    raise ValueError('No clinical sheet found in the Excel file.')\n\ndef read_clinical_data(file_path):\n    \"\"\"\n    Reads clinical data from an Excel file.\n\n    Parameters:\n    file_path (str): The path to the Excel file.\n\n    Returns:\n    pandas.DataFrame: A DataFrame containing the clinical data.\n\n    Raises:\n    ValueError: If no sheet with clinical data is found in the Excel file.\n    \"\"\"\n    clinical_keywords = ['clinical', 'клинические']\n    \n    try:\n        xls = pd.ExcelFile(file_path)\n        clinical_sheet = find_clinical_sheet(xls, clinical_keywords)\n        return pd.read_excel(xls, clinical_sheet)\n    except ValueError as e:\n        raise ValueError(f\"Error reading clinical data: {str(e)}\")","metadata":{"papermill":{"duration":0.018494,"end_time":"2024-09-12T08:06:36.049128","exception":false,"start_time":"2024-09-12T08:06:36.030634","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T09:20:52.032620Z","iopub.execute_input":"2024-09-12T09:20:52.033060Z","iopub.status.idle":"2024-09-12T09:20:52.041566Z","shell.execute_reply.started":"2024-09-12T09:20:52.033005Z","shell.execute_reply":"2024-09-12T09:20:52.040751Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def preprocess_images(dicom_images, img_size=IMG_SIZE):\n    \"\"\"\n    Preprocesses DICOM images for machine learning model input.\n\n    Parameters:\n    dicom_images (dict): A dictionary with a single key, where the value is a list of pydicom.dataset.FileDataset objects.\n    img_size (tuple): Target image size (height, width). Default is (512, 512).\n\n    Returns:\n    numpy.ndarray: 4D array of preprocessed images (n_images, height, width, 3).\n    \"\"\"\n    # Get the list of DICOM images from the dictionary\n    images_list = list(dicom_images.values())[0]\n    \n    # Apply preprocess_single_image to each image in the list\n    return np.array([preprocess_single_image(img, img_size) for img in images_list])\n\ndef preprocess_single_image(dicom_image, img_size):\n    \"\"\"\n    Preprocesses a single DICOM image.\n\n    Parameters:\n    dicom_image (pydicom.dataset.FileDataset): DICOM image object.\n    img_size (tuple): Target image size (height, width).\n\n    Returns:\n    numpy.ndarray: Preprocessed image as a 3D array (height, width, 3).\n    \"\"\"\n    image_array = dicom_image.pixel_array\n    normalized_image = normalize_image(image_array)\n    resized_image = resize_image(normalized_image, img_size)\n    return convert_to_rgb(resized_image)\n\ndef normalize_image(image):\n    \"\"\"\n    Normalizes image pixel values to [0, 1] range.\n\n    Parameters:\n    image (numpy.ndarray): Input image array.\n\n    Returns:\n    numpy.ndarray: Normalized image array.\n    \"\"\"\n    max_value = np.max(image)\n    return image / max_value if max_value > 0 else np.zeros_like(image)\n\ndef resize_image(image, target_size):\n    \"\"\"\n    Resizes image to target size using anti-aliasing.\n\n    Parameters:\n    image (numpy.ndarray): Input image array.\n    target_size (tuple): Target image size (height, width).\n\n    Returns:\n    numpy.ndarray: Resized image array.\n    \"\"\"\n    return resize(image, target_size, anti_aliasing=True)\n\ndef convert_to_rgb(image):\n    \"\"\"\n    Converts grayscale image to RGB if necessary.\n\n    Parameters:\n    image (numpy.ndarray): Input image array.\n\n    Returns:\n    numpy.ndarray: RGB image array.\n    \"\"\"\n    if len(image.shape) == 2:\n        return np.stack((image,) * 3, axis=-1)\n    return image","metadata":{"papermill":{"duration":0.020344,"end_time":"2024-09-12T08:06:36.074556","exception":false,"start_time":"2024-09-12T08:06:36.054212","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T09:20:52.042913Z","iopub.execute_input":"2024-09-12T09:20:52.043235Z","iopub.status.idle":"2024-09-12T09:20:52.052593Z","shell.execute_reply.started":"2024-09-12T09:20:52.043187Z","shell.execute_reply":"2024-09-12T09:20:52.051742Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class BaseDatasetGenerator(Dataset):\n    def __init__(self, dataset_dir: str, start_idx: int = 0, batch_size: int = BATCH_SIZE, max_images_per_series: int = MAX_IMAGES_PER_SERIES):\n        self.dataset_dir = dataset_dir\n        self.start_idx = start_idx\n        self.batch_size = batch_size\n        self.max_images_per_series = max_images_per_series\n        self.studies_folders = self._get_studies_folders()\n        self.clinical_data = self._load_clinical_data()\n        self.clinical_data = self._filter_clinical_data()\n        self.study_uids = self._get_study_uids()\n        self.current_index = self.start_idx\n\n    def _get_studies_folders(self) -> List[str]:\n        return [f for f in os.listdir(self.dataset_dir) if os.path.isdir(os.path.join(self.dataset_dir, f))]\n\n    def _load_clinical_data(self) -> pd.DataFrame:\n        all_clinical_data = []\n        for folder in self.studies_folders:\n            folder_path = os.path.join(self.dataset_dir, folder, folder)\n            excel_files = glob.glob(os.path.join(folder_path, '*.xlsx'))\n            \n            if not excel_files:\n                print(f\"Warning: No Excel file found in {folder_path}\")\n                continue\n            \n            if len(excel_files) > 1:\n                print(f\"Warning: Multiple Excel files found in {folder_path}. Using the first one.\")\n            \n            excel_path = excel_files[0]\n            df = pd.read_excel(excel_path)\n            df['folder'] = folder\n            all_clinical_data.append(df)\n        \n        if not all_clinical_data:\n            raise FileNotFoundError(f\"No Excel files found in any of the studies folders in {self.dataset_dir}\")\n        \n        return pd.concat(all_clinical_data, ignore_index=True)\n\n    def _filter_clinical_data(self) -> pd.DataFrame:\n        hemorrhage_columns = [\n            'epidural hemorrhage', 'subarachnoid hemorrhage', \n            'subdural hemorrhage', 'intracerebral hemorrhage', \n            'multiple hemorrhages', 'skull fracture'\n        ]\n\n        filtered_data = self.clinical_data[self.clinical_data['Comment'] != \"Study without report\"]\n\n        for column in hemorrhage_columns:\n            filtered_data = filtered_data[filtered_data[column].isin([0.0, 1.0])]\n\n        # Add ICH column\n        filtered_data['ICH'] = filtered_data[hemorrhage_columns].max(axis=1)\n\n        return filtered_data\n\n    def _get_study_uids(self) -> np.ndarray:\n        return self.clinical_data['study_uid'].unique()\n\n    def __len__(self) -> int:\n        return len(self.study_uids)\n\n    def __getitem__(self, idx: int) -> Tuple[np.ndarray, Dict]:\n        study_uid = self.study_uids[idx]\n        dicom_series = self._load_dicom_images(study_uid)\n        labels = self._get_labels(study_uid)\n        processed_images = self.preprocess_images(dicom_series, img_size=IMG_SIZE)\n        return processed_images, labels\n\n    def _load_dicom_images(self, study_uid: str) -> Dict[str, List[pydicom.dataset.FileDataset]]:\n        dicom_series = {}\n        study_folder = self.clinical_data[self.clinical_data['study_uid'] == study_uid]['folder'].iloc[0]\n        study_path = os.path.join(self.dataset_dir, study_folder, study_folder, study_uid)\n        \n        for root, _, files in os.walk(study_path):\n            for file in files:\n                if file.endswith('.dcm'):\n                    file_path = os.path.join(root, file)\n                    dicom_image = pydicom.dcmread(file_path, force=True)\n                    series_uid = dicom_image.SeriesInstanceUID\n                    if series_uid not in dicom_series:\n                        dicom_series[series_uid] = []\n                    dicom_series[series_uid].append(dicom_image)\n        return dicom_series\n\n    def _get_labels(self, study_uid: str) -> Dict:\n        study_clinical_data = self.clinical_data[self.clinical_data['study_uid'] == study_uid]\n        return study_clinical_data.iloc[0].to_dict() if not study_clinical_data.empty else None\n\n    @staticmethod\n    def preprocess_images(dicom_series: Dict[str, List[pydicom.dataset.FileDataset]], img_size: Tuple[int, int]) -> np.ndarray:\n        processed_images = []\n        for series in dicom_series.values():\n            for dicom_image in series[:MAX_IMAGES_PER_SERIES]:\n                pixel_array = dicom_image.pixel_array\n                resized_image = resize(pixel_array, img_size, anti_aliasing=True)\n                processed_images.append(resized_image)\n        \n        # Pad if necessary\n        if len(processed_images) < MAX_IMAGES_PER_SERIES:\n            pad_width = ((0, MAX_IMAGES_PER_SERIES - len(processed_images)), (0, 0), (0, 0))\n            processed_images = np.pad(processed_images, pad_width, mode='constant', constant_values=0)\n        \n        return np.array(processed_images)\n\nclass TrainDatasetGenerator(BaseDatasetGenerator):\n    def __init__(self, dataset_dir: str, studies_folder: str, \n                 start_idx: int = 0, batch_size: int = BATCH_SIZE, max_images_per_series: int = MAX_IMAGES_PER_SERIES):\n        super().__init__(dataset_dir, start_idx, batch_size, max_images_per_series)\n        self.studies_folder = studies_folder\n        self.study_uids = self._get_study_uids_from_folder()\n\n    def _get_study_uids_from_folder(self) -> np.ndarray:\n        folder_path = os.path.join(self.dataset_dir, self.studies_folder, self.studies_folder)\n        return np.array([d for d in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, d))])\n\nclass TestDatasetGenerator(BaseDatasetGenerator):\n    def __init__(self, dataset_dir: str, \n                 start_idx: int = 0, batch_size: int = BATCH_SIZE, max_images_per_series: int = MAX_IMAGES_PER_SERIES):\n        super().__init__(dataset_dir, start_idx, batch_size, max_images_per_series)\n        # You can add test-specific functionality here if needed\n","metadata":{"papermill":{"duration":0.039359,"end_time":"2024-09-12T08:06:36.119109","exception":false,"start_time":"2024-09-12T08:06:36.079750","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T09:20:52.054077Z","iopub.execute_input":"2024-09-12T09:20:52.054333Z","iopub.status.idle":"2024-09-12T09:20:52.081061Z","shell.execute_reply.started":"2024-09-12T09:20:52.054305Z","shell.execute_reply":"2024-09-12T09:20:52.080376Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class ResNet503D(nn.Module):\n    def __init__(self, num_classes=NUM_CLASSES):\n        super(ResNet503D, self).__init__()\n        resnet = models.resnet50(pretrained=True)\n        \n        self.conv1 = nn.Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n        self.conv1.weight.data = resnet.conv1.weight.data.unsqueeze(2).repeat(1, 1, 7, 1, 1) / 7\n        \n        self.bn1 = nn.BatchNorm3d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n        \n        self.layer1 = self._make_layer_3d(resnet.layer1, 64, 64, 3)\n        self.layer2 = self._make_layer_3d(resnet.layer2, 128, 128, 4)\n        self.layer3 = self._make_layer_3d(resnet.layer3, 256, 256, 6)\n        self.layer4 = self._make_layer_3d(resnet.layer4, 512, 512, 3)\n        \n        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n        self.fc = nn.Linear(512 * 4, num_classes)\n\n    def _make_layer_3d(self, layer_2d, inplanes, planes, blocks):\n        layers = []\n        for i in range(blocks):\n            layers.append(nn.Conv3d(inplanes, planes, kernel_size=3, stride=1, padding=1, bias=False))\n            layers.append(nn.BatchNorm3d(planes))\n            layers.append(nn.ReLU(inplace=True))\n            inplanes = planes\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-09-12T09:20:52.082220Z","iopub.execute_input":"2024-09-12T09:20:52.082634Z","iopub.status.idle":"2024-09-12T09:20:52.095589Z","shell.execute_reply.started":"2024-09-12T09:20:52.082594Z","shell.execute_reply":"2024-09-12T09:20:52.094764Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n        for inputs, labels in train_loader:\n            inputs = inputs.unsqueeze(1).float().to(device)  # Add channel dimension and convert to float\n            labels = torch.tensor([label['ICH'] for label in labels]).long().to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n        epoch_loss = running_loss / len(train_loader)\n        epoch_acc = 100. * correct / total\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-09-12T09:20:52.096573Z","iopub.execute_input":"2024-09-12T09:20:52.096862Z","iopub.status.idle":"2024-09-12T09:20:52.107612Z","shell.execute_reply.started":"2024-09-12T09:20:52.096832Z","shell.execute_reply":"2024-09-12T09:20:52.106754Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def plot_dicom_images(images, labels, num_images=4):\n    fig, axes = plt.subplots(1, num_images, figsize=(20, 5))\n    for i, ax in enumerate(axes):\n        if i < len(images):\n            ax.imshow(images[i], cmap='gray')\n            ax.set_title(f\"Image {i+1}\")\n            # ax.axis('off')\n        else:\n            ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n    \n    print(\"Labels:\")\n    for key, value in labels.items():\n        print(f\"{key}: {value}\")\n","metadata":{"papermill":{"duration":0.018272,"end_time":"2024-09-12T08:06:37.525244","exception":false,"start_time":"2024-09-12T08:06:37.506972","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T09:20:52.108770Z","iopub.execute_input":"2024-09-12T09:20:52.109576Z","iopub.status.idle":"2024-09-12T09:20:52.119253Z","shell.execute_reply.started":"2024-09-12T09:20:52.109532Z","shell.execute_reply":"2024-09-12T09:20:52.118396Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    studies_folder = '400_500_studies'  # Specify the folder for training data\n    train_dataset = TrainDatasetGenerator(dataset_dir=DATASET_DIR, studies_folder=studies_folder)\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n\n    test_dataset = TestDatasetGenerator(dataset_dir=DATASET_DIR)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n    model = ResNet503D(num_classes=NUM_CLASSES)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n    train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n\n    # After training, you can evaluate the model on the test set\n    model.eval()\n    test_correct = 0\n    test_total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs = inputs.unsqueeze(1).float().to(device)\n            labels = torch.tensor([label['ICH'] for label in labels]).long().to(device)\n            outputs = model(inputs)\n            _, predicted = outputs.max(1)\n            test_total += labels.size(0)\n            test_correct += predicted.eq(labels).sum().item()\n\n    test_accuracy = 100. * test_correct / test_total\n    print(f'Test Accuracy: {test_accuracy:.2f}%')","metadata":{"papermill":{"duration":5.846135,"end_time":"2024-09-12T08:06:43.376786","exception":false,"start_time":"2024-09-12T08:06:37.530651","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T09:20:52.121976Z","iopub.execute_input":"2024-09-12T09:20:52.122320Z","iopub.status.idle":"2024-09-12T09:21:25.849134Z","shell.execute_reply.started":"2024-09-12T09:20:52.122281Z","shell.execute_reply":"2024-09-12T09:21:25.847823Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 188MB/s] \n/opt/conda/lib/python3.10/site-packages/pydicom/valuerep.py:443: UserWarning: Invalid value for VR UI: '1.2.643.5.1.13.13.12.2.77.8252.08050700130502080901140206001012'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n  warnings.warn(msg)\n/opt/conda/lib/python3.10/site-packages/pydicom/valuerep.py:443: UserWarning: Invalid value for VR UI: '1.2.643.5.1.13.13.12.2.77.8252.05010009081314011201101002150907'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n  warnings.warn(msg)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# After training, you can evaluate the model on the test set\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n","Cell \u001b[0;32mIn[8], line 11\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     12\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Add channel dimension and convert to float\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([label[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mICH\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels])\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[6], line 64\u001b[0m, in \u001b[0;36mBaseDatasetGenerator.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Dict]:\n\u001b[1;32m     63\u001b[0m     study_uid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy_uids[idx]\n\u001b[0;32m---> 64\u001b[0m     dicom_series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_dicom_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_uid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_labels(study_uid)\n\u001b[1;32m     66\u001b[0m     processed_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_images(dicom_series, img_size\u001b[38;5;241m=\u001b[39mIMG_SIZE)\n","Cell \u001b[0;32mIn[6], line 71\u001b[0m, in \u001b[0;36mBaseDatasetGenerator._load_dicom_images\u001b[0;34m(self, study_uid)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_dicom_images\u001b[39m(\u001b[38;5;28mself\u001b[39m, study_uid: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, List[pydicom\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mFileDataset]]:\n\u001b[1;32m     70\u001b[0m     dicom_series \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 71\u001b[0m     study_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclinical_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclinical_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstudy_uid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstudy_uid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfolder\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     72\u001b[0m     study_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_dir, study_folder, study_folder, study_uid)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m root, _, files \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(study_path):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"],"ename":"IndexError","evalue":"single positional indexer is out-of-bounds","output_type":"error"}]}]}