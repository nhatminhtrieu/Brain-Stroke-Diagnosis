{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9192599,"sourceType":"datasetVersion","datasetId":5557228},{"sourceId":9303618,"sourceType":"datasetVersion","datasetId":5633589}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":15.8527,"end_time":"2024-09-12T08:06:44.513889","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-12T08:06:28.661189","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Library","metadata":{"papermill":{"duration":0.005824,"end_time":"2024-09-12T08:06:31.605274","exception":false,"start_time":"2024-09-12T08:06:31.599450","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport glob\n\nimport torch\n\nimport pandas as pd\nimport pydicom\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom skimage.transform import resize\nfrom typing import Dict, Tuple, List","metadata":{"papermill":{"duration":4.353893,"end_time":"2024-09-12T08:06:35.964394","exception":false,"start_time":"2024-09-12T08:06:31.610501","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T08:42:57.138511Z","iopub.execute_input":"2024-09-12T08:42:57.139113Z","iopub.status.idle":"2024-09-12T08:42:57.147058Z","shell.execute_reply.started":"2024-09-12T08:42:57.138974Z","shell.execute_reply":"2024-09-12T08:42:57.145311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{"papermill":{"duration":0.004956,"end_time":"2024-09-12T08:06:35.974979","exception":false,"start_time":"2024-09-12T08:06:35.970023","status":"completed"},"tags":[]}},{"cell_type":"code","source":"DATASET_DIR = '/kaggle/input/mosmeddata-ct-hemorrhage-type-viii/MosMedData-CT-HEMORRHAGE-type VIII/' \nIMG_SIZE = (512, 512)\nBATCH_SIZE = 16\nMAX_IMAGES_PER_SERIES = 512\nSTART_IDX = 0","metadata":{"papermill":{"duration":0.01543,"end_time":"2024-09-12T08:06:35.995571","exception":false,"start_time":"2024-09-12T08:06:35.980141","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T08:42:57.149963Z","iopub.execute_input":"2024-09-12T08:42:57.150620Z","iopub.status.idle":"2024-09-12T08:42:57.165054Z","shell.execute_reply.started":"2024-09-12T08:42:57.150560Z","shell.execute_reply":"2024-09-12T08:42:57.163720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"papermill":{"duration":0.014918,"end_time":"2024-09-12T08:06:36.015675","exception":false,"start_time":"2024-09-12T08:06:36.000757","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T08:42:57.166926Z","iopub.execute_input":"2024-09-12T08:42:57.167361Z","iopub.status.idle":"2024-09-12T08:42:57.179971Z","shell.execute_reply.started":"2024-09-12T08:42:57.167316Z","shell.execute_reply":"2024-09-12T08:42:57.178596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read Image","metadata":{"papermill":{"duration":0.004712,"end_time":"2024-09-12T08:06:36.025663","exception":false,"start_time":"2024-09-12T08:06:36.020951","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def find_clinical_sheet(excel_file, keywords):\n    \"\"\"\n    Finds the sheet containing clinical data in an Excel file.\n\n    Parameters:\n    excel_file (pd.ExcelFile): The Excel file object.\n    keywords (list): List of keywords to identify the clinical sheet.\n\n    Returns:\n    str: The name of the sheet containing clinical data.\n\n    Raises:\n    ValueError: If no sheet with clinical data is found.\n    \"\"\"\n    for sheet in excel_file.sheet_names:\n        if any(keyword in sheet.lower() for keyword in keywords):\n            return sheet\n    \n    raise ValueError('No clinical sheet found in the Excel file.')\n\ndef read_clinical_data(file_path):\n    \"\"\"\n    Reads clinical data from an Excel file.\n\n    Parameters:\n    file_path (str): The path to the Excel file.\n\n    Returns:\n    pandas.DataFrame: A DataFrame containing the clinical data.\n\n    Raises:\n    ValueError: If no sheet with clinical data is found in the Excel file.\n    \"\"\"\n    clinical_keywords = ['clinical', 'клинические']\n    \n    try:\n        xls = pd.ExcelFile(file_path)\n        clinical_sheet = find_clinical_sheet(xls, clinical_keywords)\n        return pd.read_excel(xls, clinical_sheet)\n    except ValueError as e:\n        raise ValueError(f\"Error reading clinical data: {str(e)}\")","metadata":{"papermill":{"duration":0.018494,"end_time":"2024-09-12T08:06:36.049128","exception":false,"start_time":"2024-09-12T08:06:36.030634","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T08:42:57.181550Z","iopub.execute_input":"2024-09-12T08:42:57.181943Z","iopub.status.idle":"2024-09-12T08:42:57.195945Z","shell.execute_reply.started":"2024-09-12T08:42:57.181903Z","shell.execute_reply":"2024-09-12T08:42:57.194607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_images(dicom_images, img_size=IMG_SIZE):\n    \"\"\"\n    Preprocesses DICOM images for machine learning model input.\n\n    Parameters:\n    dicom_images (dict): A dictionary with a single key, where the value is a list of pydicom.dataset.FileDataset objects.\n    img_size (tuple): Target image size (height, width). Default is (512, 512).\n\n    Returns:\n    numpy.ndarray: 4D array of preprocessed images (n_images, height, width, 3).\n    \"\"\"\n    # Get the list of DICOM images from the dictionary\n    images_list = list(dicom_images.values())[0]\n    \n    # Apply preprocess_single_image to each image in the list\n    return np.array([preprocess_single_image(img, img_size) for img in images_list])\n\ndef preprocess_single_image(dicom_image, img_size):\n    \"\"\"\n    Preprocesses a single DICOM image.\n\n    Parameters:\n    dicom_image (pydicom.dataset.FileDataset): DICOM image object.\n    img_size (tuple): Target image size (height, width).\n\n    Returns:\n    numpy.ndarray: Preprocessed image as a 3D array (height, width, 3).\n    \"\"\"\n    image_array = dicom_image.pixel_array\n    normalized_image = normalize_image(image_array)\n    resized_image = resize_image(normalized_image, img_size)\n    return convert_to_rgb(resized_image)\n\ndef normalize_image(image):\n    \"\"\"\n    Normalizes image pixel values to [0, 1] range.\n\n    Parameters:\n    image (numpy.ndarray): Input image array.\n\n    Returns:\n    numpy.ndarray: Normalized image array.\n    \"\"\"\n    max_value = np.max(image)\n    return image / max_value if max_value > 0 else np.zeros_like(image)\n\ndef resize_image(image, target_size):\n    \"\"\"\n    Resizes image to target size using anti-aliasing.\n\n    Parameters:\n    image (numpy.ndarray): Input image array.\n    target_size (tuple): Target image size (height, width).\n\n    Returns:\n    numpy.ndarray: Resized image array.\n    \"\"\"\n    return resize(image, target_size, anti_aliasing=True)\n\ndef convert_to_rgb(image):\n    \"\"\"\n    Converts grayscale image to RGB if necessary.\n\n    Parameters:\n    image (numpy.ndarray): Input image array.\n\n    Returns:\n    numpy.ndarray: RGB image array.\n    \"\"\"\n    if len(image.shape) == 2:\n        return np.stack((image,) * 3, axis=-1)\n    return image","metadata":{"papermill":{"duration":0.020344,"end_time":"2024-09-12T08:06:36.074556","exception":false,"start_time":"2024-09-12T08:06:36.054212","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T08:42:57.198810Z","iopub.execute_input":"2024-09-12T08:42:57.199311Z","iopub.status.idle":"2024-09-12T08:42:57.214518Z","shell.execute_reply.started":"2024-09-12T08:42:57.199228Z","shell.execute_reply":"2024-09-12T08:42:57.212936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BaseDatasetGenerator(Dataset):\n    def __init__(self, dataset_dir: str, start_idx: int = 0, batch_size: int = 100, max_images_per_series: int = 50):\n        self.dataset_dir = dataset_dir\n        self.start_idx = start_idx\n        self.batch_size = batch_size\n        self.max_images_per_series = max_images_per_series\n        self.studies_folders = self._get_studies_folders()\n        self.clinical_data = self._load_clinical_data()\n        self.clinical_data = self._filter_clinical_data()  # New step to filter the data\n        self.study_uids = self._get_study_uids()\n        self.current_index = self.start_idx\n\n    def _get_studies_folders(self) -> List[str]:\n        \"\"\"Get all studies folders in the dataset directory.\"\"\"\n        return [f for f in os.listdir(self.dataset_dir) if os.path.isdir(os.path.join(self.dataset_dir, f))]\n\n    def _load_clinical_data(self) -> pd.DataFrame:\n        \"\"\"Load clinical data from Excel files in all studies folders.\"\"\"\n        all_clinical_data = []\n        for folder in self.studies_folders:\n            folder_path = os.path.join(self.dataset_dir, folder, folder)\n            excel_files = glob.glob(os.path.join(folder_path, '*.xlsx'))\n            \n            if not excel_files:\n                print(f\"Warning: No Excel file found in {folder_path}\")\n                continue\n            \n            if len(excel_files) > 1:\n                print(f\"Warning: Multiple Excel files found in {folder_path}. Using the first one.\")\n            \n            excel_path = excel_files[0]\n            df = pd.read_excel(excel_path)\n            df['folder'] = folder  # Add a column to identify the source folder\n            all_clinical_data.append(df)\n        \n        if not all_clinical_data:\n            raise FileNotFoundError(f\"No Excel files found in any of the studies folders in {self.dataset_dir}\")\n        \n        return pd.concat(all_clinical_data, ignore_index=True)\n\n    def _get_study_uids(self) -> np.ndarray:\n        \"\"\"Extract unique study UIDs from the clinical data.\"\"\"\n        return self.clinical_data['study_uid'].unique()\n\n    def __len__(self) -> int:\n        \"\"\"Return the total number of studies in the dataset.\"\"\"\n        return len(self.study_uids)\n\n    def __getitem__(self, idx: int) -> Tuple[np.ndarray, Dict]:\n        \"\"\"\n        Get the preprocessed images and labels for a specific study.\n\n        Args:\n            idx (int): Index of the study to retrieve.\n\n        Returns:\n            Tuple[np.ndarray, Dict]: Preprocessed images and labels for the study.\n        \"\"\"\n        study_uid = self.study_uids[idx]\n        dicom_series = self._load_dicom_images(study_uid)\n        labels = self._get_labels(study_uid)\n        processed_images = self.preprocess_images(dicom_series, img_size=(512, 512))\n        return processed_images, labels\n\n    def _filter_clinical_data(self) -> pd.DataFrame:\n        \"\"\"Filter clinical data based on specified criteria.\"\"\"\n        hemorrhage_columns = [\n            'epidural hemorrhage', 'subarachnoid hemorrhage', \n            'subdural hemorrhage', 'intracerebral hemorrhage', \n            'multiple hemorrhages'\n        ]\n\n        # Filter out rows with \"Study without report\" in the 'Comment' column\n        filtered_data = self.clinical_data[self.clinical_data['Comment'] != \"Study without report\"]\n\n        # Filter out rows with non-binary values in hemorrhage columns or skull fracture\n        for column in hemorrhage_columns + ['skull fracture']:\n            filtered_data = filtered_data[filtered_data[column].isin([0.0, 1.0])]\n\n        return filtered_data\n    \n    def _get_study_uids(self) -> np.ndarray:\n        \"\"\"Extract unique study UIDs from the filtered clinical data.\"\"\"\n        return self.clinical_data['study_uid'].unique()\n    \n    def _load_dicom_images(self, study_uid: str) -> Dict[str, List[pydicom.dataset.FileDataset]]:\n        \"\"\"\n        Load DICOM images for a specific study from the appropriate folder.\n\n        Args:\n            study_uid (str): Unique identifier for the study.\n\n        Returns:\n            Dict[str, List[pydicom.dataset.FileDataset]]: Dictionary of DICOM images by series UID.\n        \"\"\"\n        dicom_series = {}\n        study_folder = self.clinical_data[self.clinical_data['study_uid'] == study_uid]['folder'].iloc[0]\n        study_path = os.path.join(self.dataset_dir, study_folder, study_folder, study_uid)\n        \n        for root, _, files in os.walk(study_path):\n            for file in files:\n                if file.endswith('.dcm'):\n                    file_path = os.path.join(root, file)\n                    dicom_image = pydicom.dcmread(file_path, force=True)\n                    series_uid = dicom_image.SeriesInstanceUID\n                    if series_uid not in dicom_series:\n                        dicom_series[series_uid] = []\n                    dicom_series[series_uid].append(dicom_image)\n        return dicom_series\n\n    def _get_labels(self, study_uid: str) -> Dict:\n        \"\"\"\n        Get labels for a specific study.\n\n        Args:\n            study_uid (str): Unique identifier for the study.\n\n        Returns:\n            Dict: Labels for the study, or None if not found.\n        \"\"\"\n        study_clinical_data = self.clinical_data[self.clinical_data['study_uid'] == study_uid]\n        return study_clinical_data.iloc[0].to_dict() if not study_clinical_data.empty else None\n\n    @staticmethod\n    def preprocess_images(dicom_series: Dict[str, List[pydicom.dataset.FileDataset]], img_size: Tuple[int, int]) -> np.ndarray:\n        \"\"\"\n        Preprocess DICOM images.\n\n        Args:\n            dicom_series (Dict[str, List[pydicom.dataset.FileDataset]]): Dictionary of DICOM images by series UID.\n            img_size (Tuple[int, int]): Target image size.\n\n        Returns:\n            np.ndarray: Preprocessed images.\n        \"\"\"\n        # Implement your image preprocessing logic here\n        # This is a placeholder implementation\n        processed_images = []\n        for series in dicom_series.values():\n            for dicom_image in series:\n                # Extract pixel array and resize\n                pixel_array = dicom_image.pixel_array\n                resized_image = np.resize(pixel_array, img_size)\n                processed_images.append(resized_image)\n        return np.array(processed_images)\n\nclass TrainDatasetGenerator(BaseDatasetGenerator):\n    def __init__(self, dataset_dir: str, studies_folder: str, \n                 start_idx: int = 0, batch_size: int = 100, max_images_per_series: int = 50):\n        super().__init__(dataset_dir, start_idx, batch_size, max_images_per_series)\n        self.studies_folder = studies_folder\n        # Additional initialization using studies_folder if needed\n\nclass TestDatasetGenerator(BaseDatasetGenerator):\n    \"\"\"\n    Dataset generator for test data.\n\n    This class inherits from BaseDatasetGenerator and can be extended with\n    test-specific functionality as needed.\n    \"\"\"\n\n    def __init__(self, dataset_dir: str, \n                 start_idx: int = 0, batch_size: int = 100, max_images_per_series: int = 50):\n        super().__init__(dataset_dir, start_idx, batch_size, max_images_per_series)\n        # Additional initialization for test dataset if needed\n","metadata":{"papermill":{"duration":0.039359,"end_time":"2024-09-12T08:06:36.119109","exception":false,"start_time":"2024-09-12T08:06:36.079750","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T08:42:57.258262Z","iopub.execute_input":"2024-09-12T08:42:57.259271Z","iopub.status.idle":"2024-09-12T08:42:57.296948Z","shell.execute_reply.started":"2024-09-12T08:42:57.259182Z","shell.execute_reply":"2024-09-12T08:42:57.295440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example usage\nstudies_folder = '400_500_studies'\n\ntrain_dataset = TrainDatasetGenerator(dataset_dir=DATASET_DIR, studies_folder=studies_folder)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"papermill":{"duration":1.37754,"end_time":"2024-09-12T08:06:37.501707","exception":false,"start_time":"2024-09-12T08:06:36.124167","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T08:42:57.299602Z","iopub.execute_input":"2024-09-12T08:42:57.300071Z","iopub.status.idle":"2024-09-12T08:42:57.967277Z","shell.execute_reply.started":"2024-09-12T08:42:57.300029Z","shell.execute_reply":"2024-09-12T08:42:57.965811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_dicom_images(images, labels, num_images=4):\n    fig, axes = plt.subplots(1, num_images, figsize=(20, 5))\n    for i, ax in enumerate(axes):\n        if i < len(images):\n            ax.imshow(images[i], cmap='gray')\n            ax.set_title(f\"Image {i+1}\")\n            # ax.axis('off')\n        else:\n            ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n    \n    print(\"Labels:\")\n    for key, value in labels.items():\n        print(f\"{key}: {value}\")\n","metadata":{"papermill":{"duration":0.018272,"end_time":"2024-09-12T08:06:37.525244","exception":false,"start_time":"2024-09-12T08:06:37.506972","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T08:42:57.968703Z","iopub.execute_input":"2024-09-12T08:42:57.969109Z","iopub.status.idle":"2024-09-12T08:42:57.977861Z","shell.execute_reply.started":"2024-09-12T08:42:57.969067Z","shell.execute_reply":"2024-09-12T08:42:57.976568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_images, first_labels = train_dataset.__getitem__(0)\n\nplot_dicom_images(first_images, first_labels)","metadata":{"papermill":{"duration":5.846135,"end_time":"2024-09-12T08:06:43.376786","exception":false,"start_time":"2024-09-12T08:06:37.530651","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-12T08:42:57.980686Z","iopub.execute_input":"2024-09-12T08:42:57.981085Z","iopub.status.idle":"2024-09-12T08:43:00.730032Z","shell.execute_reply.started":"2024-09-12T08:42:57.981044Z","shell.execute_reply":"2024-09-12T08:43:00.728631Z"},"trusted":true},"execution_count":null,"outputs":[]}]}