{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import Library"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","import pydicom\n","import psutil\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset\n","from torchvision import models\n","from skimage.transform import resize\n","from sklearn.model_selection import train_test_split\n","import gc\n","import warnings\n","import os\n","import glob\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.amp import autocast, GradScaler\n"]},{"cell_type":"markdown","metadata":{},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Constants\n","BATCH_SIZE = 8\n","CHUNK_SIZE = 8\n","START_IDX = 0\n","MAX_IMAGES_PER_SERIES = 128\n","CHECKPOINT_PATH = '/kaggle/working/model_checkpoint.pth'\n","IMG_SIZE = (224, 224)\n","NUM_EPOCHS = 5\n","LEARNING_RATE = 5e-7\n","LOSS_FUNCTION = 'binary_crossentropy'\n","METRICS = ['accuracy']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def read_clinical_data(file_path):\n","    '''\n","    Reads clinical data from an Excel file.\n","\n","    This function attempts to find a sheet containing clinical data in the given Excel file.\n","    It searches for sheets with names containing 'clinical', 'клинические', or 'сlinical' \n","    (case-insensitive).\n","\n","    Parameters:\n","    file_path (str): The path to the Excel file.\n","\n","    Returns:\n","    pandas.DataFrame: A DataFrame containing the clinical data from the identified sheet.\n","\n","    Raises:\n","    ValueError: If no sheet with clinical data is found in the Excel file.\n","\n","    Note:\n","    The function uses pandas to read the Excel file and assumes that the clinical data\n","    is contained in a single sheet.\n","    '''\n","    xls = pd.ExcelFile(file_path)\n","    sheet_names_lower = [sheet.lower() for sheet in xls.sheet_names]\n","    clinical_sheet = [sheet for sheet in sheet_names_lower if 'clinical' in sheet \n","                      or 'клинические' in sheet \n","                      or 'сlinical' in sheet]\n","    if not clinical_sheet:\n","        raise ValueError('No clinical sheet found in the XLSX file.')\n","    \n","    original_sheet_name = xls.sheet_names[sheet_names_lower.index(clinical_sheet[0])]\n","    df_clinical = pd.read_excel(xls, original_sheet_name)\n","    return df_clinical\n","\n","def read_dicom_files(study_path):\n","    '''\n","    Reads DICOM files from a study directory.\n","\n","    This function scans the given study directory for DICOM files (.dcm) organized in series \n","    subdirectories. It reads each DICOM file and groups them by series.\n","\n","    Parameters:\n","    study_path (str): The path to the study directory containing series subdirectories with DICOM files.\n","\n","    Returns:\n","    dict: A dictionary where keys are series names and values are lists of pydicom.dataset.FileDataset \n","          objects representing the DICOM images in each series.\n","\n","    Note:\n","    - The function assumes that DICOM files are organized in series subdirectories within the study directory.\n","    - It sets default values for 'SamplesPerPixel' and 'PhotometricInterpretation' if these tags are missing.\n","    - Empty series (directories without valid DICOM files) are not included in the returned dictionary.\n","    '''\n","    dicom_series = {}\n","    for series in os.listdir(study_path):\n","        series_path = os.path.join(study_path, series)\n","        if os.path.isdir(series_path):\n","            series_images = []\n","            for file in os.listdir(series_path):\n","                if file.endswith('.dcm'):\n","                    dicom_path = os.path.join(series_path, file)\n","                    dicom_image = pydicom.dcmread(dicom_path, force=True)\n","                    if 'SamplesPerPixel' not in dicom_image:\n","                        dicom_image.SamplesPerPixel = 1\n","                    if 'PhotometricInterpretation' not in dicom_image:\n","                        dicom_image.PhotometricInterpretation = 'MONOCHROME2'\n","                    series_images.append(dicom_image)\n","            if series_images:\n","                dicom_series[series] = series_images\n","    return dicom_series"]},{"cell_type":"markdown","metadata":{},"source":["### Note\n","\n","```python\n","max_value = np.max(image_array)\n","image_array = image_array / max_value if max_value > 0 else np.zeros_like(image_array)\n","```\n","\n","- Need to reconsider the division by max_value for normalization:\n","  - If max_value differs between images, two points with equal values in different images might not be equal after normalization. Does this affect training results?\n","  - If it doesn't affect results now, could it impact when applying Hounsfield Units (HU)? When values are filtered to highlight specific parts, does normalization negate this effect?\n","  - Since HU can have negative values [-1000; 2000], what if the max in an image is 0? Would all pixels become 0 after division?\n","\n","- Anti-aliasing blurs edges. Is there a way to control the degree of blurring? Can we print some sample images to see the effect?\n","  - If we're not cropping, we might not need anti-aliasing."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess_images(dicom_images):\n","    '''\n","    Preprocesses a list of DICOM images for use in a machine learning model.\n","\n","    This function performs the following preprocessing steps on each DICOM image:\n","    1. Extracts the pixel array from the DICOM image.\n","    2. Normalizes the pixel values to the range [0, 1].\n","    3. Resizes the image to a predefined size (IMG_SIZE).\n","    4. Converts grayscale images to RGB by replicating the single channel.\n","\n","    Parameters:\n","    dicom_images (list): A list of pydicom.dataset.FileDataset objects representing DICOM images.\n","\n","    Returns:\n","    numpy.ndarray: A 4D numpy array of preprocessed images with shape (n_images, height, width, 3),\n","                   where each image is normalized, resized, and in RGB format.\n","\n","    Note:\n","    - The function assumes that IMG_SIZE is a predefined constant representing the target image size.\n","    - Images are resized using anti-aliasing for better quality.\n","    - Grayscale images are converted to RGB by replicating the single channel three times.\n","    - If an image's maximum pixel value is 0, it will be converted to an all-zero array.\n","    '''\n","    preprocessed_images = []\n","    for dicom_image in dicom_images:\n","        image_array = dicom_image.pixel_array\n","        max_value = np.max(image_array)\n","        image_array = image_array / max_value if max_value > 0 else np.zeros_like(image_array)\n","        resized_image = resize(image_array, IMG_SIZE, anti_aliasing=True)\n","        rgb_image = np.stack((resized_image,) * 3, axis=-1) if len(resized_image.shape) == 2 else resized_image\n","        preprocessed_images.append(rgb_image)\n","    return np.array(preprocessed_images)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def process_batch(studies_folder, dataset_path, start_idx=START_IDX, batch_size=BATCH_SIZE, max_images_per_series=MAX_IMAGES_PER_SERIES):\n","    '''\n","    Process a batch of medical imaging studies, extracting DICOM images and clinical data.\n","\n","    This function reads DICOM files from a specified folder, preprocesses the images,\n","    and extracts corresponding clinical data from an Excel file. It processes a subset\n","    of studies based on the start index and batch size.\n","\n","    Parameters:\n","    studies_folder (str): Name of the folder containing the studies.\n","    dataset_path (str): Path to the dataset root directory.\n","    start_idx (int): Starting index for processing studies in the folder.\n","    batch_size (int): Number of studies to process in this batch.\n","    max_images_per_series (int): Maximum number of images to process per series.\n","\n","    Returns:\n","    tuple: A tuple containing three elements:\n","        - patient_data (dict): A dictionary with study UIDs as keys, containing\n","          preprocessed images and clinical labels for each study.\n","        - all_clinical_data (pd.DataFrame): A DataFrame containing clinical data\n","          for all processed studies.\n","        - next_start_idx (int): The next starting index for subsequent batches.\n","\n","    Notes:\n","    - The function expects a specific folder structure and file naming convention.\n","    - It processes DICOM images and extracts clinical data from an Excel file.\n","    - Target columns for clinical data are predefined and must be binary (0 or 1).\n","    - Warnings are logged for missing clinical data or unprocessed images.\n","    '''\n","    all_processed_series = {}\n","    all_clinical_data = pd.DataFrame()\n","    \n","    target_columns = ['epidural hemorrhage', 'subarachnoid hemorrhage', 'subdural hemorrhage', \n","                      'intracerebral hemorrhage', 'multiple hemorrhages', 'skull fracture']\n","    \n","    if studies_folder != '200_300_studies':\n","        studies_folder_path = os.path.join(dataset_path, studies_folder, studies_folder)\n","        print(f\"Processing folder {studies_folder}\")\n","        xlsx_files = [f for f in os.listdir(studies_folder_path) if f.endswith('.xlsx')]\n","        \n","        if len(xlsx_files) == 1:\n","            clinical_data_path = os.path.join(studies_folder_path, xlsx_files[0])\n","            clinical_data = read_clinical_data(clinical_data_path)    \n","            clinical_data.columns = clinical_data.columns.str.lower()\n","            clinical_data = clinical_data[clinical_data['comment'] != 'Study without report']\n","\n","            # Check if target columns are binary and drop non-binary rows\n","            for column in target_columns:\n","                if column in clinical_data.columns:\n","                    clinical_data = clinical_data[clinical_data[column].isin([0, 1])]\n","                else:\n","                    print(f\"Warning: Column '{column}' not found in clinical data.\")\n","\n","            study_uids_in_folder = [uid for uid in os.listdir(studies_folder_path) if os.path.isdir(os.path.join(studies_folder_path, uid))]\n","            \n","            for study_uid in study_uids_in_folder[start_idx:start_idx+batch_size]:\n","                study_path = os.path.join(studies_folder_path, study_uid)\n","                \n","                dicom_series = read_dicom_files(study_path)\n","                \n","                for series_uid, series_images in dicom_series.items():\n","                    processed_images = preprocess_images(series_images)\n","                    \n","                    if len(processed_images) > 0:\n","                        if study_uid not in all_processed_series:\n","                            all_processed_series[study_uid] = {}\n","                        all_processed_series[study_uid][series_uid] = processed_images\n","                        \n","                        study_clinical_data = clinical_data[clinical_data['study_uid'] == study_uid]\n","                        if not study_clinical_data.empty:\n","                            all_clinical_data = pd.concat([all_clinical_data, study_clinical_data], ignore_index=True)\n","                            print(f\"Processed {len(series_images)} DICOM images for study UID: {study_uid}, series UID: {series_uid}\")\n","                        else:\n","                            print(f\"Warning: No clinical data found for study UID: {study_uid}\")\n","                    else:\n","                        print(f\"No images processed for study UID: {study_uid}, series UID: {series_uid}\")\n","\n","        else:\n","            print(f\"Error: Expected exactly one XLSX file in {studies_folder_path}\")\n","\n","    print(\"Number of processed studies:\", len(all_processed_series))\n","    print(\"Number of rows in clinical data:\", len(all_clinical_data))\n","\n","    patient_data = {}\n","\n","    for study_uid, series_dict in all_processed_series.items():\n","        study_clinical_data = all_clinical_data[all_clinical_data['study_uid'] == study_uid]\n","        if not study_clinical_data.empty:\n","            patient_data[study_uid] = {\n","                'images': series_dict,\n","                'labels': study_clinical_data.iloc[0][target_columns].to_dict()\n","            }\n","        else:\n","            print(f\"Warning: No clinical data for study UID: {study_uid}\")\n","\n","    return patient_data, all_clinical_data, start_idx + len(all_processed_series)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torchvision.models.resnet import ResNet50_Weights\n","\n","def create_or_load_model(checkpoint_path):\n","    '''\n","    Creates a new ResNet50 model or loads a previously saved model from a checkpoint.\n","\n","    This function initializes a ResNet50 model pre-trained on ImageNet and modifies\n","    its fully connected layer for a 6-class classification task. If a checkpoint file\n","    exists at the specified path, it attempts to load the model weights from that checkpoint.\n","\n","    Parameters:\n","    checkpoint_path (str): The file path where the model checkpoint is expected to be found.\n","\n","    Returns:\n","    torch.nn.Module: A ResNet50 model, either newly initialized or loaded from a checkpoint,\n","                     with the final layer modified for 6-class output.\n","\n","    Notes:\n","    - The function uses the DEFAULT weights for ResNet50 from torchvision.\n","    - The model's fully connected layer is modified to output 6 classes.\n","    - If a checkpoint file exists:\n","        - It attempts to load the model state from the checkpoint.\n","        - If loading fails, it falls back to creating a new model.\n","    - If no checkpoint file exists, a new model is created.\n","    - Any errors during checkpoint loading are caught and reported.\n","\n","    Raises:\n","    - May raise exceptions related to file I/O or torch.load operations.\n","    '''\n","    model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n","    num_ftrs = model.fc.in_features\n","    model.fc = nn.Linear(num_ftrs, 6)  # Change to 6 outputs for 6 labels\n","    \n","    if os.path.exists(checkpoint_path):\n","        print(f\"Attempting to load checkpoint from {checkpoint_path}\")\n","        try:\n","            checkpoint = torch.load(checkpoint_path, weights_only=True)\n","            model.load_state_dict(checkpoint['model_state_dict'])\n","            print(\"Checkpoint loaded successfully\")\n","        except (KeyError, RuntimeError) as e:\n","            print(f\"Error loading checkpoint: {e}\")\n","            print(\"Creating new model instead\")\n","    else:\n","        print(\"No checkpoint found. Creating new model\")\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def custom_collate(batch):\n","    '''\n","    Custom collate function for creating batches with variable-sized image sequences.\n","\n","    This function is designed to be used with PyTorch's DataLoader to handle batches\n","    where each item may contain a different number of images. It pads the image sequences\n","    to ensure all items in the batch have the same number of images.\n","\n","    Parameters:\n","    batch (list): A list of tuples, where each tuple contains:\n","                  (images, labels, patient_id, series_uid)\n","                  - images: A tensor of shape (num_images, channels, height, width)\n","                  - labels: A tensor of labels\n","                  - patient_id: A string or identifier for the patient\n","                  - series_uid: A string or identifier for the image series\n","\n","    Returns:\n","    tuple: A tuple containing:\n","           - images (torch.Tensor): Padded and stacked images of shape \n","             (batch_size, max_images, channels, height, width)\n","           - labels (torch.Tensor): Stacked labels\n","           - patient_ids (tuple): Original patient IDs\n","           - series_uids (tuple): Original series UIDs\n","\n","    Notes:\n","    - The function pads shorter image sequences with zeros to match the length\n","      of the longest sequence in the batch.\n","    - This approach allows for efficient processing of variable-length sequences\n","      in a single batch.\n","    - The original patient IDs and series UIDs are returned as tuples to maintain\n","      the correspondence with the padded images and labels.\n","    '''\n","    images, labels, patient_ids, series_uids = zip(*batch)\n","    \n","    # Pad images to the same size\n","    max_images = max(img.size(0) for img in images)\n","    padded_images = []\n","    for img in images:\n","        if img.size(0) < max_images:\n","            padding = torch.zeros(max_images - img.size(0), *img.size()[1:])\n","            img = torch.cat([img, padding], dim=0)\n","        padded_images.append(img)\n","    \n","    images = torch.stack(padded_images)\n","    labels = torch.stack(labels)\n","    \n","    return images, labels, patient_ids, series_uids"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class PatientDataset(Dataset):\n","    '''\n","    A custom PyTorch Dataset for handling patient medical imaging data and associated labels.\n","\n","    This dataset is designed to work with a dictionary of patient data, where each patient\n","    may have multiple image series. It prepares the data for use in a PyTorch DataLoader,\n","    organizing it into a format suitable for training or evaluation of medical imaging models.\n","\n","    Attributes:\n","    patient_data (dict): A dictionary containing patient data, where each key is a patient ID\n","                         and each value is a dictionary with 'images' and 'labels' keys.\n","    patient_ids (list): A list of patient IDs to include in the dataset.\n","    series_data (list): A list of tuples, each containing (image_tensor, label_tensor, \n","                        patient_id, series_uid) for each series of each patient.\n","\n","    Methods:\n","    __init__(self, patient_data, patient_ids): Initializes the dataset.\n","    __len__(self): Returns the total number of image series in the dataset.\n","    __getitem__(self, idx): Retrieves a single item (image series, label, patient ID, series UID)\n","                            from the dataset.\n","\n","    The __init__ method:\n","    - Processes the patient_data dictionary.\n","    - Converts image data to PyTorch tensors and applies necessary transformations.\n","    - Creates label tensors for each patient.\n","    - Organizes all series data into a list of tuples for easy access.\n","\n","    The __getitem__ method:\n","    - Returns a tuple containing:\n","      1. Image tensor of shape (num_images, channels, height, width)\n","      2. Label tensor\n","      3. Patient ID\n","      4. Series UID\n","\n","    Note:\n","    - This class assumes that the 'labels' in patient_data are consistent across all patients\n","      and are in a format that can be directly converted to a tensor.\n","    - Image data is expected to be in a format that can be converted to a PyTorch tensor\n","      and have dimensions (num_images, height, width, channels).\n","    '''\n","    def __init__(self, patient_data, patient_ids):\n","        self.patient_data = patient_data\n","        self.patient_ids = patient_ids\n","        self.series_data = []\n","        \n","        for patient_id in self.patient_ids:\n","            patient = self.patient_data[patient_id]\n","            labels = patient['labels']\n","            label_tensor = torch.tensor([labels[key] for key in sorted(labels.keys())]).float()\n","            \n","            for series_uid, series_images in patient['images'].items():\n","                series_tensor = torch.tensor(series_images).float().permute(0, 3, 1, 2)\n","                self.series_data.append((series_tensor, label_tensor, patient_id, series_uid))\n","    \n","    def __len__(self):\n","        return len(self.series_data)\n","    \n","    def __getitem__(self, idx):\n","        return self.series_data[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_model_in_batches(model, studies_folders, dataset_path, batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS, accumulation_steps=4):\n","    '''\n","    Trains a PyTorch model on medical imaging data in batches.\n","\n","    This function implements a training loop that processes multiple studies folders,\n","    handles large datasets by processing them in batches, and uses mixed precision\n","    training with gradient accumulation.\n","\n","    Parameters:\n","    model (torch.nn.Module): The PyTorch model to be trained.\n","    studies_folders (list): List of folder names containing the study data.\n","    dataset_path (str): Path to the root directory of the dataset.\n","    batch_size (int): Number of images to process in each sub-batch.\n","    num_epochs (int): Number of training epochs.\n","    accumulation_steps (int): Number of steps to accumulate gradients before updating weights.\n","\n","    Returns:\n","    torch.nn.Module: The trained model.\n","\n","    Notes:\n","    - Uses BCEWithLogitsLoss as the loss function and AdamW as the optimizer.\n","    - Implements mixed precision training using torch.cuda.amp.\n","    - Processes data in batches to handle large datasets.\n","    - Saves a checkpoint after processing each batch of studies.\n","    - Assumes the existence of global constants:\n","      LEARNING_RATE, IMG_SIZE, CHUNK_SIZE, MAX_IMAGES_PER_SERIES, CHECKPOINT_PATH\n","\n","    The training process:\n","    1. Iterates over epochs and study folders.\n","    2. Processes batches of patient data using the `process_batch` function.\n","    3. Creates a DataLoader for each batch of patient data.\n","    4. For each batch:\n","       - Moves data to the appropriate device (CPU/GPU).\n","       - Processes sub-batches of images to handle memory constraints.\n","       - Computes loss, scales gradients, and performs backpropagation.\n","       - Updates model weights after accumulating gradients.\n","    5. Saves a checkpoint after processing each batch of studies.\n","\n","    Requirements:\n","    - Requires the PatientDataset class and custom_collate function to be defined.\n","    - Assumes the availability of CUDA for GPU acceleration.\n","    '''\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","    criterion = nn.BCEWithLogitsLoss()\n","    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n","    scaler = GradScaler()\n","\n","    for epoch in range(num_epochs):\n","        print(f\"Epoch {epoch+1}/{num_epochs}\")\n","        for studies_folder in studies_folders:\n","            start_idx = 0\n","            while True:\n","                patient_data, clinical_data, next_start_idx = process_batch(studies_folder, dataset_path, start_idx, BATCH_SIZE, MAX_IMAGES_PER_SERIES)\n","                \n","                if not patient_data:\n","                    break  # No more data to process in this folder\n","                \n","                dataset = PatientDataset(patient_data, list(patient_data.keys()))\n","                dataloader = torch.utils.data.DataLoader(dataset, batch_size=CHUNK_SIZE, shuffle=True, collate_fn=custom_collate)\n","                \n","                for i, (images, labels, patient_ids, series_uids) in enumerate(dataloader):\n","                    print(f\"Batch {i+1} - Images shape: {images.shape}, Labels shape: {labels.shape}\")\n","                    images = images.to(device)\n","                    labels = labels.to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    \n","                    for j in range(0, images.size(1), batch_size):\n","                        batch = images[:, j:j+batch_size].contiguous().view(-1, 3, IMG_SIZE[0], IMG_SIZE[1])\n","                        batch_labels = labels.repeat_interleave(batch_size, dim=0)\n","                        \n","                        print(f\"  Sub-batch {j//batch_size + 1} - Batch shape: {batch.shape}, Batch labels shape: {batch_labels.shape}\")\n","\n","                        with autocast():\n","                            outputs = model(batch)\n","                            print(f\"  Outputs shape: {outputs.shape}\")\n","                            loss = criterion(outputs, batch_labels[:outputs.size(0)])\n","                        \n","                        scaler.scale(loss).backward()\n","                        \n","                        if (j + batch_size) % (batch_size * accumulation_steps) == 0:\n","                            scaler.step(optimizer)\n","                            scaler.update()\n","                            optimizer.zero_grad()\n","\n","                    print(f\"Batch {i+1} processed\")\n","                \n","                start_idx = next_start_idx\n","                \n","                # Save checkpoint after each batch\n","                torch.save({\n","                    'epoch': epoch,\n","                    'model_state_dict': model.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict(),\n","                }, CHECKPOINT_PATH)\n","                print(f\"Checkpoint saved to {CHECKPOINT_PATH}\")\n","                \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-08T12:06:42.746926Z","iopub.status.busy":"2024-09-08T12:06:42.746459Z"},"trusted":true},"outputs":[],"source":["def save_final_model(model, path=CHECKPOINT_PATH):\n","    torch.save(model.state_dict(), path)\n","    print(f\"Final model saved to {path}\")\n","\n","dataset_path = '/kaggle/input/mosmeddata-ct-hemorrhage-type-viii/MosMedData-CT-HEMORRHAGE-type VIII/'\n","\n","# Get a list of all studies folders\n","# studies_folders = [f for f in os.listdir(dataset_path) if f.endswith('_studies')]\n","studies_folders = ['400_500_studies']\n","print(studies_folders)\n","\n","#### Main execution\n","model = create_or_load_model(CHECKPOINT_PATH)\n","\n","# Train the model in batches\n","model = train_model_in_batches(model, studies_folders, dataset_path)\n","\n","# Save the final model\n","save_final_model(model)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5557228,"sourceId":9192599,"sourceType":"datasetVersion"},{"datasetId":5633589,"sourceId":9303618,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
