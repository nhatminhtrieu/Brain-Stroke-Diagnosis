{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import Libraries",
   "id": "d675e2349b26c09f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-08T05:58:47.894Z",
     "start_time": "2024-12-08T05:58:46.760414Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import v2 as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Preparation",
   "id": "672bbbd8209f388f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T05:58:49.697111Z",
     "start_time": "2024-12-08T05:58:47.898064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_data, eval_data = train_test_split(mnist_data, train_size=0.1, random_state=42, stratify=mnist_data.targets)\n",
    "\n",
    "# Bag-level dataset\n",
    "class BagDataset(Dataset):\n",
    "    def __init__(self, data, bag_size=8):\n",
    "        self.data = data\n",
    "        self.bag_size = bag_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) // self.bag_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images, labels = [], []\n",
    "        for i in range(self.bag_size):\n",
    "            img, label = self.data[idx * self.bag_size + i]\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "        bag_label = 1 if 9 in labels else 0\n",
    "        return torch.stack(images), torch.tensor(bag_label)\n",
    "\n",
    "train_dataset = BagDataset(train_data)\n",
    "eval_dataset = BagDataset(eval_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, pin_memory=True, num_workers=4, drop_last=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=4, shuffle=False, pin_memory=True, num_workers=4, drop_last=True)"
   ],
   "id": "bad48fa375531d1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Definition",
   "id": "4ad3fd07b10aa85b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NTXentLoss",
   "id": "20bbdf04d7172c16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T05:58:49.727612Z",
     "start_time": "2024-12-08T05:58:49.724855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define NTXentLoss (provided by you)\n",
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        batch_size = z_i.size(0)\n",
    "        z = torch.cat([z_i, z_j], dim=0)\n",
    "        z = F.normalize(z, dim=1)\n",
    "        similarity_matrix = torch.mm(z, z.T) / self.temperature\n",
    "        mask = torch.eye(2 * batch_size, device=z.device).bool()\n",
    "        similarity_matrix.masked_fill_(mask, -float('inf'))\n",
    "        exp_sim = torch.exp(similarity_matrix)\n",
    "        denominator = exp_sim.sum(dim=1)\n",
    "        positive_samples = torch.cat(\n",
    "            [torch.arange(batch_size, 2 * batch_size), torch.arange(batch_size)], dim=0\n",
    "        ).to(z.device)\n",
    "        positives = similarity_matrix[torch.arange(2 * batch_size), positive_samples]\n",
    "        loss = -torch.log(torch.exp(positives) / denominator)\n",
    "        return loss.mean()"
   ],
   "id": "dbd03f603a2a8209",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dual-Stream MIL Model (DSMIL)",
   "id": "7bda39b2525a9499"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T05:58:49.797724Z",
     "start_time": "2024-12-08T05:58:49.792117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.fc = nn.Sequential(nn.Linear(input_dim, output_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "class InstanceClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super(InstanceClassifier, self).__init__()\n",
    "        self.features_extractor = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.features_extractor.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.features_extractor.fc = nn.Identity()\n",
    "        \n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, num_instances, C, H, W = x.shape\n",
    "        x = x.view(batch_size * num_instances, C, H, W)\n",
    "        \n",
    "        instance_features = nn.Dropout(0.25)(self.features_extractor(x)).view(batch_size, num_instances, -1)\n",
    "        classes = self.fc(instance_features)\n",
    "        \n",
    "        return instance_features, classes\n",
    "    \n",
    "class BagClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1, hidden_dim=128, dropout_v=0.2, non_linear=True, passing_v=False):\n",
    "        super(BagClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        if non_linear:\n",
    "            self.q = nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        else:\n",
    "            self.q = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        if passing_v:\n",
    "            self.v = nn.Sequential(\n",
    "                nn.Dropout(dropout_v),\n",
    "                nn.Linear(input_dim, input_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.v = nn.Identity()\n",
    "            \n",
    "        self.fc = FCLayer(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, features, classes):\n",
    "        batch_size = features.size(0)\n",
    "        num_instances = features.size(1)\n",
    "        features_dim = features.size(2)\n",
    "        \n",
    "        combine_features = features.view(features.shape[0] * features.shape[1], -1)\n",
    "        V = self.v(combine_features)\n",
    "        Q = self.q(combine_features)\n",
    "        assert V.shape[0] == Q.shape[0] == batch_size * num_instances, f'V: {V.shape}, Q: {Q.shape}'\n",
    "        assert V.shape[1] == features_dim, f'V: {V.shape} should be [{batch_size * num_instances}, {features_dim}]'\n",
    "        assert Q.shape[1] == self.hidden_dim, f'Q: {Q.shape} should be [{batch_size * num_instances}, {self.hidden_dim}]'\n",
    "        \n",
    "        # Get critical instance indices by squeezing classes\n",
    "        critical_indices = torch.squeeze(classes).argmax(dim=1)  # Shape [32]\n",
    "        assert critical_indices.shape[0] == batch_size, f'Critical indices: {critical_indices.shape}'\n",
    "\n",
    "        # Gather features for each batch using critical instance indices\n",
    "        m_features = features[torch.arange(batch_size).unsqueeze(1), critical_indices.unsqueeze(1)].squeeze()\n",
    "        assert m_features.shape[0] == batch_size, f'M features: {m_features.shape} should be [{batch_size}, {features_dim}]'\n",
    "        q_max = self.q(m_features)\n",
    "        assert q_max.shape[0] == batch_size and q_max.shape[1] == self.hidden_dim, f'Q max: {q_max.shape} should be [{batch_size}, {self.hidden_dim}]'\n",
    "        \n",
    "        A = torch.mm(Q, q_max.mT)\n",
    "        A = F.softmax(A / torch.sqrt(torch.tensor(Q.shape[-1]).float()), dim=0)\n",
    "        assert A.shape[0] == batch_size * num_instances and A.shape[1] == batch_size, f'A: {A.shape} should be [{batch_size * num_instances}, {batch_size}]'\n",
    "        \n",
    "        B = torch.mm(A.T, V)\n",
    "        assert B.shape[0] == batch_size and B.shape[1] == features_dim, f'B: {B.shape} should be [{batch_size}, {features_dim}]'\n",
    "        \n",
    "        B = B.view(1, B.shape[0], B.shape[1])\n",
    "        C = self.fc(B)\n",
    "        C = C.view(1, -1)\n",
    "        \n",
    "        return C, A, B"
   ],
   "id": "cd5780327a678c64",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Encoder Model",
   "id": "80b183f5701793a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T05:58:49.848281Z",
     "start_time": "2024-12-08T05:58:49.838252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, base_model, projection_dim=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = base_model\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(512, projection_dim)\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, projection_dim)\n",
    "        )\n",
    "        \n",
    "        self.instance_classifier = InstanceClassifier(512)\n",
    "        self.bag_classifier = BagClassifier(512)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, num_instances, channels, height, width = x.size()\n",
    "        \n",
    "        instances_features, classes = self.instance_classifier(x)\n",
    "        \n",
    "        features = instances_features.view(batch_size * num_instances, -1)  # Flatten to (batch_size * num_instances, feature_dim)\n",
    "        \n",
    "        projection_features = self.projection(features)\n",
    "        \n",
    "        predicted_bags, A, B = self.bag_classifier(instances_features, classes)\n",
    "        \n",
    "        return projection_features, classes, predicted_bags, A, B"
   ],
   "id": "70a7956091c803d9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Augmentation Function",
   "id": "5a2ce984e83bee14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T05:58:49.906128Z",
     "start_time": "2024-12-08T05:58:49.896358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Augmentation function\n",
    "\n",
    "# Version 1: Avg time taken: 1.7x seconds for 2 augmentations (w/o ResizedCrop)\n",
    "# def augment_batch(batch_images):\n",
    "#     batch_size, num_instances, channels, height, width = batch_images.shape\n",
    "#     aug_transform = transforms.Compose([\n",
    "#         # transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),\n",
    "#         transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4)], p=0.6),\n",
    "#         transforms.RandomGrayscale(p=0.2),\n",
    "#         transforms.Compose([transforms.ToImage(), transforms.ToDtype(torch.float32, scale=True)])\n",
    "#         # transforms.Normalize((0.1307,), (0.3081,))\n",
    "#     ])\n",
    "# \n",
    "#     # Apply transformation to each image instance in the batch\n",
    "#     augmented_batch = []\n",
    "#     for i in range(batch_size):\n",
    "#         augmented_instances = [aug_transform(transforms.ToPILImage()(img.cpu())) for img in batch_images[i]]\n",
    "#         augmented_batch.append(torch.stack(augmented_instances))\n",
    "# \n",
    "#     return torch.stack(augmented_batch).cuda()  # Move the augmented batch to GPU\n",
    "\n",
    "# Version 2: Avg time taken: 0.8 seconds for 2 augmentations (w/o ResizedCrop)\n",
    "def augment_batch(batch_images):\n",
    "    batch_size, num_instances, channels, height, width = batch_images.shape\n",
    "\n",
    "    # Define augmentation transformations using GPU-compatible operations\n",
    "    aug_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(28, scale=(0.75, 1.2), ratio=(0.75, 4.0/3.0)),\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4)], p=0.6),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        # transform.ToTensor() # Already in tensor form\n",
    "    ])\n",
    "\n",
    "    # Apply transformations directly on the tensor without converting to PIL\n",
    "    augmented_batch = torch.empty_like(batch_images)  # Preallocate memory for augmented images\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        for j in range(num_instances):\n",
    "            # Apply the transformation directly to the tensor\n",
    "            augmented_batch[i, j] = aug_transform(batch_images[i, j])\n",
    "\n",
    "    return augmented_batch.cuda()  # Move the augmented batch to GPU\n",
    "\n",
    "# def augment_batch(batch_images):\n",
    "#     batch_size, num_instances, channels, height, width = batch_images.shape\n",
    "# \n",
    "#     # Define augmentation transformations using Albumentations\n",
    "#     aug_transform = A.Compose([\n",
    "#         A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4, p=0.6),\n",
    "#         A.ToGray(p=0.2)\n",
    "#     ])\n",
    "# \n",
    "#     # Prepare a tensor for augmented images\n",
    "#     augmented_batch = torch.empty_like(batch_images)  # Preallocate memory for augmented images\n",
    "# \n",
    "#     # Apply transformations directly on the tensor without converting to PIL\n",
    "#     for i in range(batch_size):\n",
    "#         for j in range(num_instances):\n",
    "#             # Convert the image tensor to a numpy array for Albumentations\n",
    "#             img_np = batch_images[i, j].cpu().numpy().transpose(1, 2, 0)  # Change from CHW to HWC format\n",
    "#             \n",
    "#             # Apply the augmentation\n",
    "#             augmented_image = aug_transform(image=img_np)['image']\n",
    "#             \n",
    "#             # Convert back to tensor and store it in the augmented batch\n",
    "#             augmented_batch[i, j] = torch.tensor(augmented_image).permute(2, 0, 1)  # Change back to CHW format\n",
    "# \n",
    "#     return augmented_batch.cuda()  # Move the augmented batch to GPU"
   ],
   "id": "824abbbb6bcc0979",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Augmentation with Multi-scale",
   "id": "e874bb3befc172c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T05:58:49.962531Z",
     "start_time": "2024-12-08T05:58:49.951638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def augment_func_v2(batch_images):\n",
    "    batch_size, num_instances, channels, height, width = batch_images.shape\n",
    "\n",
    "    # Define augmentation transformations using GPU-compatible operations\n",
    "    aug_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(28, scale=(0.75, 1.2), ratio=(0.75, 4.0/3.0)),\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4)], p=0.6),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "    ])\n",
    "\n",
    "    # Preallocate memory for augmented images\n",
    "    augmented_batch = torch.empty((batch_size, num_instances * 4, channels, height, width), device=batch_images.device)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        for j in range(num_instances):\n",
    "            # Apply the initial transformations\n",
    "            augmented_image = aug_transform(batch_images[i, j])\n",
    "\n",
    "            # Scale the image up to 4 times its original size\n",
    "            scaled_image = torch.nn.functional.interpolate(augmented_image.unsqueeze(0), scale_factor=4, mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "            # Split the scaled image into 4 parts (assuming it is now (112, 112))\n",
    "            split_images = [\n",
    "                scaled_image[:, :scaled_image.shape[1] // 2, :scaled_image.shape[2] // 2],  # Top-left\n",
    "                scaled_image[:, :scaled_image.shape[1] // 2, scaled_image.shape[2] // 2:],  # Top-right\n",
    "                scaled_image[:, scaled_image.shape[1] // 2:, :scaled_image.shape[2] // 2],  # Bottom-left\n",
    "                scaled_image[:, scaled_image.shape[1] // 2:, scaled_image.shape[2] // 2:]   # Bottom-right\n",
    "            ]\n",
    "\n",
    "            # Fill augmented_batch with split images\n",
    "            for k in range(4):\n",
    "                augmented_batch[i, j * 4 + k] = split_images[k]\n",
    "\n",
    "    return augmented_batch.cuda()  # Move the augmented batch to GPU"
   ],
   "id": "35659d7891e02e25",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Initialization",
   "id": "862eff286e786bcf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T05:58:50.244538Z",
     "start_time": "2024-12-08T05:58:50.004979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize models, loss function, and optimizer\n",
    "base_model = models.resnet18(weights=None)\n",
    "base_model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "base_model.fc = nn.Identity()\n",
    "encoder = Encoder(base_model).cuda()\n",
    "projection_dim = 256\n",
    "ntxent_loss = NTXentLoss().cuda()"
   ],
   "id": "aa34df87541f2986",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training & Evaluation",
   "id": "2fd8f0b3fc1bc9c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T05:58:55.319613Z",
     "start_time": "2024-12-08T05:58:50.254564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training parameters\n",
    "epochs = 50\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "bceLoss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "# Training loop for contrastive learning\n",
    "for epoch in range(epochs):\n",
    "    encoder.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.cuda()  # Move the batch to GPU\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        aug1 = augment_batch(images).cuda()\n",
    "        aug2 = augment_batch(images).cuda()\n",
    "        \n",
    "        z_i, outputs_1, predicted_bags_1, _, _ = encoder(aug1)\n",
    "        z_j, outputs_2, predicted_bags_2, _, _ = encoder(aug2)\n",
    "\n",
    "        NTXLoss = ntxent_loss(z_i, z_j)\n",
    "        max_agg_1 = torch.max(outputs_1, dim=1).values.squeeze()\n",
    "        max_agg_2 = torch.max(outputs_2, dim=1).values.squeeze()\n",
    "\n",
    "        loss_max_1 = bceLoss(max_agg_1, labels.float())\n",
    "        loss_max_2 = bceLoss(max_agg_2, labels.float())\n",
    "        loss_bag_1 = bceLoss(predicted_bags_1.squeeze(), labels.float())\n",
    "        loss_bag_2 = bceLoss(predicted_bags_2.squeeze(), labels.float())\n",
    "\n",
    "        loss = 0.6 * NTXLoss + 0.1 * loss_max_1 + 0.1 * loss_max_2 + 0.1 * loss_bag_1 + 0.1 * loss_bag_2\n",
    "        loss = loss.mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate predictions and update correct predictions count\n",
    "        predicted = (torch.sigmoid(predicted_bags_1.squeeze()) > 0.5).float()  # Binary classification threshold\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate average loss and accuracy for this epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = (correct_predictions / total_samples) * 100  # Convert to percentage\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.5f}, Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "# Evaluation loop\n",
    "with torch.no_grad():\n",
    "    encoder.eval()\n",
    "    correct, total = 0, 0\n",
    "    for images, labels in eval_loader:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        z_i, output, predicted_bags, _, _ = encoder(images)\n",
    "        predicted = (torch.sigmoid(predicted_bags.squeeze()) > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(f\"Test Accuracy: {correct/total}\")"
   ],
   "id": "52689a59ab9a7caf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.95003, Accuracy: 61.76%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 18\u001B[0m\n\u001B[1;32m     15\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mcuda()\n\u001B[1;32m     17\u001B[0m aug1 \u001B[38;5;241m=\u001B[39m augment_batch(images)\u001B[38;5;241m.\u001B[39mcuda()\n\u001B[0;32m---> 18\u001B[0m aug2 \u001B[38;5;241m=\u001B[39m \u001B[43maugment_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mcuda()\n\u001B[1;32m     20\u001B[0m z_i, outputs_1, predicted_bags_1, _, _ \u001B[38;5;241m=\u001B[39m encoder(aug1)\n\u001B[1;32m     21\u001B[0m z_j, outputs_2, predicted_bags_2, _, _ \u001B[38;5;241m=\u001B[39m encoder(aug2)\n",
      "Cell \u001B[0;32mIn[6], line 40\u001B[0m, in \u001B[0;36maugment_batch\u001B[0;34m(batch_images)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(batch_size):\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_instances):\n\u001B[1;32m     39\u001B[0m         \u001B[38;5;66;03m# Apply the transformation directly to the tensor\u001B[39;00m\n\u001B[0;32m---> 40\u001B[0m         augmented_batch[i, j] \u001B[38;5;241m=\u001B[39m \u001B[43maug_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_images\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m augmented_batch\u001B[38;5;241m.\u001B[39mcuda()\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[0;34m(self, img)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[0;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torchvision/transforms/transforms.py:973\u001B[0m, in \u001B[0;36mRandomResizedCrop.forward\u001B[0;34m(self, img)\u001B[0m\n\u001B[1;32m    965\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    966\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m    967\u001B[0m \u001B[38;5;124;03m    img (PIL Image or Tensor): Image to be cropped and resized.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    970\u001B[0m \u001B[38;5;124;03m    PIL Image or Tensor: Randomly cropped and resized image.\u001B[39;00m\n\u001B[1;32m    971\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    972\u001B[0m i, j, h, w \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_params(img, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mratio)\n\u001B[0;32m--> 973\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresized_crop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mantialias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mantialias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torchvision/transforms/functional.py:650\u001B[0m, in \u001B[0;36mresized_crop\u001B[0;34m(img, top, left, height, width, size, interpolation, antialias)\u001B[0m\n\u001B[1;32m    648\u001B[0m     _log_api_usage_once(resized_crop)\n\u001B[1;32m    649\u001B[0m img \u001B[38;5;241m=\u001B[39m crop(img, top, left, height, width)\n\u001B[0;32m--> 650\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mantialias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mantialias\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    651\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torchvision/transforms/functional.py:479\u001B[0m, in \u001B[0;36mresize\u001B[0;34m(img, size, interpolation, max_size, antialias)\u001B[0m\n\u001B[1;32m    476\u001B[0m     pil_interpolation \u001B[38;5;241m=\u001B[39m pil_modes_mapping[interpolation]\n\u001B[1;32m    477\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F_pil\u001B[38;5;241m.\u001B[39mresize(img, size\u001B[38;5;241m=\u001B[39moutput_size, interpolation\u001B[38;5;241m=\u001B[39mpil_interpolation)\n\u001B[0;32m--> 479\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF_t\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mantialias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mantialias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py:465\u001B[0m, in \u001B[0;36mresize\u001B[0;34m(img, size, interpolation, antialias)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;66;03m# Define align_corners to avoid warnings\u001B[39;00m\n\u001B[1;32m    463\u001B[0m align_corners \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m interpolation \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbilinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbicubic\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 465\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[43minterpolate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malign_corners\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malign_corners\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mantialias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mantialias\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m interpolation \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbicubic\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m out_dtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39muint8:\n\u001B[1;32m    468\u001B[0m     img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mclamp(\u001B[38;5;28mmin\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mmax\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m255\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/functional.py:4077\u001B[0m, in \u001B[0;36minterpolate\u001B[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001B[0m\n\u001B[1;32m   4075\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m align_corners \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   4076\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m antialias:\n\u001B[0;32m-> 4077\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_upsample_bilinear2d_aa\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malign_corners\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_factors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4078\u001B[0m \u001B[38;5;66;03m# Two levels are necessary to prevent TorchScript from touching\u001B[39;00m\n\u001B[1;32m   4079\u001B[0m \u001B[38;5;66;03m# are_deterministic_algorithms_enabled.\u001B[39;00m\n\u001B[1;32m   4080\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_scripting():\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualizing Augmented Bags",
   "id": "450d9cf578cd11d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T05:58:55.394179119Z",
     "start_time": "2024-12-08T05:37:26.232199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_augmented_bags(original_bags, augmented_bags, num_bags=8):\n",
    "    \"\"\"\n",
    "    Visualizes original and augmented bags of images.\n",
    "\n",
    "    Parameters:\n",
    "    - original_bags: A tensor of shape (batch_size, num_instances, channels, height, width)\n",
    "    - augmented_bags: A tensor of shape (batch_size, num_instances, channels, height, width)\n",
    "    - num_bags: Number of bags to visualize.\n",
    "    \"\"\"\n",
    "    batch_size = original_bags.size(0)\n",
    "    \n",
    "    # Limit the number of bags to visualize\n",
    "    num_bags = min(num_bags, batch_size)\n",
    "\n",
    "    fig, axes = plt.subplots(num_bags, 2, figsize=(10, 2 * num_bags))\n",
    "    \n",
    "    for i in range(num_bags):\n",
    "        # Original images\n",
    "        for j in range(original_bags.size(1)):  # Iterate over instances in the bag\n",
    "            img = original_bags[i][j].cpu().numpy().squeeze()  # Remove channel dimension\n",
    "            axes[i, 0].imshow(img, cmap='gray')\n",
    "            axes[i, 0].axis('off')\n",
    "        axes[i, 0].set_title(f'Original Bag {i + 1}')\n",
    "        \n",
    "        # Augmented images\n",
    "        for j in range(augmented_bags.size(1)):\n",
    "            img = augmented_bags[i][j].cpu().numpy().squeeze()  # Remove channel dimension\n",
    "            axes[i, 1].imshow(img, cmap='gray')\n",
    "            axes[i, 1].axis('off')\n",
    "        axes[i, 1].set_title(f'Augmented Bag {i + 1}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get the first batch of images from the evaluation loader\n",
    "images, _ = next(iter(eval_loader))\n",
    "print(f'Original batch shape: {images.shape}')\n",
    "\n",
    "# Augment the batch of images\n",
    "augmented_images = augment_batch(images)\n",
    "print(f'Augmented batch shape: {augmented_images.shape}')\n",
    "\n",
    "# Visualize the original and augmented bags\n",
    "visualize_augmented_bags(images, augmented_images)"
   ],
   "id": "2d6ef0f4cc987c4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original batch shape: torch.Size([4, 8, 1, 28, 28])\n",
      "Augmented batch shape: torch.Size([4, 8, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 8 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T05:58:55.394605982Z",
     "start_time": "2024-12-08T05:37:26.700339Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2eb660a0d59d60d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
