{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "id": "90bbee99dd41f007"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:10:58.590054Z",
     "start_time": "2024-12-18T16:10:57.540163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "\n",
    "import random\n",
    "import os\n",
    "import numpy as np"
   ],
   "id": "1b2b03da333ce2a5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "ef17d380a355bbc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:10:58.601264Z",
     "start_time": "2024-12-18T16:10:58.598264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()"
   ],
   "id": "1079b53b2b0a3843",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load and Preprocess the MNIST Dataset",
   "id": "38892de2a3ff3c72"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-18T16:11:01.163503Z",
     "start_time": "2024-12-18T16:10:58.647756Z"
    }
   },
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_data, eval_data = train_test_split(mnist_data, train_size=0.3, random_state=42, stratify=mnist_data.targets)\n",
    "\n",
    "# Instance-level dataset\n",
    "class InstanceDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx]\n",
    "        return img, label\n",
    "\n",
    "# Create instance datasets\n",
    "train_dataset = InstanceDataset(train_data)\n",
    "eval_dataset = InstanceDataset(eval_data)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True, num_workers=4)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=8, shuffle=False, pin_memory=True, num_workers=4)\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NT-Xent Loss",
   "id": "b2371d158a38f07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:11:01.190968Z",
     "start_time": "2024-12-18T16:11:01.183874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorch_metric_learning import losses\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NTXentLoss(losses.NTXentLoss):\n",
    "    def __init__(self, temperature, **kwargs):\n",
    "        super().__init__(temperature=temperature, **kwargs)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, embeddings1, embeddings2, labels=None):\n",
    "        # Concatenate the embeddings\n",
    "        embeddings = torch.cat([embeddings1, embeddings2], dim=0)\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "        if labels == None:\n",
    "            # Self-supervised labels\n",
    "            labels = torch.arange(feature_vectors_normalized.size(0))\n",
    "        else:\n",
    "            # Supervised labels\n",
    "            labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "        # Compute logits\n",
    "        logits = torch.div(\n",
    "            torch.matmul(\n",
    "                feature_vectors_normalized, torch.transpose(feature_vectors_normalized, 0, 1)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "\n",
    "        if labels == None:\n",
    "            return losses.NTXentLoss(temperature=self.temperature)(logits, torch.squeeze(labels))\n",
    "        else:\n",
    "            return losses.SupConLoss(temperature=self.temperature)(logits, torch.squeeze(labels))\n",
    "\n",
    "# NT-Xent loss\n",
    "criterion = NTXentLoss(0.5)"
   ],
   "id": "8f79705d63c4aecc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Architecture",
   "id": "d5994e8e498d9697"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:11:01.231032Z",
     "start_time": "2024-12-18T16:11:01.227257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, outputs_dim):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.model.fc = nn.Identity()\n",
    "\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(512, outputs_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        projections = self.projection(x)\n",
    "\n",
    "        # Flatten the output\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x, projections"
   ],
   "id": "9fd7082da282d730",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "60a0c0d1ec280a18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:11:01.278031Z",
     "start_time": "2024-12-18T16:11:01.274018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Version 2: Avg time taken: 0.8 seconds for 2 augmentations (w/o ResizedCrop)\n",
    "def augment_batch(batch_images):\n",
    "    batch_size, channels, height, width = batch_images.shape\n",
    "\n",
    "    # Define augmentation transformations using GPU-compatible operations\n",
    "    aug_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(28, scale=(0.75, 1.2), ratio=(0.75, 4.0/3.0)),\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4)], p=0.6),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "    ])\n",
    "\n",
    "    # Apply transformations directly on the tensor without converting to PIL\n",
    "    augmented_batch = torch.empty_like(batch_images)  # Preallocate memory for augmented images\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        augmented_batch[i] = aug_transform(batch_images[i])\n",
    "    return augmented_batch.cuda()  # Move the augmented batch to GPU"
   ],
   "id": "7c954a6caa9bfb88",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:11:01.493309Z",
     "start_time": "2024-12-18T16:11:01.320233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Encoder(outputs_dim=10).to(device)\n",
    "criterion_cl = NTXentLoss(0.5)\n",
    "criterion_sl = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "b56c5eb81e6f04c5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        aug1 = augment_batch(images).cuda()\n",
    "        aug2 = augment_batch(images).cuda()\n",
    "\n",
    "        outputs1, proj1 = model(aug1)\n",
    "        outputs2, proj2 = model(aug2)\n",
    "\n",
    "        loss_cl = criterion_cl(proj1, proj2, labels)\n",
    "\n",
    "        loss_sl_1 = criterion_sl(outputs1, labels)\n",
    "        loss_sl_2 = criterion_sl(outputs2, labels)\n",
    "\n",
    "        loss = 0.6 * loss_cl + 0.2 * loss_sl_1 + 0.2 * loss_sl_2\n",
    "        # loss = 0.5 * loss_sl_1 + 0.5 * loss_sl_2\n",
    "        loss = loss.mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in eval_loader:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs, _ = model(images)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f'Epoch [{epoch}/{10}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')"
   ],
   "id": "39ba2d8efb943850"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Results",
   "id": "816d706065a06a1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:15:14.339281Z",
     "start_time": "2024-12-18T16:11:36.439877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Stage 1: Pre-training with Supervised Contrastive Learning\n",
    "for epoch in range(10):  # Adjust epochs as needed for pre-training\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        aug1 = augment_batch(images).cuda()\n",
    "        aug2 = augment_batch(images).cuda()\n",
    "\n",
    "        outputs1, proj1 = model(aug1)\n",
    "        outputs2, proj2 = model(aug2)\n",
    "\n",
    "        loss_cl = criterion_cl(proj1, proj2)\n",
    "\n",
    "        loss_cl.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation phase for contrastive learning\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in eval_loader:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs, _ = model(images)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f'Stage 1 - Epoch [{epoch}/{10}], Contrastive Loss: {loss_cl.item():.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "\n",
    "# Stage 2: Fine-tuning with CrossEntropy Loss\n",
    "for epoch in range(10):  # Adjust epochs as needed for fine-tuning\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        outputs, _ = model(images)  # Only use the main output for classification\n",
    "\n",
    "        loss_sl = criterion_sl(outputs, labels)\n",
    "\n",
    "        loss_sl.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation phase for classification\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in eval_loader:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs, _ = model(images)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f'Stage 2 - Epoch [{epoch}/{10}], Classification Loss: {loss_sl.item():.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')"
   ],
   "id": "a9fe3a8ebdf5e057",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 - Epoch [0/10], Contrastive Loss: 0.0000, Accuracy: 0.1078, Precision: 0.1048, Recall: 0.1078, F1 Score: 0.0788\n",
      "Stage 1 - Epoch [1/10], Contrastive Loss: 0.0000, Accuracy: 0.1076, Precision: 0.0985, Recall: 0.1076, F1 Score: 0.0754\n",
      "Stage 1 - Epoch [2/10], Contrastive Loss: 0.0000, Accuracy: 0.1066, Precision: 0.1020, Recall: 0.1066, F1 Score: 0.0740\n",
      "Stage 1 - Epoch [3/10], Contrastive Loss: 0.0000, Accuracy: 0.1089, Precision: 0.0963, Recall: 0.1089, F1 Score: 0.0776\n",
      "Stage 1 - Epoch [4/10], Contrastive Loss: 0.0000, Accuracy: 0.1072, Precision: 0.1025, Recall: 0.1072, F1 Score: 0.0774\n",
      "Stage 1 - Epoch [5/10], Contrastive Loss: 0.0000, Accuracy: 0.1090, Precision: 0.1009, Recall: 0.1090, F1 Score: 0.0768\n",
      "Stage 1 - Epoch [6/10], Contrastive Loss: 0.0000, Accuracy: 0.1135, Precision: 0.1164, Recall: 0.1135, F1 Score: 0.0825\n",
      "Stage 1 - Epoch [7/10], Contrastive Loss: 0.0000, Accuracy: 0.1109, Precision: 0.1143, Recall: 0.1109, F1 Score: 0.0801\n",
      "Stage 1 - Epoch [8/10], Contrastive Loss: 0.0000, Accuracy: 0.1127, Precision: 0.1006, Recall: 0.1127, F1 Score: 0.0757\n",
      "Stage 1 - Epoch [9/10], Contrastive Loss: 0.0000, Accuracy: 0.1081, Precision: 0.1061, Recall: 0.1081, F1 Score: 0.0758\n",
      "Stage 2 - Epoch [0/10], Classification Loss: 0.0335, Accuracy: 0.9733, Precision: 0.9735, Recall: 0.9733, F1 Score: 0.9733\n",
      "Stage 2 - Epoch [1/10], Classification Loss: 0.5819, Accuracy: 0.9702, Precision: 0.9710, Recall: 0.9702, F1 Score: 0.9703\n",
      "Stage 2 - Epoch [2/10], Classification Loss: 0.0183, Accuracy: 0.9586, Precision: 0.9607, Recall: 0.9586, F1 Score: 0.9585\n",
      "Stage 2 - Epoch [3/10], Classification Loss: 0.1638, Accuracy: 0.9768, Precision: 0.9771, Recall: 0.9768, F1 Score: 0.9768\n",
      "Stage 2 - Epoch [4/10], Classification Loss: 0.0054, Accuracy: 0.9768, Precision: 0.9770, Recall: 0.9768, F1 Score: 0.9768\n",
      "Stage 2 - Epoch [5/10], Classification Loss: 0.0620, Accuracy: 0.9829, Precision: 0.9831, Recall: 0.9829, F1 Score: 0.9829\n",
      "Stage 2 - Epoch [6/10], Classification Loss: 0.0100, Accuracy: 0.9815, Precision: 0.9817, Recall: 0.9815, F1 Score: 0.9815\n",
      "Stage 2 - Epoch [7/10], Classification Loss: 0.0030, Accuracy: 0.9795, Precision: 0.9798, Recall: 0.9795, F1 Score: 0.9795\n",
      "Stage 2 - Epoch [8/10], Classification Loss: 0.0074, Accuracy: 0.9778, Precision: 0.9784, Recall: 0.9778, F1 Score: 0.9778\n",
      "Stage 2 - Epoch [9/10], Classification Loss: 0.0240, Accuracy: 0.9819, Precision: 0.9822, Recall: 0.9819, F1 Score: 0.9819\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1e740b043dd726aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4ec5395091a2002",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c6f0a5c79365bb2b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
