{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "id": "90bbee99dd41f007"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T05:31:19.976761Z",
     "start_time": "2024-12-19T05:31:18.921560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "\n",
    "import random\n",
    "import os\n",
    "import numpy as np"
   ],
   "id": "1b2b03da333ce2a5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "ef17d380a355bbc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T05:31:19.983794Z",
     "start_time": "2024-12-19T05:31:19.980306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()"
   ],
   "id": "1079b53b2b0a3843",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load and Preprocess the MNIST Dataset",
   "id": "38892de2a3ff3c72"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-19T05:31:22.439946Z",
     "start_time": "2024-12-19T05:31:20.025973Z"
    }
   },
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_data, eval_data = train_test_split(mnist_data, train_size=0.3, random_state=42, stratify=mnist_data.targets)\n",
    "\n",
    "# Instance-level dataset\n",
    "class InstanceDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx]\n",
    "        return img, label\n",
    "\n",
    "# Create instance datasets\n",
    "train_dataset = InstanceDataset(train_data)\n",
    "eval_dataset = InstanceDataset(eval_data)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True, num_workers=4)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=8, shuffle=False, pin_memory=True, num_workers=4)\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NT-Xent Loss",
   "id": "b2371d158a38f07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T05:31:22.468086Z",
     "start_time": "2024-12-19T05:31:22.460337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorch_metric_learning import losses, miners\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NTXentLoss(losses.NTXentLoss):\n",
    "    def __init__(self, temperature, **kwargs):\n",
    "        super().__init__(temperature=temperature, **kwargs)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, embeddings1, embeddings2, labels=None, hard_pairs=None):\n",
    "        # Concatenate the embeddings\n",
    "        embeddings = torch.cat([embeddings1, embeddings2], dim=0)\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "        if labels == None:\n",
    "            # Self-supervised labels\n",
    "            labels = torch.arange(feature_vectors_normalized.size(0))\n",
    "        else:\n",
    "            # Supervised labels\n",
    "            labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "        # Compute logits\n",
    "        logits = torch.div(\n",
    "            torch.matmul(\n",
    "                feature_vectors_normalized, torch.transpose(feature_vectors_normalized, 0, 1)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "\n",
    "        if labels == None:\n",
    "            return losses.NTXentLoss(temperature=self.temperature)(logits, torch.squeeze(labels))\n",
    "        else:\n",
    "            return losses.SupConLoss(temperature=self.temperature)(logits, torch.squeeze(labels), hard_pairs)\n",
    "\n",
    "# NT-Xent loss\n",
    "criterion = NTXentLoss(0.5)"
   ],
   "id": "8f79705d63c4aecc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Architecture",
   "id": "d5994e8e498d9697"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T05:31:22.506842Z",
     "start_time": "2024-12-19T05:31:22.503546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, outputs_dim):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.model.fc = nn.Identity()\n",
    "\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(512, outputs_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        projections = self.projection(x)\n",
    "\n",
    "        # Flatten the output\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x, projections"
   ],
   "id": "9fd7082da282d730",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "60a0c0d1ec280a18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T05:31:22.558584Z",
     "start_time": "2024-12-19T05:31:22.552719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Version 2: Avg time taken: 0.8 seconds for 2 augmentations (w/o ResizedCrop)\n",
    "def augment_batch(batch_images):\n",
    "    batch_size, channels, height, width = batch_images.shape\n",
    "\n",
    "    # Define augmentation transformations using GPU-compatible operations\n",
    "    aug_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(28, scale=(0.75, 1.2), ratio=(0.75, 4.0/3.0)),\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4)], p=0.6),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "    ])\n",
    "\n",
    "    # Apply transformations directly on the tensor without converting to PIL\n",
    "    augmented_batch = torch.empty_like(batch_images)  # Preallocate memory for augmented images\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        augmented_batch[i] = aug_transform(batch_images[i])\n",
    "    return augmented_batch.cuda()  # Move the augmented batch to GPU"
   ],
   "id": "7c954a6caa9bfb88",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T05:31:22.799965Z",
     "start_time": "2024-12-19T05:31:22.604614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Encoder(outputs_dim=10).to(device)\n",
    "criterion_cl = NTXentLoss(0.5)\n",
    "criterion_sl = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "b56c5eb81e6f04c5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T05:31:22.819523Z",
     "start_time": "2024-12-19T05:31:22.817432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorch_metric_learning.miners import BaseMiner\n",
    "from pytorch_metric_learning.utils import loss_and_miner_utils as lmu\n",
    "\n",
    "class ExamplePairMiner(BaseMiner):\n",
    "    def __init__(self, margin=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.margin = margin\n",
    "\n",
    "    def mine(self, embeddings, labels, ref_emb, ref_labels):\n",
    "        mat = self.distance(embeddings, ref_emb)\n",
    "        a1, p, a2, n = lmu.get_all_pairs_indices(labels, ref_labels)\n",
    "        pos_pairs = mat[a1, p]\n",
    "        neg_pairs = mat[a2, n]\n",
    "        pos_mask = (\n",
    "            pos_pairs < self.margin\n",
    "            if self.distance.is_inverted\n",
    "            else pos_pairs > self.margin\n",
    "        )\n",
    "        neg_mask = (\n",
    "            neg_pairs > self.margin\n",
    "            if self.distance.is_inverted\n",
    "            else neg_pairs < self.margin\n",
    "        )\n",
    "        return a1[pos_mask], p[pos_mask], a2[neg_mask], n[neg_mask]"
   ],
   "id": "f64742b5044f9583",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T05:33:44.744677Z",
     "start_time": "2024-12-19T05:31:22.865398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        aug1 = augment_batch(images).cuda()\n",
    "        aug2 = augment_batch(images).cuda()\n",
    "\n",
    "        outputs1, proj1 = model(aug1)\n",
    "        outputs2, proj2 = model(aug2)\n",
    "\n",
    "        # miner_func = miners.BaseMiner()\n",
    "        # hard_pairs = miner_func(embeddings=torch.cat([proj1, proj2], dim=0), labels=torch.cat([labels, labels], dim=0))\n",
    "        miner_func = ExamplePairMiner()\n",
    "        hard_pairs = miner_func(torch.cat([proj1, proj2], dim=0), torch.cat([labels, labels], dim=0))\n",
    "\n",
    "        loss_cl = criterion_cl(proj1, proj2, labels, hard_pairs)\n",
    "\n",
    "        loss_sl_1 = criterion_sl(outputs1, labels)\n",
    "        loss_sl_2 = criterion_sl(outputs2, labels)\n",
    "\n",
    "        loss = 0.6 * loss_cl + 0.2 * loss_sl_1 + 0.2 * loss_sl_2\n",
    "        # loss = 0.5 * loss_sl_1 + 0.5 * loss_sl_2\n",
    "        loss = loss.mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in eval_loader:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs, _ = model(images)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f'Epoch [{epoch}/{10}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')"
   ],
   "id": "39ba2d8efb943850",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10], Loss: 0.1636, Accuracy: 0.9600, Precision: 0.9615, Recall: 0.9600, F1 Score: 0.9601\n",
      "Epoch [1/10], Loss: 0.0111, Accuracy: 0.9606, Precision: 0.9640, Recall: 0.9606, F1 Score: 0.9612\n",
      "Epoch [2/10], Loss: 0.0098, Accuracy: 0.9764, Precision: 0.9771, Recall: 0.9764, F1 Score: 0.9764\n",
      "Epoch [3/10], Loss: 0.0130, Accuracy: 0.9846, Precision: 0.9848, Recall: 0.9846, F1 Score: 0.9846\n",
      "Epoch [4/10], Loss: 0.0220, Accuracy: 0.9806, Precision: 0.9813, Recall: 0.9806, F1 Score: 0.9808\n",
      "Epoch [5/10], Loss: 0.0065, Accuracy: 0.9845, Precision: 0.9847, Recall: 0.9845, F1 Score: 0.9845\n",
      "Epoch [6/10], Loss: 0.0491, Accuracy: 0.9881, Precision: 0.9882, Recall: 0.9881, F1 Score: 0.9881\n",
      "Epoch [7/10], Loss: 0.0197, Accuracy: 0.9762, Precision: 0.9769, Recall: 0.9762, F1 Score: 0.9761\n",
      "Epoch [8/10], Loss: 0.0220, Accuracy: 0.9863, Precision: 0.9865, Recall: 0.9863, F1 Score: 0.9863\n",
      "Epoch [9/10], Loss: 0.0001, Accuracy: 0.9869, Precision: 0.9870, Recall: 0.9869, F1 Score: 0.9869\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Results",
   "id": "816d706065a06a1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T05:37:32.329491Z",
     "start_time": "2024-12-19T05:33:44.829749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Stage 1: Pre-training with Supervised Contrastive Learning\n",
    "for epoch in range(10):  # Adjust epochs as needed for pre-training\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        aug1 = augment_batch(images).cuda()\n",
    "        aug2 = augment_batch(images).cuda()\n",
    "\n",
    "        outputs1, proj1 = model(aug1)\n",
    "        outputs2, proj2 = model(aug2)\n",
    "\n",
    "        loss_cl = criterion_cl(proj1, proj2)\n",
    "\n",
    "        loss_cl.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation phase for contrastive learning\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in eval_loader:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs, _ = model(images)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f'Stage 1 - Epoch [{epoch}/{10}], Contrastive Loss: {loss_cl.item():.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "\n",
    "# Stage 2: Fine-tuning with CrossEntropy Loss\n",
    "for epoch in range(10):  # Adjust epochs as needed for fine-tuning\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        outputs, _ = model(images)  # Only use the main output for classification\n",
    "\n",
    "        loss_sl = criterion_sl(outputs, labels)\n",
    "\n",
    "        loss_sl.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation phase for classification\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in eval_loader:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs, _ = model(images)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f'Stage 2 - Epoch [{epoch}/{10}], Classification Loss: {loss_sl.item():.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')"
   ],
   "id": "a9fe3a8ebdf5e057",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 - Epoch [0/10], Contrastive Loss: 0.0000, Accuracy: 0.9871, Precision: 0.9872, Recall: 0.9871, F1 Score: 0.9871\n",
      "Stage 1 - Epoch [1/10], Contrastive Loss: 0.0000, Accuracy: 0.9868, Precision: 0.9869, Recall: 0.9868, F1 Score: 0.9868\n",
      "Stage 1 - Epoch [2/10], Contrastive Loss: 0.0000, Accuracy: 0.9863, Precision: 0.9864, Recall: 0.9863, F1 Score: 0.9863\n",
      "Stage 1 - Epoch [3/10], Contrastive Loss: 0.0000, Accuracy: 0.9866, Precision: 0.9867, Recall: 0.9866, F1 Score: 0.9866\n",
      "Stage 1 - Epoch [4/10], Contrastive Loss: 0.0000, Accuracy: 0.9853, Precision: 0.9855, Recall: 0.9853, F1 Score: 0.9853\n",
      "Stage 1 - Epoch [5/10], Contrastive Loss: 0.0000, Accuracy: 0.9860, Precision: 0.9862, Recall: 0.9860, F1 Score: 0.9860\n",
      "Stage 1 - Epoch [6/10], Contrastive Loss: 0.0000, Accuracy: 0.9848, Precision: 0.9850, Recall: 0.9848, F1 Score: 0.9848\n",
      "Stage 1 - Epoch [7/10], Contrastive Loss: 0.0000, Accuracy: 0.9869, Precision: 0.9870, Recall: 0.9869, F1 Score: 0.9869\n",
      "Stage 1 - Epoch [8/10], Contrastive Loss: 0.0000, Accuracy: 0.9859, Precision: 0.9860, Recall: 0.9859, F1 Score: 0.9859\n",
      "Stage 1 - Epoch [9/10], Contrastive Loss: 0.0000, Accuracy: 0.9858, Precision: 0.9860, Recall: 0.9858, F1 Score: 0.9858\n",
      "Stage 2 - Epoch [0/10], Classification Loss: 1.0199, Accuracy: 0.9855, Precision: 0.9856, Recall: 0.9855, F1 Score: 0.9855\n",
      "Stage 2 - Epoch [1/10], Classification Loss: 0.0146, Accuracy: 0.9824, Precision: 0.9826, Recall: 0.9824, F1 Score: 0.9823\n",
      "Stage 2 - Epoch [2/10], Classification Loss: 0.0020, Accuracy: 0.9860, Precision: 0.9861, Recall: 0.9860, F1 Score: 0.9860\n",
      "Stage 2 - Epoch [3/10], Classification Loss: 0.0067, Accuracy: 0.9849, Precision: 0.9851, Recall: 0.9849, F1 Score: 0.9849\n",
      "Stage 2 - Epoch [4/10], Classification Loss: 0.1803, Accuracy: 0.9894, Precision: 0.9894, Recall: 0.9894, F1 Score: 0.9894\n",
      "Stage 2 - Epoch [5/10], Classification Loss: 0.0123, Accuracy: 0.9880, Precision: 0.9881, Recall: 0.9880, F1 Score: 0.9880\n",
      "Stage 2 - Epoch [6/10], Classification Loss: 0.0011, Accuracy: 0.9878, Precision: 0.9878, Recall: 0.9878, F1 Score: 0.9878\n",
      "Stage 2 - Epoch [7/10], Classification Loss: 0.0239, Accuracy: 0.9780, Precision: 0.9787, Recall: 0.9780, F1 Score: 0.9779\n",
      "Stage 2 - Epoch [8/10], Classification Loss: 0.0009, Accuracy: 0.9906, Precision: 0.9906, Recall: 0.9906, F1 Score: 0.9906\n",
      "Stage 2 - Epoch [9/10], Classification Loss: 0.0049, Accuracy: 0.9816, Precision: 0.9819, Recall: 0.9816, F1 Score: 0.9816\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T05:37:32.372108Z",
     "start_time": "2024-12-19T05:37:32.371040Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1e740b043dd726aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T05:37:32.415253Z",
     "start_time": "2024-12-19T05:37:32.413890Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4ec5395091a2002",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T05:37:32.459577Z",
     "start_time": "2024-12-19T05:37:32.458413Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c6f0a5c79365bb2b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
