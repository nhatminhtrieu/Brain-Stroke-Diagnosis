{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "from pyexpat import features\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, Dataset, Subset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "# Constants\n",
    "RANDOM_SEED = 42\n",
    "TRAIN_VAL_SPLIT_RATIO = 0.7\n",
    "SUBSET_RATIO = 0.1\n",
    "BAG_SIZE = 8\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = True\n",
    "INPUT_DIM = 512\n",
    "OUTPUT_DIM = 1\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-11-21T14:12:49.114945Z",
     "iopub.execute_input": "2024-11-21T14:12:49.115281Z",
     "iopub.status.idle": "2024-11-21T14:12:53.847497Z",
     "shell.execute_reply.started": "2024-11-21T14:12:49.115249Z",
     "shell.execute_reply": "2024-11-21T14:12:53.846799Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T06:13:19.563721Z",
     "start_time": "2024-11-29T06:13:18.430612Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "# Set random seed for reproducibility\nrandom.seed(RANDOM_SEED)\ntorch.cuda.manual_seed_all(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\n\n# Ensure deterministic behavior for CUDA operations\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-21T14:12:53.848913Z",
     "iopub.execute_input": "2024-11-21T14:12:53.849265Z",
     "iopub.status.idle": "2024-11-21T14:12:53.859265Z",
     "shell.execute_reply.started": "2024-11-21T14:12:53.849239Z",
     "shell.execute_reply": "2024-11-21T14:12:53.858683Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T06:13:19.569693Z",
     "start_time": "2024-11-29T06:13:19.567018Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "# Data transformation\ntransform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n\n# Dataset preparation\nmnist_train = datasets.MNIST(root='data', train=True, download=True, transform=transform)\nmnist_test = datasets.MNIST(root='data', train=False, download=True, transform=transform)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-21T14:12:53.860334Z",
     "iopub.execute_input": "2024-11-21T14:12:53.860615Z",
     "iopub.status.idle": "2024-11-21T14:12:59.169627Z",
     "shell.execute_reply.started": "2024-11-21T14:12:53.860591Z",
     "shell.execute_reply": "2024-11-21T14:12:59.168696Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T06:13:19.648415Z",
     "start_time": "2024-11-29T06:13:19.611436Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "# Subset and splitting data\nsubset_size = int(SUBSET_RATIO * len(mnist_train))\nsubset_indices = torch.randperm(len(mnist_train))[:subset_size]\nmnist_train_subset = Subset(mnist_train, subset_indices)\n\ntrain_size = int(TRAIN_VAL_SPLIT_RATIO * len(mnist_train_subset))\nval_size = len(mnist_train_subset) - train_size\ntrain_dataset, val_dataset = random_split(mnist_train_subset, [train_size, val_size])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-21T14:12:59.172109Z",
     "iopub.execute_input": "2024-11-21T14:12:59.172701Z",
     "iopub.status.idle": "2024-11-21T14:12:59.197944Z",
     "shell.execute_reply.started": "2024-11-21T14:12:59.172659Z",
     "shell.execute_reply": "2024-11-21T14:12:59.197010Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T06:13:19.660200Z",
     "start_time": "2024-11-29T06:13:19.658045Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "class BagDataset(Dataset):\n    def __init__(self, dataset, bag_size=BAG_SIZE):\n        self.dataset = dataset\n        self.bag_size = bag_size\n\n    def __len__(self):\n        return len(self.dataset) // self.bag_size\n\n    def __getitem__(self, idx):\n        bag_images = []\n        bag_labels = []\n\n        for i in range(self.bag_size):\n            img, label = self.dataset[idx * self.bag_size + i]\n            bag_images.append(img)\n            bag_labels.append(label)\n        \n        bag_images = torch.stack(bag_images)\n        bag_label = 1 if 9 in bag_labels else 0\n\n        return bag_images, bag_label",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-21T14:12:59.199216Z",
     "iopub.execute_input": "2024-11-21T14:12:59.199575Z",
     "iopub.status.idle": "2024-11-21T14:12:59.216780Z",
     "shell.execute_reply.started": "2024-11-21T14:12:59.199520Z",
     "shell.execute_reply": "2024-11-21T14:12:59.215947Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T06:13:19.711663Z",
     "start_time": "2024-11-29T06:13:19.704350Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "class BagDataLoader:\n    def __init__(self, dataset, bag_size, batch_size, shuffle=True, num_workers=0, pin_memory=False, drop_last=False):\n        self.bag_dataset = BagDataset(dataset, bag_size)\n        self.loader = DataLoader(\n            self.bag_dataset,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            num_workers=num_workers,\n            pin_memory=pin_memory,\n            drop_last=drop_last\n        )\n\n    def get_loader(self):\n        return self.loader",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-21T14:12:59.217724Z",
     "iopub.execute_input": "2024-11-21T14:12:59.217955Z",
     "iopub.status.idle": "2024-11-21T14:12:59.230471Z",
     "shell.execute_reply.started": "2024-11-21T14:12:59.217932Z",
     "shell.execute_reply": "2024-11-21T14:12:59.229710Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T06:13:19.762968Z",
     "start_time": "2024-11-29T06:13:19.756488Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "def create_bag_loader(dataset, bag_size, batch_size, shuffle, num_workers, pin_memory, drop_last):\n    return BagDataLoader(\n        dataset=dataset,\n        bag_size=bag_size,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        drop_last=drop_last\n    ).get_loader()\n\ntrain_loader = create_bag_loader(\n    train_dataset, BAG_SIZE, BATCH_SIZE, shuffle=True,\n    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=True\n)\n\nval_loader = create_bag_loader(\n    val_dataset, BAG_SIZE, BATCH_SIZE, shuffle=False,\n    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=True\n)\n\ntest_loader = create_bag_loader(\n    mnist_test, BAG_SIZE, BATCH_SIZE, shuffle=False,\n    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=True\n)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-21T14:12:59.231520Z",
     "iopub.execute_input": "2024-11-21T14:12:59.231866Z",
     "iopub.status.idle": "2024-11-21T14:12:59.241617Z",
     "shell.execute_reply.started": "2024-11-21T14:12:59.231828Z",
     "shell.execute_reply": "2024-11-21T14:12:59.240911Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T06:13:19.816714Z",
     "start_time": "2024-11-29T06:13:19.808361Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": "# Model configurations",
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dual-Stream Multiple Instance Learning (DSMIL)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T06:13:19.883296Z",
     "start_time": "2024-11-29T06:13:19.861367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.fc = nn.Sequential(nn.Linear(input_dim, output_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "class InstanceClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super(InstanceClassifier, self).__init__()\n",
    "        self.features_extractor = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        self.features_extractor.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.features_extractor.fc = nn.Identity()\n",
    "        \n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, num_instances, C, H, W = x.shape\n",
    "        x = x.view(batch_size * num_instances, C, H, W)\n",
    "        \n",
    "        instance_features = self.features_extractor(x).view(batch_size, num_instances, -1)\n",
    "        classes = self.fc(instance_features)\n",
    "        \n",
    "        return instance_features, classes\n",
    "    \n",
    "class BagClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1, hidden_dim=128, dropout_v=0.2, non_linear=True, passing_v=False):\n",
    "        super(BagClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        if non_linear:\n",
    "            self.q = nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        else:\n",
    "            self.q = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        if passing_v:\n",
    "            self.v = nn.Sequential(\n",
    "                nn.Dropout(dropout_v),\n",
    "                nn.Linear(input_dim, input_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.v = nn.Identity()\n",
    "            \n",
    "        self.fc = FCLayer(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, features, classes):\n",
    "        batch_size = features.size(0)\n",
    "        num_instances = features.size(1)\n",
    "        features_dim = features.size(2)\n",
    "        \n",
    "        combine_features = features.view(features.shape[0] * features.shape[1], -1)\n",
    "        V = self.v(combine_features)\n",
    "        Q = self.q(combine_features)\n",
    "        assert V.shape[0] == Q.shape[0] == batch_size * num_instances, f'V: {V.shape}, Q: {Q.shape}'\n",
    "        assert V.shape[1] == features_dim, f'V: {V.shape} should be [{batch_size * num_instances}, {features_dim}]'\n",
    "        assert Q.shape[1] == self.hidden_dim, f'Q: {Q.shape} should be [{batch_size * num_instances}, {self.hidden_dim}]'\n",
    "        \n",
    "        # Get critical instance indices by squeezing classes\n",
    "        critical_indices = torch.squeeze(classes).argmax(dim=1)  # Shape [32]\n",
    "        assert critical_indices.shape[0] == batch_size, f'Critical indices: {critical_indices.shape}'\n",
    "\n",
    "        # Gather features for each batch using critical instance indices\n",
    "        m_features = features[torch.arange(batch_size).unsqueeze(1), critical_indices.unsqueeze(1)].squeeze()\n",
    "        assert m_features.shape[0] == batch_size, f'M features: {m_features.shape} should be [{batch_size}, {features_dim}]'\n",
    "        q_max = self.q(m_features)\n",
    "        assert q_max.shape[0] == batch_size and q_max.shape[1] == self.hidden_dim, f'Q max: {q_max.shape} should be [{batch_size}, {self.hidden_dim}]'\n",
    "        \n",
    "        A = torch.mm(Q, q_max.mT)\n",
    "        A = F.softmax(A / torch.sqrt(torch.tensor(Q.shape[-1]).float()), dim=0)\n",
    "        assert A.shape[0] == batch_size * num_instances and A.shape[1] == batch_size, f'A: {A.shape} should be [{batch_size * num_instances}, {batch_size}]'\n",
    "        \n",
    "        B = torch.mm(A.T, V)\n",
    "        assert B.shape[0] == batch_size and B.shape[1] == features_dim, f'B: {B.shape} should be [{batch_size}, {features_dim}]'\n",
    "        \n",
    "        B = B.view(1, B.shape[0], B.shape[1])\n",
    "        C = self.fc(B)\n",
    "        C = C.view(1, -1)\n",
    "        \n",
    "        return C, A, B\n",
    "    \n",
    "class MILNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super(MILNetwork, self).__init__()\n",
    "        self.instance_classifier = InstanceClassifier(input_dim)\n",
    "        self.bag_classifier = BagClassifier(input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        instance_features, classes = self.instance_classifier(x)\n",
    "        predicted_bags, A, B = self.bag_classifier(instance_features, classes)\n",
    "        \n",
    "        return classes, predicted_bags, A, B"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Attention Layer"
  },
  {
   "cell_type": "code",
   "source": [
    "class SecondStreamDSMIL(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SecondStreamDSMIL, self).__init__()\n",
    "\n",
    "        self.W_q = nn.Linear(input_dim, input_dim)\n",
    "        self.W_v = nn.Linear(input_dim, input_dim)\n",
    "        self.W_b = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "        # You can choose any activation function here\n",
    "        self.activation = nn.ReLU()  # Example: using ReLU\n",
    "\n",
    "    def forward(self, B):\n",
    "        # Linear transformations followed by non-linear activation\n",
    "        q = self.activation(self.W_q(B))\n",
    "        v = self.activation(self.W_v(B))\n",
    "\n",
    "        # Max pooling over the value vectors\n",
    "        h_m = torch.max(v, dim=0)[0]\n",
    "\n",
    "        # Compute cosine similarity and attention weights\n",
    "        U = F.softmax(F.cosine_similarity(q.unsqueeze(1), h_m.unsqueeze(0), dim=-1), dim=1).unsqueeze(-1)\n",
    "\n",
    "        # Weighted sum of values\n",
    "        return self.W_b(torch.sum(U * v, dim=1))\n",
    "\n",
    "\n",
    "# class SecondStreamDSMIL(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim):\n",
    "#         super(SecondStreamDSMIL, self).__init__()\n",
    "# \n",
    "#         self.W_q = nn.Linear(input_dim, input_dim)\n",
    "#         self.W_v = nn.Linear(input_dim, input_dim)\n",
    "#         self.W_b = nn.Linear(input_dim, output_dim)\n",
    "# \n",
    "#     def forward(self, B):\n",
    "#         h_m = torch.max(B @ self.W_v.weight.T, dim=0)[0]\n",
    "#         q, v = self.W_q(B), self.W_v(B)\n",
    "#         U = F.softmax(F.cosine_similarity(q.unsqueeze(1), h_m.unsqueeze(0), dim=-1), dim=1).unsqueeze(-1)\n",
    "#         return self.W_b(torch.sum(U * v, dim=1))\n",
    "\n",
    "# class SecondStreamDSMIL(nn.Module):\n",
    "#     def __init__(self, input_dim, output_class, non_linear=True, passing_v=False, dropout_v=0.2):\n",
    "#         super(SecondStreamDSMIL, self).__init__()\n",
    "#         if non_linear:\n",
    "#             self.q = nn.Sequential(\n",
    "#                 nn.Linear(input_dim, 128),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(128, 128),\n",
    "#                 nn.Tanh())\n",
    "#         else:\n",
    "#             self.q = nn.Linear(input_dim, 128)\n",
    "# \n",
    "#         if passing_v:\n",
    "#             self.v = nn.Sequential(\n",
    "#                 nn.Dropout(dropout_v),\n",
    "#                 nn.Linear(input_dim, input_dim),\n",
    "#                 nn.ReLU())\n",
    "#         else:\n",
    "#             self.v = nn.Identity()\n",
    "# \n",
    "#         # 1D Convolutional layer that can handle multiple classes (including binary)\n",
    "#         self.fcc = nn.Conv1d(output_class, output_class, kernel_size=input_dim)\n",
    "# \n",
    "#     def forward(self, features, classes): # N * K, N * C\n",
    "#         V = self.v(features) # N * V, unsorted\n",
    "#         Q = self.q(features).view(features.shape[0], -1) # N * Q, unsorted \n",
    "#         print(f'Shape of V: {V.shape}, Q: {Q.shape}')\n",
    "# \n",
    "#         # handle multiple classes\n",
    "#         _, m_indices = torch.sort(classes, 0,descending=True) # sort class scores along the instance dimension, m_indices in shape N x C\n",
    "#         print(f'Shape of m_indices: {m_indices.shape}')\n",
    "#         m_features = torch.index_select(features, dim=0, index=m_indices[0, :]) # Select critical instances based on class scores, m_features in shape C x K\n",
    "#         print(f'Shape of m_features: {m_features.shape}')\n",
    "#         q_max = self.q(m_features) # Extract features from critical instances, q_max in shape C x Q\n",
    "#         print(f'Shape of q_max: {q_max.shape}')\n",
    "#         A = torch.mm(Q, q_max.T) # Compute attention weights, A in shape N x C\n",
    "#         print(f'Shape of A after mm: {A.shape}') \n",
    "#         A = F.softmax(A / torch.sqrt(torch.tensor(Q.shape[-1]).float()), dim=0) # normalize attention scores, A in shape N x C,\n",
    "#         print(f'Shape of A after softmax: {A.shape}')\n",
    "#         B = torch.mm(A.T, V) # compute bag representation, B in shape C x V\n",
    "#         print(f'Shape of B after mm: {B.shape}')\n",
    "# \n",
    "#         B = B.view(1, B.shape[0], B.shape[1]) # 1 x C x V\n",
    "#         print(f'Shape of B after view: {B.shape}')\n",
    "#         C = self.fcc(B) # 1 x C x 1\n",
    "#         print(f'Shape of C after fcc: {C.shape}')\n",
    "#         print(f'C after fcc: {C}')\n",
    "#         C = C.view(1, -1)\n",
    "#         print(f'Shape of C after view: {C.shape}')\n",
    "#         return C, A, B \n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "          nn.Linear(input_dim, hidden_dim), # in = out\n",
    "          nn.PReLU(),\n",
    "          nn.Linear(hidden_dim, 1) # 1 = num of classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_instances, feature_dim)\n",
    "        attention_weights = self.attention(x)\n",
    "        weights = F.softmax(attention_weights, dim=1)\n",
    "        return (x * weights).sum(dim=1), weights.squeeze(-1)\n",
    "\n",
    "class DualStreamMIL(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, mode='all'):\n",
    "        super(DualStreamMIL, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.mode = mode  # New parameter to handle different modes\n",
    "\n",
    "        # Initialize ResNet18 with custom input channels\n",
    "        self.resnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        self.resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet18.fc = nn.Identity()\n",
    "\n",
    "        self.attention_layer = AttentionLayer(input_dim, input_dim)\n",
    "        # self.second_stream = SecondStreamDSMIL(input_dim, output_class=1)\n",
    "        self.second_stream = SecondStreamDSMIL(input_dim, input_dim)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(in_features=512, out_features=128),\n",
    "            nn.ReLU(),          \n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(in_features=128, out_features=128),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(in_features=128, out_features=1)  # 1 = num of classes\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, bag_size, C, H, W = x.shape\n",
    "        x = x.view(N * bag_size, C, H, W)\n",
    "\n",
    "        features = nn.Dropout(0.2)(self.resnet18(x).view(N, bag_size, -1))\n",
    "\n",
    "        # Feature extraction\n",
    "        max_aggregation = torch.max(features, dim=1)[0]\n",
    "        classes = self.classifier(max_aggregation)\n",
    "\n",
    "        if self.mode == 'max-pooling':\n",
    "            return classes\n",
    "\n",
    "        elif self.mode == 'dual-stream':\n",
    "            # Use max aggregation and second stream features\n",
    "            second_stream_features = torch.max(self.second_stream(features), dim=1)[0]\n",
    "            # predicted_bags, A, B = self.second_stream(features, classes)\n",
    "            return classes, self.classifier(second_stream_features)\n",
    "\n",
    "        elif self.mode == 'all':\n",
    "            # Use a combination of max, second stream and attention features\n",
    "            attention_features, _ = self.attention_layer(features)\n",
    "            second_stream_features = torch.max(self.second_stream(features), dim=1)[0]\n",
    "\n",
    "            return classes, self.classifier(attention_features), self.classifier(second_stream_features)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode selected. Choose from 'max-pooling', 'dual-stream', or 'all'.\")\n",
    "\n",
    "        return None"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-21T14:12:59.242745Z",
     "iopub.execute_input": "2024-11-21T14:12:59.243005Z",
     "iopub.status.idle": "2024-11-21T14:12:59.256828Z",
     "shell.execute_reply.started": "2024-11-21T14:12:59.242977Z",
     "shell.execute_reply": "2024-11-21T14:12:59.255887Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T06:13:19.944365Z",
     "start_time": "2024-11-29T06:13:19.925115Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model, criterion, and optimizer setup"
  },
  {
   "cell_type": "code",
   "source": [
    "# Model, criterion, and optimizer setup\n",
    "# model = DualStreamMIL(INPUT_DIM, OUTPUT_DIM, 'dual-stream').to(DEVICE)\n",
    "model = MILNetwork(INPUT_DIM, OUTPUT_DIM).to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-21T14:12:59.257906Z",
     "iopub.execute_input": "2024-11-21T14:12:59.258227Z",
     "iopub.status.idle": "2024-11-21T14:13:00.029045Z",
     "shell.execute_reply.started": "2024-11-21T14:12:59.258192Z",
     "shell.execute_reply": "2024-11-21T14:13:00.028255Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T06:13:20.146662Z",
     "start_time": "2024-11-29T06:13:19.988779Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training loop"
  },
  {
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_labels = []\n",
    "    train_preds = []\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # max_agg, second_stream = model(images)\n",
    "        classes, predicted_bags, A, B = model(images)\n",
    "        max_agg = torch.max(classes, dim=1)[0]\n",
    "        loss_max = criterion(max_agg.squeeze(), labels.float())\n",
    "        loss_bag = criterion(predicted_bags.squeeze(), labels.float())\n",
    "        \n",
    "        loss = 0.5 * loss_max + 0.5 * loss_bag\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds = torch.sigmoid(predicted_bags).squeeze().round()\n",
    "        \n",
    "        train_labels.extend(labels.cpu().numpy())\n",
    "        train_preds.extend(preds.detach().cpu().numpy())\n",
    "\n",
    "    train_accuracy = accuracy_score(train_labels, train_preds)\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "    with torch.inference_mode():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            # max_agg, second_stream = model(images)\n",
    "            classes, predicted_bags, A, B = model(images)\n",
    "            max_agg = torch.max(classes, dim=1)[0]\n",
    "            loss_max = criterion(max_agg.squeeze(), labels.float())\n",
    "            loss_bag = criterion(predicted_bags.squeeze(), labels.float())\n",
    "            \n",
    "            loss = 0.5 * loss_max + 0.5 * loss_bag\n",
    "            loss = loss.mean()\n",
    "            val_loss += loss.item()\n",
    "            preds = torch.sigmoid(predicted_bags).squeeze().round()\n",
    "            \n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_preds.extend(preds.detach().cpu().numpy())\n",
    "\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.4f}, Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-21T14:13:00.031671Z",
     "iopub.execute_input": "2024-11-21T14:13:00.032036Z",
     "iopub.status.idle": "2024-11-21T14:14:21.668219Z",
     "shell.execute_reply.started": "2024-11-21T14:13:00.031998Z",
     "shell.execute_reply": "2024-11-21T14:14:21.667135Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T06:13:42.981744Z",
     "start_time": "2024-11-29T06:13:20.151471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.5912, Train Accuracy: 0.5391, Validation Loss: 0.6654, Validation Accuracy: 0.5714\n",
      "Epoch 2/5, Train Loss: 0.3144, Train Accuracy: 0.6738, Validation Loss: 0.4164, Validation Accuracy: 0.8125\n",
      "Epoch 3/5, Train Loss: 0.0883, Train Accuracy: 0.9746, Validation Loss: 0.1929, Validation Accuracy: 0.9375\n",
      "Epoch 4/5, Train Loss: 0.0295, Train Accuracy: 0.9961, Validation Loss: 0.0700, Validation Accuracy: 0.9821\n",
      "Epoch 5/5, Train Loss: 0.0317, Train Accuracy: 0.9961, Validation Loss: 0.0672, Validation Accuracy: 0.9821\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# Test loop\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_labels = []\n",
    "test_preds = []\n",
    "with torch.inference_mode():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        # max_agg, second_stream = model(images)\n",
    "        classes, predicted_bags, A, B = model(images)\n",
    "        max_agg = torch.max(classes, dim=1)[0]\n",
    "        loss_max = criterion(max_agg.squeeze(), labels.float())\n",
    "        loss_bag = criterion(predicted_bags.squeeze(), labels.float())\n",
    "        loss = 0.5 * loss_max + 0.5 * loss_bag\n",
    "        loss = loss.mean()\n",
    "        test_loss += loss.item()\n",
    "        preds = torch.sigmoid(predicted_bags).squeeze().round()\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_preds.extend(preds.detach().cpu().numpy())\n",
    "        \n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "print(f\"Test Loss: {test_loss/len(test_loader):.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-21T14:14:21.669503Z",
     "iopub.execute_input": "2024-11-21T14:14:21.669827Z",
     "iopub.status.idle": "2024-11-21T14:14:26.958919Z",
     "shell.execute_reply.started": "2024-11-21T14:14:21.669796Z",
     "shell.execute_reply": "2024-11-21T14:14:26.957921Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T06:13:45.996469Z",
     "start_time": "2024-11-29T06:13:43.029727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1158, Test Accuracy: 0.9655\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ]
}
