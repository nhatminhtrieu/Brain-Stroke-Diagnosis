{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T07:23:14.275734Z",
     "start_time": "2025-02-23T07:23:14.274093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "d944452bb66df221",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T07:23:15.478600Z",
     "start_time": "2025-02-23T07:23:14.278847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_src = pd.read_csv('sorted_training_dataset_with_labels.csv')\n",
    "prefix = 'src'\n",
    "middle = 'test'\n",
    "suffix = 4\n",
    "dir = f'{prefix}_{middle}_{suffix}.csv'\n",
    "df_dest = pd.read_csv(dir)\n",
    "\n",
    "column_list = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "\n",
    "# Criteria columns:\n",
    "# Src: filename, study_instance_uid\n",
    "# Dest: instance_name, bag_name\n",
    "\n",
    "# Copy the criteria columns from the source to the destination if the criteria columns are the same\n",
    "# Rename columns in df_src to match df_dest\n",
    "df_src = df_src.rename(columns={'filename': 'instance_name', 'study_instance_uid': 'bag_name'})\n",
    "\n",
    "# Merge the DataFrames based on the criteria columns\n",
    "df_merged = pd.merge(df_dest, df_src[['instance_name', 'bag_name'] + column_list],\n",
    "                     on=['instance_name', 'bag_name'],\n",
    "                     how='left')\n",
    "\n",
    "# Update df_dest with the merged data\n",
    "df_dest = df_merged\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df_dest.to_csv(f'{prefix}_{middle}_{suffix}_update.csv', index=False)"
   ],
   "id": "c68b0d2ff2b128df",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T07:23:15.497454Z",
     "start_time": "2025-02-23T07:23:15.495695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# column_list = ['any', 'extradural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "# src_column_list = ['patient_ICH', 'patient_EDH', 'patient_IPH', 'patient_IVH', 'patient_SAH', 'patient_SDH']\n",
    "#\n",
    "# df_src = 'cq500.csv'\n",
    "# prefix = 'cq500'\n",
    "# middle = 'test'\n",
    "# suffix = 2\n",
    "# dir = f'{prefix}_{middle}_{suffix}.csv'\n",
    "# df_dest = pd.read_csv(dir)\n",
    "# # Remove '-' in the bag_name column\n",
    "# df_dest['bag_name'] = df_dest['bag_name'].str.replace('-', '')\n",
    "#\n",
    "# df_src = pd.read_csv(df_src)\n",
    "# df_src = df_src.rename(columns={'name':'bag_name'})\n",
    "#\n",
    "# df_merged = pd.merge(df_dest, df_src[['bag_name'] + src_column_list],\n",
    "#                         on=['bag_name'],\n",
    "#                         how='left')\n",
    "#\n",
    "# df_dest = df_merged\n",
    "# df_dest.to_csv(f'{prefix}_{middle}_{suffix}_update.csv', index=False)"
   ],
   "id": "865394d3d47534bd",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T07:23:15.540617Z",
     "start_time": "2025-02-23T07:23:15.537469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df_dest\n",
    "# Group by its bag_name columns and count the largest number of instances in each bag\n",
    "df = df.groupby('bag_name').size().reset_index(name='count')\n",
    "# Sort the DataFrame by the count column in descending order\n",
    "df = df.sort_values('count', ascending=False)\n",
    "# print the first 10 rows\n",
    "print(df.head(10))"
   ],
   "id": "722649955d5c89d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          bag_name  count\n",
      "53   ID_fea37ba57c     57\n",
      "118  ID_ff8e97229a     57\n",
      "108  ID_ff6f2428a1     52\n",
      "64   ID_fecc8e4431     50\n",
      "106  ID_ff5d2ae4ee     48\n",
      "36   ID_fe6badda38     48\n",
      "147  ID_fffc71b58c     46\n",
      "35   ID_fe6ad33d25     46\n",
      "30   ID_fe597795f5     46\n",
      "79   ID_fefaf4fb24     45\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T07:23:15.614885Z",
     "start_time": "2025-02-23T07:23:15.582253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUM_INSTANCES = 28\n",
    "def downsample_bag(group):\n",
    "    n_instances = len(group)\n",
    "\n",
    "    # First remove small bags before processing\n",
    "    if n_instances < 10:\n",
    "        return pd.DataFrame()  # Return empty dataframe\n",
    "\n",
    "    # Then handle downsampling\n",
    "    if n_instances <= NUM_INSTANCES:\n",
    "        return group\n",
    "\n",
    "    step = n_instances / NUM_INSTANCES\n",
    "    indices = np.round(np.arange(0, n_instances, step)).astype(int)\n",
    "    unique_indices = pd.unique(np.clip(indices, 0, n_instances-1))\n",
    "\n",
    "    return group.iloc[unique_indices]\n",
    "\n",
    "# Apply with two-stage filtering\n",
    "downsampled_df = (\n",
    "    df_dest.groupby('bag_name', group_keys=False)\n",
    "    .apply(downsample_bag)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "downsampled_df.to_csv(f'{prefix}_{middle}_{suffix}_redundancy.csv', index=False)"
   ],
   "id": "dbc001d0acd11291",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32834/2645923044.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(downsample_bag)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T07:23:15.629935Z",
     "start_time": "2025-02-23T07:23:15.626732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = downsampled_df\n",
    "# Group by its bag_name columns and count the largest number of instances in each bag\n",
    "df = df.groupby('bag_name').size().reset_index(name='count')\n",
    "# Sort the DataFrame by the count column in descending order\n",
    "df = df.sort_values('count', ascending=False)\n",
    "# print the min and max count\n",
    "print(f\"Min count: {df['count'].min()}\")\n",
    "print(f\"Max count: {df['count'].max()}\")"
   ],
   "id": "87b43a0558dbe174",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min count: 24\n",
      "Max count: 28\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T07:23:15.673594Z",
     "start_time": "2025-02-23T07:23:15.671457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import pandas as pd\n",
    "#\n",
    "# def copy_files_from_df(df, filename_column, src_dir, dest_dir):\n",
    "#     \"\"\"\n",
    "#     Copy files listed in a DataFrame from a source directory (including subfolders) to a destination directory.\n",
    "#\n",
    "#     Args:\n",
    "#     df (pandas.DataFrame): DataFrame containing filenames.\n",
    "#     filename_column (str): Name of the column in df that contains filenames.\n",
    "#     src_dir (str): Path to the source directory containing the files (including subfolders).\n",
    "#     dest_dir (str): Path to the destination directory where files will be copied.\n",
    "#     \"\"\"\n",
    "#     # Create the destination directory if it doesn't exist\n",
    "#     os.makedirs(dest_dir, exist_ok=True)\n",
    "#\n",
    "#     # Iterate through the filenames in the DataFrame\n",
    "#     for filename in df[filename_column]:\n",
    "#         # Search for the file in the source directory and its subfolders\n",
    "#         for root, dirs, files in os.walk(src_dir):\n",
    "#             if filename in files:\n",
    "#                 src_path = os.path.join(root, filename)\n",
    "#                 dest_path = os.path.join(dest_dir, filename)\n",
    "#\n",
    "#                 # Create subdirectories in the destination if needed\n",
    "#                 os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "#\n",
    "#                 # Copy the file\n",
    "#                 shutil.copy2(src_path, dest_path)\n",
    "#                 print(f\"Copied: {src_path} -> {dest_path}\")\n",
    "#                 break\n",
    "#         else:\n",
    "#             print(f\"File not found: {filename}\")\n",
    "#\n",
    "# # Example usage\n",
    "# df = pd.read_csv('testing_example.csv')\n",
    "# src_dir = '../../src-ich-mil/'\n",
    "# dest_dir = 'sa_test'\n",
    "#\n",
    "# # Assuming the column with filenames is called 'filename'\n",
    "# copy_files_from_df(df, 'instance_name', src_dir, dest_dir)\n"
   ],
   "id": "7d88307d0d10c814",
   "outputs": [],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
