{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T14:22:46.521205Z",
     "start_time": "2024-12-30T14:22:46.502200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import zipfile\n",
    "# import os\n",
    "#\n",
    "# def extract_folder_from_zip(zip_path, folder_name, output_path):\n",
    "#     \"\"\"\n",
    "#     Extracts all files from a specific folder in a ZIP file to a destination directory,\n",
    "#     preserving the original folder structure.\n",
    "#\n",
    "#     Parameters:\n",
    "#     zip_path (str): Path to the ZIP file.\n",
    "#     folder_name (str): Name of the folder within the ZIP file to extract.\n",
    "#     output_path (str): Destination directory where files will be extracted.\n",
    "#     \"\"\"\n",
    "#     with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#         # Iterate over all the items in the ZIP file\n",
    "#         for file_info in zip_ref.infolist():\n",
    "#             # Check if the current item is in the specified folder\n",
    "#             if file_info.filename.startswith(folder_name + '/'):\n",
    "#                 # Define the full path for extraction\n",
    "#                 # Use os.path.relpath to keep the structure relative to folder_name\n",
    "#                 extracted_path = os.path.join(output_path, os.path.relpath(file_info.filename, start=folder_name))\n",
    "#                 # Create any necessary directories\n",
    "#                 os.makedirs(os.path.dirname(extracted_path), exist_ok=True)\n",
    "#                 # Extract the file\n",
    "#                 with zip_ref.open(file_info) as source_file, open(extracted_path, 'wb') as target_file:\n",
    "#                     target_file.write(source_file.read())\n",
    "#                 # print(f\"Extracted: {file_info.filename} to {extracted_path}\")\n",
    "#\n",
    "# # Example usage\n",
    "# zip_file_path = '/media02/tdhoang01/21127112-21127734/data/rsna-intracranial-hemorrhage-detection.zip'  # Path to your ZIP file\n",
    "# folder_to_extract = 'rsna-intracranial-hemorrhage-detection/stage_2_train'  # Folder inside the ZIP to extract\n",
    "# destination_directory = '/media02/tdhoang01/21127112-21127734/data/rsna-ich-mil/'  # Where to extract files\n",
    "#\n",
    "# extract_folder_from_zip(zip_file_path, folder_to_extract, destination_directory)"
   ],
   "id": "fd0c14b1c942707f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T14:22:46.552212Z",
     "start_time": "2024-12-30T14:22:46.534208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import shutil\n",
    "#\n",
    "# def organize_dicom_files(csv_file, source_dir):\n",
    "#     # Read the CSV file into a DataFrame\n",
    "#     df = pd.read_csv(csv_file)\n",
    "#\n",
    "#     # Remove 'ID_' prefix from patient_id and study_instance_uid\n",
    "#     df['patient_id'] = df['patient_id'].str.replace('ID_', '', regex=False)\n",
    "#     df['study_instance_uid'] = df['study_instance_uid'].str.replace('ID_', '', regex=False)\n",
    "#\n",
    "#     # Group by patient_id and study_instance_uid\n",
    "#     grouped = df.groupby(['patient_id', 'study_instance_uid'])\n",
    "#\n",
    "#     for (patient_id, study_instance_uid), group in grouped:\n",
    "#         # Create a subfolder name based on patient_id and study_instance_uid\n",
    "#         subfolder_name = f\"{patient_id}_{study_instance_uid}\"\n",
    "#         subfolder_path = os.path.join(source_dir, subfolder_name)\n",
    "#\n",
    "#         # Create the subfolder if it does not exist\n",
    "#         os.makedirs(subfolder_path, exist_ok=True)\n",
    "#\n",
    "#         # Move each file in the group to the respective subfolder\n",
    "#         for _, row in group.iterrows():\n",
    "#             filename = row['filename']\n",
    "#             source_file_path = os.path.join(source_dir, filename)\n",
    "#             destination_file_path = os.path.join(subfolder_path, filename)\n",
    "#\n",
    "#             # Move the file\n",
    "#             if os.path.exists(source_file_path):\n",
    "#                 shutil.move(source_file_path, destination_file_path)\n",
    "#                 # print(f\"Moved: {source_file_path} to {destination_file_path}\")\n",
    "#             else:\n",
    "#                 print(f\"File not found: {source_file_path}\")\n",
    "#\n",
    "# # Example usage\n",
    "# csv_file_path = '/media02/tdhoang01/21127112-21127734/data/training_dataset.csv'  # Path to your CSV file\n",
    "# source_directory = '/media02/tdhoang01/21127112-21127734/data/rsna-ich-mil/'        # Source directory containing DICOM files\n",
    "#\n",
    "# organize_dicom_files(csv_file_path, source_directory)"
   ],
   "id": "eccc0a04fe5664b4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T14:22:51.914751Z",
     "start_time": "2024-12-30T14:22:47.536644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def extract_and_organize_from_zip(zip_path, csv_file, output_path, n, folder_name):\n",
    "    \"\"\"\n",
    "    Extracts specific files from a ZIP file based on the filenames listed in a CSV,\n",
    "    and organizes them into subfolders named based on patient_id and study_instance_uid,\n",
    "    but only for the first n rows in the CSV. Only files within a specific folder in the ZIP are considered.\n",
    "\n",
    "    Parameters:\n",
    "    zip_path (str): Path to the ZIP file.\n",
    "    csv_file (str): Path to the CSV file containing filenames and metadata.\n",
    "    output_path (str): Destination directory where files will be extracted and organized.\n",
    "    n (int): Number of rows to process from the CSV file.\n",
    "    folder_name (str): The specific folder within the ZIP file to read files from.\n",
    "    \"\"\"\n",
    "    # Read the CSV file into a DataFrame, limiting to the first n rows\n",
    "    df = pd.read_csv(csv_file, nrows=n)\n",
    "\n",
    "    # Ensure the CSV column names match the expected column names\n",
    "    df.columns = df.columns.str.strip()  # Remove leading/trailing spaces from column names\n",
    "    if 'patient_id' not in df.columns or 'study_instance_uid' not in df.columns or 'filename' not in df.columns:\n",
    "        raise ValueError(\"CSV file must contain 'patient_id', 'study_instance_uid', and 'filename' columns\")\n",
    "\n",
    "    # Remove 'ID_' prefix from patient_id and study_instance_uid\n",
    "    df['patient_id'] = df['patient_id'].str.replace('ID_', '', regex=False)\n",
    "    df['study_instance_uid'] = df['study_instance_uid'].str.replace('ID_', '', regex=False)\n",
    "\n",
    "    # Parse the filenames column from string representation of list to actual list\n",
    "    df['filename'] = df['filename'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"))\n",
    "\n",
    "    # Flatten the DataFrame to have one filename per row\n",
    "    df = df.explode('filename')\n",
    "\n",
    "    # Create a set of filenames for quick lookup\n",
    "    required_files = set(df['filename'].tolist())\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        # Iterate over all the items in the ZIP file\n",
    "        for file_info in zip_ref.infolist():\n",
    "            # Check if the current item is in the specified folder and in the required files list\n",
    "            if file_info.filename.startswith(folder_name + '/') and os.path.basename(file_info.filename) in required_files:\n",
    "                # Find the corresponding row in the DataFrame\n",
    "                row = df[df['filename'] == os.path.basename(file_info.filename)].iloc[0]\n",
    "                patient_id = row['patient_id']\n",
    "                study_instance_uid = row['study_instance_uid']\n",
    "\n",
    "                # Create a subfolder name based on patient_id and study_instance_uid\n",
    "                subfolder_name = f\"{patient_id}_{study_instance_uid}\"\n",
    "                subfolder_path = os.path.join(output_path, subfolder_name)\n",
    "\n",
    "                # Create the subfolder if it does not exist\n",
    "                os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "                # Define the full path for extraction\n",
    "                extracted_path = os.path.join(subfolder_path, os.path.basename(file_info.filename))\n",
    "\n",
    "                # Extract the file\n",
    "                with zip_ref.open(file_info) as source_file, open(extracted_path, 'wb') as target_file:\n",
    "                    target_file.write(source_file.read())\n",
    "                # print(f\"Extracted: {file_info.filename} to {extracted_path}\")"
   ],
   "id": "aa836760f23a076e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T14:27:28.764753Z",
     "start_time": "2024-12-30T14:26:53.906514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "zip_file_path = \"D:/Datasets/rsna-intracranial-hemorrhage-detection.zip\"  # Path to your ZIP file\n",
    "csv_file_path = \"rsna/data_analyze/testing_dataset_150.csv\"  # Path to your CSV file\n",
    "destination_directory = 'D:/Datasets/rsna-ich-mil/'  # Where to extract and organize files\n",
    "n_rows = 2000  # Limit to first n rows in the CSV\n",
    "folder_to_read = 'rsna-intracranial-hemorrhage-detection/stage_2_train'  # Specific folder within the ZIP file\n",
    "\n",
    "extract_and_organize_from_zip(zip_file_path, csv_file_path, destination_directory, n_rows, folder_to_read)"
   ],
   "id": "761f9b6f326a13bf",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T14:26:22.470873Z",
     "start_time": "2024-12-30T14:26:22.456870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import pandas as pd\n",
    "#\n",
    "# df = pd.read_csv('./rsna/data_analyze/training_dataset_1.csv')\n",
    "#\n",
    "# multi_label_columns = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "#\n",
    "# for column in multi_label_columns:\n",
    "#     df[column] = df[column].apply(\n",
    "#         lambda x: eval(x) if isinstance(x, str) else x\n",
    "#     )\n",
    "#\n",
    "# # Create new 6 columns for each multi-label column\n",
    "# for column in multi_label_columns:\n",
    "#         df[column + f'_'] = df[column].apply(lambda x: 1 if sum(x) > 0 else 0)\n",
    "# df.head()\n",
    "#\n",
    "# # df.to_csv('temp.csv', index=False)"
   ],
   "id": "a9e42c3742783706",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T14:26:22.502879Z",
     "start_time": "2024-12-30T14:26:22.487878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Count the number of row that has more than 1 label in these columns\n",
    "# multi_label_columns = ['any_', 'epidural_', 'intraparenchymal_', 'intraventricular_', 'subarachnoid_', 'subdural_']\n",
    "# df['multi_label'] = df[multi_label_columns].sum(axis=1)\n",
    "# df['multi_label'].value_counts()\n"
   ],
   "id": "8ad4ef9c7f754ae4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T14:33:48.234498Z",
     "start_time": "2024-12-30T14:33:48.160832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = pd.read_csv('rsna/data_analyze/training_dataset_1150.csv')\n",
    "df_test = pd.read_csv('rsna/data_analyze/testing_dataset_150.csv')\n",
    "\n",
    "# Check if df_train and df_test have the same row\n",
    "print(df_train.shape, df_test.shape)\n",
    "\n",
    "# Check if there are same patient_id and study_instance_uid in both df_train and df_test\n",
    "train_ids = set(df_train['patient_id'] + '_' + df_train['study_instance_uid'])\n",
    "test_ids = set(df_test['patient_id'] + '_' + df_test['study_instance_uid'])\n",
    "\n",
    "# Print out the duplicate ids\n",
    "duplicate_ids = train_ids.intersection(test_ids)\n",
    "duplicate_ids"
   ],
   "id": "82d43d950a2ed031",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 19) (150, 19)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ID_e0d2de32_ID_00047d6503'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
