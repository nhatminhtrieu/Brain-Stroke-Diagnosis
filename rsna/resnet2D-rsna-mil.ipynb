{
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 9652074,
     "sourceType": "datasetVersion",
     "datasetId": 5705276
    }
   ],
   "dockerImageVersionId": 30776,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25022.389189,
   "end_time": "2024-10-05T02:20:29.848670",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-04T19:23:27.459481",
   "version": "2.6.0"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Library",
   "metadata": {
    "papermill": {
     "duration": 0.015487,
     "end_time": "2024-10-04T19:23:30.290610",
     "exception": false,
     "start_time": "2024-10-04T19:23:30.275123",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from scipy.stats import variation\n",
    "!pip install gpytorch\n",
    "!pip install wandb"
   ],
   "metadata": {
    "papermill": {
     "duration": 13.842163,
     "end_time": "2024-10-04T19:23:44.147775",
     "exception": false,
     "start_time": "2024-10-04T19:23:30.305612",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:03:29.962323Z",
     "iopub.execute_input": "2024-11-09T12:03:29.962697Z",
     "iopub.status.idle": "2024-11-09T12:03:54.971291Z",
     "shell.execute_reply.started": "2024-11-09T12:03:29.962659Z",
     "shell.execute_reply": "2024-11-09T12:03:54.970161Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:10.261106Z",
     "start_time": "2024-11-14T16:23:08.949746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpytorch in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (1.13)\r\n",
      "Requirement already satisfied: jaxtyping==0.2.19 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (0.2.19)\r\n",
      "Requirement already satisfied: mpmath<=1.3,>=0.19 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (1.3.0)\r\n",
      "Requirement already satisfied: scikit-learn in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (1.5.1)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (1.10.1)\r\n",
      "Requirement already satisfied: linear-operator>=0.5.3 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (0.5.3)\r\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from jaxtyping==0.2.19->gpytorch) (1.24.3)\r\n",
      "Requirement already satisfied: typeguard>=2.13.3 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from jaxtyping==0.2.19->gpytorch) (4.2.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from jaxtyping==0.2.19->gpytorch) (4.12.2)\r\n",
      "Requirement already satisfied: torch>=1.11 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from linear-operator>=0.5.3->gpytorch) (2.4.0)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-learn->gpytorch) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-learn->gpytorch) (3.5.0)\r\n",
      "Requirement already satisfied: filelock in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (3.13.1)\r\n",
      "Requirement already satisfied: sympy in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (2024.6.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (2.20.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (12.1.105)\r\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.5.3->gpytorch) (3.0.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->linear-operator>=0.5.3->gpytorch) (12.6.20)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from jinja2->torch>=1.11->linear-operator>=0.5.3->gpytorch) (2.1.3)\r\n",
      "Requirement already satisfied: wandb in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (0.18.5)\r\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (8.1.7)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (3.1.43)\r\n",
      "Requirement already satisfied: platformdirs in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (4.2.2)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (5.28.3)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (6.0.0)\r\n",
      "Requirement already satisfied: pyyaml in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (6.0.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (2.32.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (2.17.0)\r\n",
      "Requirement already satisfied: setproctitle in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (1.3.3)\r\n",
      "Requirement already satisfied: setuptools in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (72.1.0)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (4.12.2)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\r\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "source": "import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pydicom\nimport cv2\nfrom tqdm import tqdm\nfrom skimage.transform import resize\nfrom skimage.transform import rotate\nfrom scipy.ndimage import gaussian_filter\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.distributions import Normal\nimport torchvision.models as models\nfrom torchvision import transforms\n\nimport wandb\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n\nimport gpytorch\nfrom gpytorch.models import ApproximateGP\nfrom gpytorch.variational import CholeskyVariationalDistribution, VariationalStrategy\n\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'",
   "metadata": {
    "papermill": {
     "duration": 11.793387,
     "end_time": "2024-10-04T19:23:55.956283",
     "exception": false,
     "start_time": "2024-10-04T19:23:44.162896",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:03:54.973321Z",
     "iopub.execute_input": "2024-11-09T12:03:54.973660Z",
     "iopub.status.idle": "2024-11-09T12:04:04.345572Z",
     "shell.execute_reply.started": "2024-11-09T12:03:54.973624Z",
     "shell.execute_reply": "2024-11-09T12:04:04.344540Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:10.307916Z",
     "start_time": "2024-11-14T16:23:10.269764Z"
    }
   },
   "outputs": [],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "source": "import warnings\nfrom sklearn.exceptions import UndefinedMetricWarning\n\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\nwarnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)",
   "metadata": {
    "papermill": {
     "duration": 0.02447,
     "end_time": "2024-10-04T19:23:55.997833",
     "exception": false,
     "start_time": "2024-10-04T19:23:55.973363",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:04.346735Z",
     "iopub.execute_input": "2024-11-09T12:04:04.347247Z",
     "iopub.status.idle": "2024-11-09T12:04:04.352304Z",
     "shell.execute_reply.started": "2024-11-09T12:04:04.347210Z",
     "shell.execute_reply": "2024-11-09T12:04:04.351162Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:10.336309Z",
     "start_time": "2024-11-14T16:23:10.320085Z"
    }
   },
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "markdown",
   "source": "## Init GPU",
   "metadata": {
    "papermill": {
     "duration": 0.024749,
     "end_time": "2024-10-04T19:23:56.038412",
     "exception": false,
     "start_time": "2024-10-04T19:23:56.013663",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "# Initialize GPU Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\nelse:\n    print(\"No GPU available. Training will run on CPU.\")\n\nprint(device)",
   "metadata": {
    "papermill": {
     "duration": 0.105269,
     "end_time": "2024-10-04T19:23:56.159555",
     "exception": false,
     "start_time": "2024-10-04T19:23:56.054286",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:04.354377Z",
     "iopub.execute_input": "2024-11-09T12:04:04.354684Z",
     "iopub.status.idle": "2024-11-09T12:04:04.410802Z",
     "shell.execute_reply.started": "2024-11-09T12:04:04.354653Z",
     "shell.execute_reply": "2024-11-09T12:04:04.409843Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:10.395832Z",
     "start_time": "2024-11-14T16:23:10.378912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 4070 SUPER is available.\n",
      "cuda\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "source": "%load_ext autoreload\n%autoreload 2",
   "metadata": {
    "papermill": {
     "duration": 0.081958,
     "end_time": "2024-10-04T19:23:56.258405",
     "exception": false,
     "start_time": "2024-10-04T19:23:56.176447",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:04.411954Z",
     "iopub.execute_input": "2024-11-09T12:04:04.412279Z",
     "iopub.status.idle": "2024-11-09T12:04:04.479489Z",
     "shell.execute_reply.started": "2024-11-09T12:04:04.412244Z",
     "shell.execute_reply": "2024-11-09T12:04:04.478787Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:10.474852Z",
     "start_time": "2024-11-14T16:23:10.456874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "source": "## Config Info",
   "metadata": {
    "papermill": {
     "duration": 0.016234,
     "end_time": "2024-10-04T19:23:56.291671",
     "exception": false,
     "start_time": "2024-10-04T19:23:56.275437",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Constants\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "CHANNELS = 3\n",
    "\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "TEST_BATCH_SIZE = 4\n",
    "TEST_SIZE = 0.15\n",
    "VALID_SIZE = 0.15\n",
    "\n",
    "MAX_SLICES = 60\n",
    "SHAPE = (HEIGHT, WIDTH, CHANNELS)\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "INDUCING_POINTS = 128\n",
    "\n",
    "# TARGET_LABELS = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "TARGET_LABELS = ['intraparenchymal']\n",
    "\n",
    "MODEL_PATH = 'results/trained_model.pth'\n",
    "DEVICE = 'cuda'"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.076674,
     "end_time": "2024-10-04T19:23:56.384583",
     "exception": false,
     "start_time": "2024-10-04T19:23:56.307909",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:04.480520Z",
     "iopub.execute_input": "2024-11-09T12:04:04.480805Z",
     "iopub.status.idle": "2024-11-09T12:04:04.541310Z",
     "shell.execute_reply.started": "2024-11-09T12:04:04.480773Z",
     "shell.execute_reply": "2024-11-09T12:04:04.540405Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:10.545880Z",
     "start_time": "2024-11-14T16:23:10.517973Z"
    }
   },
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "source": "# Kaggle and local switch\nKAGGLE = os.path.exists('/kaggle')\nprint(\"Running on Kaggle\" if KAGGLE else \"Running locally\")\nROOT_DIR = '/kaggle/input/rsna-mil-training/' if KAGGLE else None\nDATA_DIR = ROOT_DIR + 'rsna-mil-training/' if KAGGLE else '../rsna-mil-training/'\nDICOM_DIR = DATA_DIR\nCSV_PATH = DICOM_DIR + 'training_1000_scan_subset.csv' if KAGGLE else './data_analyze/training_1000_scan_subset.csv'\n# SLICE_LABEL_PATH = ROOT_DIR + \"sorted_training_dataset_with_labels.csv\" if KAGGLE else './data_analyze/sorted_training_dataset_with_labels.csv'\n\ndicom_dir = DICOM_DIR if KAGGLE else DATA_DIR\n# Load patient scan labels\npatient_scan_labels = pd.read_csv(CSV_PATH)\n# patient_slice_labels = pd.read_csv(SLICE_LABEL_PATH)\nos.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)",
   "metadata": {
    "papermill": {
     "duration": 4.085647,
     "end_time": "2024-10-04T19:24:00.487263",
     "exception": false,
     "start_time": "2024-10-04T19:23:56.401616",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:04.542362Z",
     "iopub.execute_input": "2024-11-09T12:04:04.542646Z",
     "iopub.status.idle": "2024-11-09T12:04:04.649755Z",
     "shell.execute_reply.started": "2024-11-09T12:04:04.542615Z",
     "shell.execute_reply": "2024-11-09T12:04:04.648985Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:10.610920Z",
     "start_time": "2024-11-14T16:23:10.583452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# key = user_secrets.get_secret(\"Wandb key\")\n",
    "# \n",
    "# wandb.login(key=key, relogin=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:04.650858Z",
     "iopub.execute_input": "2024-11-09T12:04:04.651199Z",
     "iopub.status.idle": "2024-11-09T12:04:06.250597Z",
     "shell.execute_reply.started": "2024-11-09T12:04:04.651166Z",
     "shell.execute_reply": "2024-11-09T12:04:06.249864Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:10.652637Z",
     "start_time": "2024-11-14T16:23:10.634454Z"
    }
   },
   "outputs": [],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "source": "patient_scan_labels.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:06.251742Z",
     "iopub.execute_input": "2024-11-09T12:04:06.252251Z",
     "iopub.status.idle": "2024-11-09T12:04:06.331892Z",
     "shell.execute_reply.started": "2024-11-09T12:04:06.252216Z",
     "shell.execute_reply": "2024-11-09T12:04:06.331086Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:10.716814Z",
     "start_time": "2024-11-14T16:23:10.697627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    patient_id study_instance_uid  \\\n",
       "0  ID_2e010e33      ID_bda0f47e84   \n",
       "1  ID_43dd2890      ID_43af13416f   \n",
       "2  ID_93753256      ID_1ee74896bd   \n",
       "3  ID_2d49911c      ID_a71e7c6817   \n",
       "4  ID_cd2cd174      ID_d02e9abf35   \n",
       "\n",
       "                                              images  \\\n",
       "0  ['ID_b9035cb1e.dcm', 'ID_0713bed86.dcm', 'ID_5...   \n",
       "1  ['ID_23864d3ba.dcm', 'ID_f1c65b76e.dcm', 'ID_5...   \n",
       "2  ['ID_a3a37df48.dcm', 'ID_61dd5485f.dcm', 'ID_9...   \n",
       "3  ['ID_93d9cf661.dcm', 'ID_efd4e2780.dcm', 'ID_7...   \n",
       "4  ['ID_b437d2e19.dcm', 'ID_0a919428c.dcm', 'ID_d...   \n",
       "\n",
       "                                              labels  patient_label  length  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              0      48  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              0      33  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              0      30  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              0      40  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              0      33  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>study_instance_uid</th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "      <th>patient_label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_2e010e33</td>\n",
       "      <td>ID_bda0f47e84</td>\n",
       "      <td>['ID_b9035cb1e.dcm', 'ID_0713bed86.dcm', 'ID_5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_43dd2890</td>\n",
       "      <td>ID_43af13416f</td>\n",
       "      <td>['ID_23864d3ba.dcm', 'ID_f1c65b76e.dcm', 'ID_5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_93753256</td>\n",
       "      <td>ID_1ee74896bd</td>\n",
       "      <td>['ID_a3a37df48.dcm', 'ID_61dd5485f.dcm', 'ID_9...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_2d49911c</td>\n",
       "      <td>ID_a71e7c6817</td>\n",
       "      <td>['ID_93d9cf661.dcm', 'ID_efd4e2780.dcm', 'ID_7...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_cd2cd174</td>\n",
       "      <td>ID_d02e9abf35</td>\n",
       "      <td>['ID_b437d2e19.dcm', 'ID_0a919428c.dcm', 'ID_d...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "cell_type": "markdown",
   "source": "## Data Preprocessing",
   "metadata": {
    "papermill": {
     "duration": 0.016012,
     "end_time": "2024-10-04T19:24:00.520265",
     "exception": false,
     "start_time": "2024-10-04T19:24:00.504253",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "def correct_dcm(dcm):\n    x = dcm.pixel_array + 1000\n    px_mode = 4096\n    x[x>=px_mode] = x[x>=px_mode] - px_mode\n    dcm.PixelData = x.tobytes()\n    dcm.RescaleIntercept = -1000\n\ndef window_image(dcm, window_center, window_width):    \n    if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):\n        correct_dcm(dcm)\n    img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n    \n    # Resize\n    img = cv2.resize(img, SHAPE[:2], interpolation = cv2.INTER_LINEAR)\n   \n    img_min = window_center - window_width // 2\n    img_max = window_center + window_width // 2\n    img = np.clip(img, img_min, img_max)\n    return img\n\ndef bsb_window(dcm):\n    brain_img = window_image(dcm, 40, 80)\n    subdural_img = window_image(dcm, 80, 200)\n    soft_img = window_image(dcm, 40, 380)\n    \n    brain_img = (brain_img - 0) / 80\n    subdural_img = (subdural_img - (-20)) / 200\n    soft_img = (soft_img - (-150)) / 380\n\n    if CHANNELS == 3:\n        bsb_img = np.stack([brain_img, subdural_img, soft_img], axis=-1)\n    else:\n        bsb_img = brain_img\n    return bsb_img.astype(np.float16)",
   "metadata": {
    "papermill": {
     "duration": 0.079596,
     "end_time": "2024-10-04T19:24:00.617176",
     "exception": false,
     "start_time": "2024-10-04T19:24:00.537580",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:06.335428Z",
     "iopub.execute_input": "2024-11-09T12:04:06.335746Z",
     "iopub.status.idle": "2024-11-09T12:04:06.404940Z",
     "shell.execute_reply.started": "2024-11-09T12:04:06.335713Z",
     "shell.execute_reply": "2024-11-09T12:04:06.403960Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:10.788760Z",
     "start_time": "2024-11-14T16:23:10.770872Z"
    }
   },
   "outputs": [],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "source": "def preprocess_slice(slice, target_size=(HEIGHT, WIDTH)):\n    # Check if type of slice is dicom or an empty numpy array\n    if (type(slice) == np.ndarray):\n        slice = resize(slice, target_size, anti_aliasing=True)\n        multichannel_slice = np.stack([slice, slice, slice], axis=-1)\n        if CHANNELS == 3:\n            return multichannel_slice.astype(np.float16)\n        else:\n            return slice.astype(np.float16)\n    else:\n        slice = bsb_window(slice)\n        return slice.astype(np.float16)",
   "metadata": {
    "papermill": {
     "duration": 0.076531,
     "end_time": "2024-10-04T19:24:00.710787",
     "exception": false,
     "start_time": "2024-10-04T19:24:00.634256",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:06.406284Z",
     "iopub.execute_input": "2024-11-09T12:04:06.406824Z",
     "iopub.status.idle": "2024-11-09T12:04:06.470535Z",
     "shell.execute_reply.started": "2024-11-09T12:04:06.406773Z",
     "shell.execute_reply": "2024-11-09T12:04:06.469524Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:10.841884Z",
     "start_time": "2024-11-14T16:23:10.812929Z"
    }
   },
   "outputs": [],
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "source": "def read_dicom_folder(folder_path):\n    slices = []\n    for filename in sorted(os.listdir(folder_path))[:MAX_SLICES]:  # Limit to MAX_SLICES\n        if filename.endswith(\".dcm\"):\n            file_path = os.path.join(folder_path, filename)\n            ds = pydicom.dcmread(file_path)\n            slices.append(ds)\n            \n    # Sort slices by images position (z-coordinate) in ascending order\n    slices = sorted(slices, key=lambda x: float(x.ImagePositionPatient[2]))\n    \n    # Pad with black images if necessary\n    while len(slices) < MAX_SLICES:\n        slices.append(np.zeros_like(slices[0].pixel_array))\n    \n    return slices[:MAX_SLICES]  # Ensure we return exactly MAX_SLICES",
   "metadata": {
    "papermill": {
     "duration": 0.076142,
     "end_time": "2024-10-04T19:24:00.803356",
     "exception": false,
     "start_time": "2024-10-04T19:24:00.727214",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:06.471678Z",
     "iopub.execute_input": "2024-11-09T12:04:06.471972Z",
     "iopub.status.idle": "2024-11-09T12:04:06.536802Z",
     "shell.execute_reply.started": "2024-11-09T12:04:06.471940Z",
     "shell.execute_reply": "2024-11-09T12:04:06.535848Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:10.891100Z",
     "start_time": "2024-11-14T16:23:10.872153Z"
    }
   },
   "outputs": [],
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "source": "## Dataset and DataLoader",
   "metadata": {
    "papermill": {
     "duration": 0.016487,
     "end_time": "2024-10-04T19:24:00.836476",
     "exception": false,
     "start_time": "2024-10-04T19:24:00.819989",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Splitting the Dataset",
   "metadata": {
    "papermill": {
     "duration": 0.015844,
     "end_time": "2024-10-04T19:24:00.868235",
     "exception": false,
     "start_time": "2024-10-04T19:24:00.852391",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "def split_dataset(patient_scan_labels, test_size=TEST_SIZE, val_size=VALID_SIZE, random_state=42):\n    # Extract the labels from the DataFrame\n    labels = patient_scan_labels['patient_label']\n\n    # First, split off the test set\n    train_val_labels, test_labels = train_test_split(\n        patient_scan_labels, \n        test_size=test_size, \n        stratify=labels, \n        random_state=random_state\n    )\n\n    # Calculate the validation size relative to the train_val set\n    val_size_adjusted = val_size / (1 - test_size)\n\n    # Split the train_val set into train and validation sets\n    train_labels, val_labels = train_test_split(\n        train_val_labels, \n        test_size=val_size_adjusted, \n        stratify=train_val_labels['patient_label'], \n        random_state=random_state\n    )\n\n    return train_labels, val_labels, test_labels",
   "metadata": {
    "papermill": {
     "duration": 0.075616,
     "end_time": "2024-10-04T19:24:00.959889",
     "exception": false,
     "start_time": "2024-10-04T19:24:00.884273",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:06.537885Z",
     "iopub.execute_input": "2024-11-09T12:04:06.538200Z",
     "iopub.status.idle": "2024-11-09T12:04:06.603427Z",
     "shell.execute_reply.started": "2024-11-09T12:04:06.538168Z",
     "shell.execute_reply": "2024-11-09T12:04:06.602545Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:10.938886Z",
     "start_time": "2024-11-14T16:23:10.916114Z"
    }
   },
   "outputs": [],
   "execution_count": 92
  },
  {
   "cell_type": "markdown",
   "source": "### Processing the Data",
   "metadata": {
    "papermill": {
     "duration": 0.017012,
     "end_time": "2024-10-04T19:24:00.993325",
     "exception": false,
     "start_time": "2024-10-04T19:24:00.976313",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "def process_patient_data(dicom_dir, row, num_instances=12, depth=5):\n    patient_id = row['patient_id'].replace('ID_', '')\n    study_instance_uid = row['study_instance_uid'].replace('ID_', '')\n    \n    folder_name = f\"{patient_id}_{study_instance_uid}\"\n    folder_path = os.path.join(dicom_dir, folder_name)\n    \n    if os.path.exists(folder_path):\n        slices = read_dicom_folder(folder_path)\n        \n        # Ensure we have enough slices to create the specified instances\n        if len(slices) < depth * num_instances:\n            print(f\"Not enough slices for patient {patient_id}: found {len(slices)}, needed {depth * num_instances}\")\n            return None, None\n        \n        preprocessed_slices = [torch.tensor(preprocess_slice(slice), dtype=torch.float32) for slice in slices]  # Convert to tensor\n        \n        # Stack preprocessed slices into an array\n        preprocessed_slices = torch.stack(preprocessed_slices, dim=0)  # (num_slices, height, width, channels)\n    \n        # Labels are already in list form, so just convert them to a tensor\n        labels = torch.tensor(row['labels'], dtype=torch.long)\n        \n        # Fill labels with 0s if necessary\n        if len(preprocessed_slices) > len(labels):\n            padded_labels = torch.zeros(len(preprocessed_slices), dtype=torch.long)\n            padded_labels[:len(labels)] = labels\n        else:\n            padded_labels = labels[:len(preprocessed_slices)]\n        \n        return preprocessed_slices, padded_labels\n    \n    else:\n        print(f\"Folder not found: {folder_path}\")\n        return None, None",
   "metadata": {
    "papermill": {
     "duration": 0.076813,
     "end_time": "2024-10-04T19:24:01.086193",
     "exception": false,
     "start_time": "2024-10-04T19:24:01.009380",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:06.604538Z",
     "iopub.execute_input": "2024-11-09T12:04:06.604898Z",
     "iopub.status.idle": "2024-11-09T12:04:06.673120Z",
     "shell.execute_reply.started": "2024-11-09T12:04:06.604856Z",
     "shell.execute_reply": "2024-11-09T12:04:06.672312Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:10.984175Z",
     "start_time": "2024-11-14T16:23:10.960575Z"
    }
   },
   "outputs": [],
   "execution_count": 93
  },
  {
   "cell_type": "markdown",
   "source": "### Augmentation",
   "metadata": {
    "papermill": {
     "duration": 0.016194,
     "end_time": "2024-10-04T19:24:01.118549",
     "exception": false,
     "start_time": "2024-10-04T19:24:01.102355",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "# class DatasetAugmentor:\n#     def __init__(self, height, width, seed=None):\n#         self.height = height\n#         self.width = width\n#         self.seed = seed\n        \n#         # Store parameters for consistency checks with non-overlapping ranges\n#         self.min_params = self._create_transform(5, (0.05, 0.05), (0.95, 1.05), \n#                                                   brightness_range=0.05, contrast_range=0.05,\n#                                                   blur_sigma_range=(0.1, 0.2), apply_elastic=False, level_name='min')\n#         self.med_params = self._create_transform(10, (0.1, 0.1), (0.9, 1.1), \n#                                                   brightness_range=0.1, contrast_range=0.1,\n#                                                   blur_sigma_range=(0.2, 0.5), apply_elastic=True, level_name='med')\n#         self.max_params = self._create_transform(15, (0.2, 0.2), (0.8, 1.2), \n#                                                   brightness_range=0.2, contrast_range=0.2,\n#                                                   blur_sigma_range=(0.5, 1.0), apply_elastic=True, level_name='max')\n\n#     def _sample_value(self, value_range):\n#         if isinstance(value_range, tuple):\n#             random.seed(self.seed)\n#             return random.uniform(value_range[0], value_range[1])\n#         return value_range\n\n#     def _create_transform(self, degrees, translate_range, scale_range,\n#                       brightness_range, contrast_range,\n#                       blur_sigma_range, apply_elastic, level_name):\n#         print(f\"Creating '{level_name}' transform with parameters:\")\n\n#         # Sample specific values and take the absolute value for positivity\n#         sampled_degrees = abs(self._sample_value((-degrees, degrees)) if isinstance(degrees, int) else degrees)\n#         sampled_translate_x = abs(self._sample_value(translate_range[0]))\n#         sampled_translate_y = abs(self._sample_value(translate_range[1]))\n#         sampled_scale = self._sample_value(scale_range)\n#         sampled_brightness = self._sample_value(brightness_range)\n#         sampled_contrast = self._sample_value(contrast_range)\n#         sampled_blur_sigma = self._sample_value(blur_sigma_range)\n\n#         # Print specific sampled values\n#         print(f\"  Degrees: {sampled_degrees}, Translate: ({sampled_translate_x}, {sampled_translate_y}), Scale: {sampled_scale}\")\n#         print(f\"  Brightness: {sampled_brightness}, Contrast: {sampled_contrast}\")\n#         print(f\"  Blur Sigma: {sampled_blur_sigma}, Apply Elastic: {apply_elastic}\")\n\n#         return {\n#             \"degrees\": sampled_degrees,\n#             \"translate\": (sampled_translate_x, sampled_translate_y),\n#             \"scale\": sampled_scale,\n#             \"brightness\": sampled_brightness,\n#             \"contrast\": sampled_contrast,\n#             \"blur_sigma\": sampled_blur_sigma,\n#             \"apply_elastic\": apply_elastic\n#         }\n\n#     def apply_transform(self, image, level):\n#         channels = image.shape[0]\n        \n#         if self.seed is not None:\n#             torch.manual_seed(self.seed)\n#             random.seed(self.seed)\n\n#         if level == 0:\n#             params = self.min_params\n#             transform = self._get_transform(params, channels)\n#         elif level == 1:\n#             params = self.med_params\n#             transform = self._get_transform(params, channels)\n#         else:\n#             params = self.max_params\n#             transform = self._get_transform(params, channels)\n\n#         transformed_image = transform(image)        \n#         return transformed_image\n\n#     def _get_transform(self, params, channels=3):\n#         transform_list = [\n#             transforms.ToPILImage(),\n#             transforms.RandomHorizontalFlip(p=0.5),\n#             transforms.RandomAffine(degrees=params[\"degrees\"], translate=params[\"translate\"], scale=(params[\"scale\"], params[\"scale\"])),\n#             transforms.ColorJitter(brightness=params[\"brightness\"], contrast=params[\"contrast\"]),\n#             transforms.GaussianBlur(kernel_size=(3, 3), sigma=params[\"blur_sigma\"]),\n#             transforms.RandomApply([transforms.ElasticTransform()] if params[\"apply_elastic\"] else [], p=0.3),\n#             transforms.Resize(256),\n#             transforms.CenterCrop(HEIGHT),\n#             transforms.ToTensor(),\n#         ]\n\n#         if channels == 3:\n#             transform_list.extend([\n#                 transforms.Normalize(mean=[0.16774411, 0.1360026, 0.19076315], std=[0.3101935, 0.27605791, 0.30469988]),\n#                 transforms.RandomApply([self._channel_shuffle], p=0.3)\n#             ])\n#         elif channels == 1:\n#             transform_list.append(transforms.Normalize(mean=[0.16774411], std=[0.3101935]))\n\n#         return transforms.Compose(transform_list)\n\n#     def _channel_shuffle(self, tensor):\n#         torch.manual_seed(self.seed)\n#         channels = tensor.shape[0]\n#         indices = torch.randperm(channels)\n#         return tensor[indices]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:06.674617Z",
     "iopub.execute_input": "2024-11-09T12:04:06.675050Z",
     "iopub.status.idle": "2024-11-09T12:04:06.741026Z",
     "shell.execute_reply.started": "2024-11-09T12:04:06.675004Z",
     "shell.execute_reply": "2024-11-09T12:04:06.740160Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.030619Z",
     "start_time": "2024-11-14T16:23:11.008640Z"
    }
   },
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "source": "class DatasetAugmentor:\n    def __init__(self, height, width, levels=2, seed=None):\n        self.height = height\n        self.width = width\n        self.levels = levels  # Dynamic number of levels\n        self.seed = seed\n        self.params = []\n\n        # Create different levels of transforms based on the number of levels specified\n        for i in range(levels):\n            factor = (i + 1) / levels\n            self.params.append(\n                self._create_transform(\n                    degrees=int(15 * factor), \n                    translate_range=(0.2 * factor, 0.2 * factor),\n                    scale_range=(1 - 0.2 * factor, 1 + 0.2 * factor),\n                    brightness_range=0.2 * factor,\n                    contrast_range=0.2 * factor,\n                    blur_sigma_range=(0.5 * factor, 1.0 * factor),\n                    apply_elastic=(i >= levels // 2),\n                    level_name=f'level_{i + 1}'\n                )\n            )\n\n    def _sample_value(self, value_range):\n        if isinstance(value_range, tuple):\n            random.seed(self.seed)\n            return random.uniform(value_range[0], value_range[1])\n        return value_range\n\n    def _create_transform(self, degrees, translate_range, scale_range, brightness_range, contrast_range, blur_sigma_range, apply_elastic, level_name):\n        print(f\"Creating '{level_name}' transform with parameters:\")\n        sampled_values = {\n            \"degrees\": abs(self._sample_value((-degrees, degrees))),\n            \"translate\": (abs(self._sample_value(translate_range[0])), abs(self._sample_value(translate_range[1]))),\n            \"scale\": self._sample_value(scale_range),\n            \"brightness\": self._sample_value(brightness_range),\n            \"contrast\": self._sample_value(contrast_range),\n            \"blur_sigma\": self._sample_value(blur_sigma_range),\n            \"apply_elastic\": apply_elastic\n        }\n        \n        print(sampled_values)\n        return sampled_values\n\n    def apply_transform(self, image, level):\n        params = self.params[level]\n        transform = self._get_transform(params, channels=image.shape[0])\n        return transform(image)\n\n    def _get_transform(self, params, channels=3):\n        transform_list = [\n            transforms.ToPILImage(),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomAffine(degrees=params[\"degrees\"], translate=params[\"translate\"], scale=(params[\"scale\"], params[\"scale\"])),\n            transforms.ColorJitter(brightness=params[\"brightness\"], contrast=params[\"contrast\"]),\n            transforms.GaussianBlur(kernel_size=(3, 3), sigma=params[\"blur_sigma\"]),\n            transforms.RandomApply([transforms.ElasticTransform()] if params[\"apply_elastic\"] else [], p=0.3),\n            transforms.Resize(256),\n            transforms.CenterCrop(self.height),\n            transforms.ToTensor(),\n        ]\n\n        if channels == 3:\n            transform_list.extend([\n                transforms.Normalize(mean=[0.16774411, 0.1360026, 0.19076315], std=[0.3101935, 0.27605791, 0.30469988]),\n                transforms.RandomApply([self._channel_shuffle], p=0.3)\n            ])\n        elif channels == 1:\n            transform_list.append(transforms.Normalize(mean=[0.16774411], std=[0.3101935]))\n\n        return transforms.Compose(transform_list)\n\n    def _channel_shuffle(self, tensor):\n        torch.manual_seed(self.seed)\n        channels = tensor.shape[0]\n        indices = torch.randperm(channels)\n        return tensor[indices]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:06.742336Z",
     "iopub.execute_input": "2024-11-09T12:04:06.742670Z",
     "iopub.status.idle": "2024-11-09T12:04:06.817331Z",
     "shell.execute_reply.started": "2024-11-09T12:04:06.742638Z",
     "shell.execute_reply": "2024-11-09T12:04:06.816387Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.088435Z",
     "start_time": "2024-11-14T16:23:11.058245Z"
    }
   },
   "outputs": [],
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "source": "augmentor = DatasetAugmentor(224, 224, seed=42)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:06.818519Z",
     "iopub.execute_input": "2024-11-09T12:04:06.818878Z",
     "iopub.status.idle": "2024-11-09T12:04:06.881845Z",
     "shell.execute_reply.started": "2024-11-09T12:04:06.818836Z",
     "shell.execute_reply": "2024-11-09T12:04:06.881035Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.157926Z",
     "start_time": "2024-11-14T16:23:11.133287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 'level_1' transform with parameters:\n",
      "{'degrees': 1.9519751784103718, 'translate': (0.1, 0.1), 'scale': 1.027885359691577, 'brightness': 0.1, 'contrast': 0.1, 'blur_sigma': 0.4098566996144709, 'apply_elastic': False}\n",
      "Creating 'level_2' transform with parameters:\n",
      "{'degrees': 4.182803953736514, 'translate': (0.2, 0.2), 'scale': 1.0557707193831534, 'brightness': 0.2, 'contrast': 0.2, 'blur_sigma': 0.8197133992289418, 'apply_elastic': True}\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "source": "### Dataset Generator",
   "metadata": {
    "papermill": {
     "duration": 0.015494,
     "end_time": "2024-10-04T19:24:01.252123",
     "exception": false,
     "start_time": "2024-10-04T19:24:01.236629",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "# class MedicalScanDataset(Dataset):\n#     \"\"\"\n#     Base dataset class for processing medical scan data.\n#     Handles data loading, preprocessing, and normalization of medical scan images.\n#     \"\"\"\n#     def __init__(self, data_dir, patient_scan_labels, augmentor):\n#         self.data_dir = data_dir\n#         self.patient_scan_labels = self._parse_patient_scan_labels(patient_scan_labels)\n#         self.augmentor = augmentor\n\n#     def _parse_patient_scan_labels(self, patient_scan_labels):\n#         \"\"\"Parse and validate patient scan labels.\"\"\"\n#         patient_scan_labels['images'] = patient_scan_labels['images'].apply(\n#             lambda x: eval(x) if isinstance(x, str) else x\n#         )\n#         patient_scan_labels['labels'] = patient_scan_labels['labels'].apply(\n#             lambda x: eval(x) if isinstance(x, str) else x\n#         )\n#         patient_scan_labels['patient_label'] = patient_scan_labels['patient_label'].astype(bool)\n#         return patient_scan_labels\n\n#     def __len__(self):\n#         \"\"\"Return the total number of samples in the dataset.\"\"\"\n#         return len(self.patient_scan_labels)\n\n#     def __getitem__(self, idx):\n#         \"\"\"Get a single item from the dataset.\"\"\"\n#         row = self.patient_scan_labels.iloc[idx]\n#         preprocessed_slices, labels = self._process_patient_data(row)\n        \n#         if preprocessed_slices is None:\n#             return None, None, None\n            \n#         preprocessed_slices = self._prepare_tensor(preprocessed_slices)\n#         patient_label = torch.tensor(bool(row['patient_label']), dtype=torch.uint8)\n        \n#         return preprocessed_slices, labels, patient_label\n\n#     def _process_patient_data(self, row):\n#         \"\"\"Process patient data to get preprocessed slices and labels.\"\"\"\n#         return process_patient_data(self.data_dir, row)\n\n#     def _prepare_tensor(self, preprocessed_slices):\n#         \"\"\"Convert preprocessed slices to normalized tensor.\"\"\"\n#         preprocessed_slices = np.array(preprocessed_slices)\n#         preprocessed_slices = torch.tensor(preprocessed_slices, dtype=torch.float32)\n\n#         if preprocessed_slices.ndim == 3:  # Grayscale\n#             preprocessed_slices = preprocessed_slices.unsqueeze(1)  # Add channel dimension\n#             return torch.stack([self.augmentor.apply_transform(img, level=0) for img in preprocessed_slices])\n#         elif preprocessed_slices.ndim == 4:  # RGB\n#             preprocessed_slices = preprocessed_slices.permute(0, 3, 1, 2) \n#             return torch.stack([self.augmentor.apply_transform(img, level=0) for img in preprocessed_slices])\n#         else:\n#             raise ValueError(f\"Unexpected number of dimensions: {preprocessed_slices.ndim}\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:06.883210Z",
     "iopub.execute_input": "2024-11-09T12:04:06.883884Z",
     "iopub.status.idle": "2024-11-09T12:04:06.948390Z",
     "shell.execute_reply.started": "2024-11-09T12:04:06.883840Z",
     "shell.execute_reply": "2024-11-09T12:04:06.947409Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.208153Z",
     "start_time": "2024-11-14T16:23:11.190706Z"
    }
   },
   "outputs": [],
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "source": "class MedicalScanDataset(Dataset):\n    def __init__(self, data_dir, patient_scan_labels, augmentor=None):\n        self.data_dir = data_dir\n        self.patient_scan_labels = self._parse_patient_scan_labels(patient_scan_labels)\n        self.augmentor = augmentor\n        \n    def _parse_patient_scan_labels(self, patient_scan_labels):\n        \"\"\"Parse and validate patient scan labels.\"\"\"\n        patient_scan_labels['images'] = patient_scan_labels['images'].apply(\n            lambda x: eval(x) if isinstance(x, str) else x\n        )\n        patient_scan_labels['labels'] = patient_scan_labels['labels'].apply(\n            lambda x: eval(x) if isinstance(x, str) else x\n        )\n        patient_scan_labels['patient_label'] = patient_scan_labels['patient_label'].astype(bool)\n        return patient_scan_labels\n    \n    def _process_patient_data(self, row):\n        \"\"\"Process patient data to get preprocessed slices and labels.\"\"\"\n        return process_patient_data(self.data_dir, row)\n\n    def __len__(self):\n        return len(self.patient_scan_labels) * (self.augmentor.levels if self.augmentor else 1)\n\n    def __getitem__(self, idx):\n        patient_idx = idx // (self.augmentor.levels if self.augmentor else 1)\n        aug_level = idx % (self.augmentor.levels if self.augmentor else 1)\n\n        row = self.patient_scan_labels.iloc[patient_idx]\n        preprocessed_slices, labels = self._process_patient_data(row)\n\n        if preprocessed_slices is None:\n            return None, None, None\n\n        preprocessed_slices = self._prepare_tensor(preprocessed_slices, aug_level if self.augmentor else None)\n        patient_label = torch.tensor(bool(row['patient_label']), dtype=torch.uint8)\n\n        return preprocessed_slices, labels, patient_label\n\n#     def _prepare_tensor(self, preprocessed_slices, aug_level):\n#         preprocessed_slices = np.array(preprocessed_slices)\n#         preprocessed_slices = torch.tensor(preprocessed_slices, dtype=torch.float32)\n\n#         if self.augmentor and aug_level is not None:\n#             if preprocessed_slices.ndim == 3:\n#                 preprocessed_slices = preprocessed_slices.unsqueeze(1)\n#                 return torch.stack([self.augmentor.apply_transform(img, aug_level) for img in preprocessed_slices])\n#             elif preprocessed_slices.ndim == 4:\n#                 preprocessed_slices = preprocessed_slices.permute(0, 3, 1, 2)\n#                 return torch.stack([self.augmentor.apply_transform(img, aug_level) for img in preprocessed_slices])\n#         else:\n#             return preprocessed_slices\n\n    def _prepare_tensor(self, preprocessed_slices, aug_level):\n        # Convert to numpy array and then to torch tensor\n        preprocessed_slices = np.array(preprocessed_slices)\n        preprocessed_slices = torch.tensor(preprocessed_slices, dtype=torch.float32)\n\n        # Add an additional dimension for channel if it's missing (no augmentor)\n        if preprocessed_slices.ndim == 3:\n            preprocessed_slices = preprocessed_slices.unsqueeze(1)  # shape: [slices, 1, H, W]\n\n        # Apply augmentation if augmentor is specified\n        if self.augmentor and aug_level is not None:\n            if preprocessed_slices.ndim == 4:  # Ensure it has the [slices, channels, H, W] format\n                return torch.stack([self.augmentor.apply_transform(img, aug_level) for img in preprocessed_slices])\n\n        return preprocessed_slices  # Return without augmentation if augmentor is None",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:06.949800Z",
     "iopub.execute_input": "2024-11-09T12:04:06.950129Z",
     "iopub.status.idle": "2024-11-09T12:04:07.020925Z",
     "shell.execute_reply.started": "2024-11-09T12:04:06.950072Z",
     "shell.execute_reply": "2024-11-09T12:04:07.020108Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.259741Z",
     "start_time": "2024-11-14T16:23:11.235837Z"
    }
   },
   "outputs": [],
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "source": [
    "class TrainDatasetGenerator(MedicalScanDataset):\n",
    "    \"\"\"Dataset class for training medical scan data.\"\"\"\n",
    "    def __init__(self, data_dir, patient_scan_labels, augmentor=None):\n",
    "        super().__init__(data_dir, patient_scan_labels, augmentor)\n",
    "\n",
    "class TestDatasetGenerator(MedicalScanDataset):\n",
    "    \"\"\"Dataset class for testing medical scan data.\"\"\"\n",
    "    def __init__(self, data_dir, patient_scan_labels, augmentor=None):\n",
    "        super().__init__(data_dir, patient_scan_labels, augmentor)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:07.022171Z",
     "iopub.execute_input": "2024-11-09T12:04:07.022528Z",
     "iopub.status.idle": "2024-11-09T12:04:07.085840Z",
     "shell.execute_reply.started": "2024-11-09T12:04:07.022481Z",
     "shell.execute_reply": "2024-11-09T12:04:07.084942Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.310295Z",
     "start_time": "2024-11-14T16:23:11.284861Z"
    }
   },
   "outputs": [],
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "source": "original_dataset = TrainDatasetGenerator(dicom_dir, patient_scan_labels, augmentor=None)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:07.086910Z",
     "iopub.execute_input": "2024-11-09T12:04:07.087252Z",
     "iopub.status.idle": "2024-11-09T12:04:07.255534Z",
     "shell.execute_reply.started": "2024-11-09T12:04:07.087214Z",
     "shell.execute_reply": "2024-11-09T12:04:07.254706Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.391781Z",
     "start_time": "2024-11-14T16:23:11.331243Z"
    }
   },
   "outputs": [],
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "source": "len(original_dataset)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:07.256674Z",
     "iopub.execute_input": "2024-11-09T12:04:07.256977Z",
     "iopub.status.idle": "2024-11-09T12:04:07.320972Z",
     "shell.execute_reply.started": "2024-11-09T12:04:07.256945Z",
     "shell.execute_reply": "2024-11-09T12:04:07.320056Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.416379Z",
     "start_time": "2024-11-14T16:23:11.399656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "source": [
    "x,y,z = original_dataset[0]\n",
    "print(x.shape, y.shape, z.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:07.322156Z",
     "iopub.execute_input": "2024-11-09T12:04:07.322491Z",
     "iopub.status.idle": "2024-11-09T12:04:08.712840Z",
     "shell.execute_reply.started": "2024-11-09T12:04:07.322458Z",
     "shell.execute_reply": "2024-11-09T12:04:08.711911Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.640923Z",
     "start_time": "2024-11-14T16:23:11.478548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 224, 224, 3]) torch.Size([60]) torch.Size([])\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "source": [
    "# # Check if the returned data is valid\n",
    "# if x is not None:\n",
    "#     # Convert the tensor to a numpy array\n",
    "#     x_np = x.numpy()\n",
    "#\n",
    "#     # Check the number of dimensions and squeeze if necessary\n",
    "#     if x_np.ndim == 4:  # RGB images\n",
    "#         # Plot each slice\n",
    "#         fig, axes = plt.subplots(1, x_np.shape[0], figsize=(15, 5))\n",
    "#         for i, ax in enumerate(axes):\n",
    "#             ax.imshow(x_np[i].transpose(1, 2, 0))  # Convert CHW to HWC\n",
    "#             ax.axis('off')\n",
    "#         plt.show()\n",
    "#     elif x_np.ndim == 3:  # Grayscale images\n",
    "#         # Plot each slice\n",
    "#         fig, axes = plt.subplots(1, x_np.shape[0], figsize=(15, 5))\n",
    "#         for i, ax in enumerate(axes):\n",
    "#             ax.imshow(x_np[i], cmap='gray')\n",
    "#             ax.axis('off')\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unexpected number of dimensions: {x_np.ndim}\")\n",
    "# else:\n",
    "#     print(\"No data available for this patient.\")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:08.713992Z",
     "iopub.execute_input": "2024-11-09T12:04:08.714306Z",
     "iopub.status.idle": "2024-11-09T12:04:10.720210Z",
     "shell.execute_reply.started": "2024-11-09T12:04:08.714273Z",
     "shell.execute_reply": "2024-11-09T12:04:10.719091Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.673412Z",
     "start_time": "2024-11-14T16:23:11.656505Z"
    }
   },
   "outputs": [],
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "source": [
    "def get_train_loader(dicom_dir, patient_scan_labels, batch_size=TRAIN_BATCH_SIZE):\n",
    "    # original_dataset = TrainDatasetGenerator(dicom_dir, patient_scan_labels, augmentor=augmentor)\n",
    "    original_dataset = TrainDatasetGenerator(dicom_dir, patient_scan_labels, augmentor=None)\n",
    "    return DataLoader(original_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "def get_test_loader(dicom_dir, patient_scan_labels, batch_size=TEST_BATCH_SIZE):\n",
    "    test_dataset = TestDatasetGenerator(dicom_dir, patient_scan_labels, augmentor=None)\n",
    "    return DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.074769,
     "end_time": "2024-10-04T19:24:01.438666",
     "exception": false,
     "start_time": "2024-10-04T19:24:01.363897",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:10.721483Z",
     "iopub.execute_input": "2024-11-09T12:04:10.721855Z",
     "iopub.status.idle": "2024-11-09T12:04:10.790322Z",
     "shell.execute_reply.started": "2024-11-09T12:04:10.721821Z",
     "shell.execute_reply": "2024-11-09T12:04:10.789279Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.719212Z",
     "start_time": "2024-11-14T16:23:11.700476Z"
    }
   },
   "outputs": [],
   "execution_count": 104
  },
  {
   "cell_type": "markdown",
   "source": "## CNN Feature Extractor",
   "metadata": {
    "papermill": {
     "duration": 0.015548,
     "end_time": "2024-10-04T19:24:01.470464",
     "exception": false,
     "start_time": "2024-10-04T19:24:01.454916",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": "### GP Model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class GPModel(gpytorch.models.ApproximateGP):\n    def __init__(self, inducing_points):\n        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(inducing_points.size(0))\n        variational_strategy = gpytorch.variational.VariationalStrategy(\n            self, inducing_points, variational_distribution, learn_inducing_locations=True\n        )\n        super(GPModel, self).__init__(variational_strategy)\n        self.mean_module = gpytorch.means.ConstantMean()\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n\n    def forward(self, x):\n        mean_x = self.mean_module(x)\n        covar_x = self.covar_module(x)\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:10.791523Z",
     "iopub.execute_input": "2024-11-09T12:04:10.791820Z",
     "iopub.status.idle": "2024-11-09T12:04:10.858127Z",
     "shell.execute_reply.started": "2024-11-09T12:04:10.791789Z",
     "shell.execute_reply": "2024-11-09T12:04:10.857159Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.769057Z",
     "start_time": "2024-11-14T16:23:11.745154Z"
    }
   },
   "outputs": [],
   "execution_count": 105
  },
  {
   "cell_type": "markdown",
   "source": "### Attention Layer",
   "metadata": {
    "papermill": {
     "duration": 0.015987,
     "end_time": "2024-10-04T19:24:01.719520",
     "exception": false,
     "start_time": "2024-10-04T19:24:01.703533",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "class AttentionLayer(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(AttentionLayer, self).__init__()\n        self.attention = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            # nn.Tanh(),\n            # nn.ReLU(),\n            nn.PReLU(),\n            nn.Linear(hidden_dim, 1)\n        )\n\n    def forward(self, x):\n        # x shape: (batch_size, num_instances, feature_dim)\n        attention_weights = self.attention(x)\n        weights = F.softmax(attention_weights, dim=1)\n\n        return (x * weights).sum(dim=1), weights.squeeze(-1)",
   "metadata": {
    "papermill": {
     "duration": 0.077274,
     "end_time": "2024-10-04T19:24:01.812862",
     "exception": false,
     "start_time": "2024-10-04T19:24:01.735588",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:10.859388Z",
     "iopub.execute_input": "2024-11-09T12:04:10.859734Z",
     "iopub.status.idle": "2024-11-09T12:04:10.926160Z",
     "shell.execute_reply.started": "2024-11-09T12:04:10.859698Z",
     "shell.execute_reply": "2024-11-09T12:04:10.925167Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.811239Z",
     "start_time": "2024-11-14T16:23:11.790189Z"
    }
   },
   "outputs": [],
   "execution_count": 106
  },
  {
   "cell_type": "code",
   "source": "class GatedAttention(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(GatedAttention, self).__init__()\n        self.attention = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            # nn.Tanh(),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1)\n        )\n        self.gate = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            # nn.Tanh(),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1)\n        )\n        \n    def forward(self, x):\n        # x shape: (batch_size, num_instances, input_dim)\n        attention_weights = self.attention(x)\n        gate_weights = torch.sigmoid(self.gate(x))\n        \n        weights = attention_weights * gate_weights\n        weights = F.softmax(weights, dim=1)\n        \n        return (x * weights).sum(dim=1), weights.squeeze(-1)",
   "metadata": {
    "papermill": {
     "duration": 0.079025,
     "end_time": "2024-10-04T19:24:01.908938",
     "exception": false,
     "start_time": "2024-10-04T19:24:01.829913",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:10.931368Z",
     "iopub.execute_input": "2024-11-09T12:04:10.931690Z",
     "iopub.status.idle": "2024-11-09T12:04:11.000139Z",
     "shell.execute_reply.started": "2024-11-09T12:04:10.931654Z",
     "shell.execute_reply": "2024-11-09T12:04:10.999075Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.857160Z",
     "start_time": "2024-11-14T16:23:11.835925Z"
    }
   },
   "outputs": [],
   "execution_count": 107
  },
  {
   "cell_type": "markdown",
   "source": "### Mixed Pooling",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class MixedPooling(nn.Module):\n    def __init__(self, in_channels: int, alpha: float=0.5):\n        super(MixedPooling, self).__init__()\n        self.alpha = alpha\n        \n        # Convolution layer\n        self.conv = nn.Conv2d(in_channels, 16, kernel_size=1)  # Adjust output channels as needed\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.maxpool = nn.AdaptiveMaxPool2d((1, 1))\n\n    def forward(self, x):\n        # Perform average pooling and apply weight\n        avg_out = self.avgpool(x)\n        avg_out_weighted = avg_out * self.alpha\n        \n        # Perform max pooling and apply weight\n        max_out = self.maxpool(x)\n        max_out_weighted = max_out * (1 - self.alpha)\n\n        # Add the weighted outputs together\n        # combined = avg_out_weighted + max_out_weighted\n        combined = torch.cat((avg_out_weighted, max_out_weighted), dim=1)  # Concatenate along channel dimension\n        combined = self.conv(combined)  # Reduce channels\n        return combined  # Output with combined features",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:11.001398Z",
     "iopub.execute_input": "2024-11-09T12:04:11.001723Z",
     "iopub.status.idle": "2024-11-09T12:04:11.070134Z",
     "shell.execute_reply.started": "2024-11-09T12:04:11.001690Z",
     "shell.execute_reply": "2024-11-09T12:04:11.069154Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.902737Z",
     "start_time": "2024-11-14T16:23:11.881864Z"
    }
   },
   "outputs": [],
   "execution_count": 108
  },
  {
   "cell_type": "markdown",
   "source": "### ResNet2D Model",
   "metadata": {
    "papermill": {
     "duration": 0.015805,
     "end_time": "2024-10-04T19:24:02.065521",
     "exception": false,
     "start_time": "2024-10-04T19:24:02.049716",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### ResNet2D Model",
   "metadata": {
    "papermill": {
     "duration": 0.015973,
     "end_time": "2024-10-04T19:24:02.353086",
     "exception": false,
     "start_time": "2024-10-04T19:24:02.337113",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class MILResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MILResNet18, self).__init__()\n",
    "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.resnet.conv1 = nn.Conv2d(in_channels=CHANNELS, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        self.attention = AttentionLayer(input_dim=512, hidden_dim=512)\n",
    "        self.classifier = nn.Linear(512 + 1, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Define inducing points for the GP layer\n",
    "        inducing_points = torch.randn(32, 512)\n",
    "        # inducing_points = torch.full((256, 512), 1e-20)  \n",
    "        self.gp_layer = GPModel(inducing_points)\n",
    "\n",
    "    def forward(self, bags):\n",
    "        # batch_size, num_instances = bags.size(0), bags.size(1)\n",
    "        # bags_flattened = bags.view(-1, *bags.shape[2:])\n",
    "        # batch_size, num_instances, h, w, c = bags.size()\n",
    "        # bags_flattened = bags.view(batch_size * num_instances, c, h, w)\n",
    "        if CHANNELS == 1:\n",
    "            batch_size, num_instances, c, h, w = bags.size()\n",
    "        else:\n",
    "            batch_size, num_instances, h, w, c = bags.size()\n",
    "\n",
    "        # batch_size, num_instances, c, h, w = bags.size()\n",
    "        bags_flattened = bags.view(batch_size * num_instances, c, h, w)\n",
    "\n",
    "        features = self.resnet(bags_flattened)\n",
    "        features = features.view(batch_size, num_instances, -1)\n",
    "        attended_features, attended_weights = self.attention(features)\n",
    "\n",
    "        attended_features_reshaped = attended_features.view(-1, 512)\n",
    "\n",
    "        gp_output = self.gp_layer(attended_features_reshaped)\n",
    "        gp_mean = gp_output.mean.view(batch_size, -1)\n",
    "\n",
    "        combine_features = torch.cat((attended_features, gp_mean), dim=1)\n",
    "        combine_features = self.dropout(combine_features)\n",
    "\n",
    "        outputs = torch.sigmoid(self.classifier(combine_features))\n",
    "        return outputs, attended_weights, gp_output"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:11.071536Z",
     "iopub.execute_input": "2024-11-09T12:04:11.071923Z",
     "iopub.status.idle": "2024-11-09T12:04:11.143565Z",
     "shell.execute_reply.started": "2024-11-09T12:04:11.071889Z",
     "shell.execute_reply": "2024-11-09T12:04:11.142556Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:11.960685Z",
     "start_time": "2024-11-14T16:23:11.929365Z"
    }
   },
   "outputs": [],
   "execution_count": 109
  },
  {
   "cell_type": "markdown",
   "source": "## Training and Evaluation",
   "metadata": {
    "papermill": {
     "duration": 0.015973,
     "end_time": "2024-10-04T19:24:02.496444",
     "exception": false,
     "start_time": "2024-10-04T19:24:02.480471",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### Loss Function",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def combined_loss(outputs, gp_distribution, target, alpha=0.5):\n    # Cross-Entropy Loss for CNN outputs\n    bce_loss = nn.BCELoss()(outputs.squeeze(), target.float())\n    kl_divergence = gp_distribution.variational_strategy.kl_divergence()\n    total_loss = (1 - alpha) * bce_loss + alpha * kl_divergence\n    \n    return total_loss",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:11.144744Z",
     "iopub.execute_input": "2024-11-09T12:04:11.145137Z",
     "iopub.status.idle": "2024-11-09T12:04:11.209993Z",
     "shell.execute_reply.started": "2024-11-09T12:04:11.145066Z",
     "shell.execute_reply": "2024-11-09T12:04:11.209156Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:12.001925Z",
     "start_time": "2024-11-14T16:23:11.980025Z"
    }
   },
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:12.044163Z",
     "start_time": "2024-11-14T16:23:12.024558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combined_loss_v2(outputs, gp_output, mll, target, alpha=0.5):\n",
    "    # Cross-Entropy Loss for CNN outputs\n",
    "    bce_loss = nn.BCELoss()(outputs.squeeze(), target.float())\n",
    "    gp_loss = -mll(gp_output, target)\n",
    "    total_loss = (1 - alpha) * bce_loss + alpha * gp_loss\n",
    "\n",
    "    return total_loss"
   ],
   "outputs": [],
   "execution_count": 111
  },
  {
   "cell_type": "markdown",
   "source": "### Training",
   "metadata": {
    "papermill": {
     "duration": 0.016325,
     "end_time": "2024-10-04T19:24:02.529050",
     "exception": false,
     "start_time": "2024-10-04T19:24:02.512725",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train_epoch(model, data_loader, criterion, optimizer, scheduler, device, variational_optimizer=None, mll=None):\n",
    "    total_loss = 0.0\n",
    "    alpha = 0.5\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    for batch_data, batch_labels, batch_patient_labels in data_loader:\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs, attention_weights, gp_output = model(batch_data)\n",
    "        outputs = outputs.squeeze()\n",
    "        # loss = combined_loss(outputs, model.gp_layer, batch_patient_labels, alpha)\n",
    "        loss = combined_loss_v2(outputs, gp_output, mll, batch_patient_labels, alpha)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        variational_optimizer.step()\n",
    "\n",
    "        # Store predictions and labels\n",
    "        predictions.extend((outputs > 0.5).cpu().detach().numpy())\n",
    "        labels.extend(batch_patient_labels.cpu().numpy())\n",
    "\n",
    "    return total_loss, predictions, labels\n",
    "\n",
    "def validate(model, data_loader, criterion, device, variational_optimizer=None, mll=None):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    alpha = 0.5\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels, batch_patient_labels in data_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, attention_weights, gp_output = model(batch_data)\n",
    "            outputs = outputs.squeeze()\n",
    "            # loss = combined_loss(outputs, model.gp_layer, batch_patient_labels, alpha)\n",
    "            loss = combined_loss_v2(outputs, gp_output, mll, batch_patient_labels, alpha)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "            # Store predictions and labels\n",
    "            predictions.extend((outputs > 0.5).cpu().detach().numpy())\n",
    "            labels.extend(batch_patient_labels.cpu().numpy())\n",
    "\n",
    "    return total_loss, predictions, labels\n",
    "\n",
    "def calculate_metrics(predictions, labels):\n",
    "    \"\"\"Calculate and return performance metrics.\"\"\"\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"precision\": precision_score(labels, predictions),\n",
    "        \"recall\": recall_score(labels, predictions),\n",
    "        \"f1\": f1_score(labels, predictions)\n",
    "    }\n",
    "\n",
    "def print_epoch_stats(epoch, num_epochs, phase, loss, metrics):\n",
    "    \"\"\"Print statistics for an epoch.\"\"\"\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - {phase.capitalize()}:\")\n",
    "    print(f\"Loss: {loss:.4f}, Accuracy: {metrics['accuracy']:.4f}, \"\n",
    "          f\"Precision: {metrics['precision']:.4f}, Recall: {metrics['recall']:.4f}, \"\n",
    "          f\"F1: {metrics['f1']:.4f}\")\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer,num_epochs, learning_rate, device='cuda', variational_optimizer=None, mll=None, likelihood=None):\n",
    "    \"\"\"Train the model and return the best model based on validation accuracy.\"\"\"\n",
    "    model = model.to(device)\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, \n",
    "                                              steps_per_epoch=len(train_loader), epochs=num_epochs)\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        train_loss, train_predictions, train_labels = train_epoch(model, train_loader, criterion, optimizer, scheduler, device, variational_optimizer, mll)\n",
    "        train_metrics = calculate_metrics(train_predictions, train_labels)\n",
    "        print_epoch_stats(epoch, num_epochs, \"train\", train_loss, train_metrics)\n",
    "        # Log training metrics to W&B\n",
    "        wandb.log({\"train/loss\": train_loss / len(train_loader), **train_metrics})\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, val_predictions, val_labels = validate(model, val_loader, criterion, device, variational_optimizer, mll)\n",
    "        val_metrics = calculate_metrics(val_predictions, val_labels)\n",
    "        print_epoch_stats(epoch, num_epochs, \"validation\", val_loss, val_metrics)\n",
    "        # Log validation metrics to W&B\n",
    "        wandb.log({\"val/loss\": val_loss / len(val_loader), **val_metrics})\n",
    "\n",
    "        # Save best model\n",
    "        if val_metrics['accuracy'] > best_val_accuracy:\n",
    "            best_val_accuracy = val_metrics['accuracy']\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    # Optionally log the best model to W&B (if desired)\n",
    "    wandb.log_artifact(wandb.Artifact(\"best_model\", type=\"model\", metadata={\"accuracy\": best_val_accuracy}))\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.089765,
     "end_time": "2024-10-04T19:24:02.636485",
     "exception": false,
     "start_time": "2024-10-04T19:24:02.546720",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:11.211419Z",
     "iopub.execute_input": "2024-11-09T12:04:11.212295Z",
     "iopub.status.idle": "2024-11-09T12:04:11.290690Z",
     "shell.execute_reply.started": "2024-11-09T12:04:11.212259Z",
     "shell.execute_reply": "2024-11-09T12:04:11.289598Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:12.095068Z",
     "start_time": "2024-11-14T16:23:12.070516Z"
    }
   },
   "outputs": [],
   "execution_count": 112
  },
  {
   "cell_type": "markdown",
   "source": "### Evaluation Functions",
   "metadata": {
    "papermill": {
     "duration": 0.016054,
     "end_time": "2024-10-04T19:24:02.668925",
     "exception": false,
     "start_time": "2024-10-04T19:24:02.652871",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## Model Evaluation Functions\n",
    "def evaluate_model(model, data_loader, device='cuda', likelihood=None):\n",
    "    \"\"\"Evaluate the model on the given data loader.\"\"\"\n",
    "    model = model.to(device)\n",
    "    likelihood = likelihood.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.inference_mode(): # Torch.inference_mode() is equivalent to torch.no_grad(), but it's faster and consumes less memory!!!\n",
    "        for batch_data, batch_labels, batch_patient_labels in data_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "\n",
    "            outputs, attention_weights, _ = model(batch_data)\n",
    "            outputs = outputs.squeeze()\n",
    "            predictions.extend((outputs > 0.5).cpu().detach().numpy())\n",
    "            labels.extend(batch_patient_labels.cpu().numpy())\n",
    "\n",
    "    return np.array(predictions), np.array(labels)\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    \"\"\"Print the calculated metrics.\"\"\"\n",
    "    print(f\"Test Accuracy: {metrics['accuracy']:.4f}, \"\n",
    "          f\"Precision: {metrics['precision']:.4f}, \"\n",
    "          f\"Recall: {metrics['recall']:.4f}, \"\n",
    "          f\"F1: {metrics['f1']:.4f}\")"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.079611,
     "end_time": "2024-10-04T19:24:02.764721",
     "exception": false,
     "start_time": "2024-10-04T19:24:02.685110",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:11.291769Z",
     "iopub.execute_input": "2024-11-09T12:04:11.292052Z",
     "iopub.status.idle": "2024-11-09T12:04:11.359152Z",
     "shell.execute_reply.started": "2024-11-09T12:04:11.292017Z",
     "shell.execute_reply": "2024-11-09T12:04:11.358128Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:12.141833Z",
     "start_time": "2024-11-14T16:23:12.120997Z"
    }
   },
   "outputs": [],
   "execution_count": 113
  },
  {
   "cell_type": "markdown",
   "source": "### Visualization Functions",
   "metadata": {
    "papermill": {
     "duration": 0.01814,
     "end_time": "2024-10-04T19:24:02.800208",
     "exception": false,
     "start_time": "2024-10-04T19:24:02.782068",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## Visualization Functions\n",
    "def plot_roc_curve(model, data_loader, device, likelihood=None):\n",
    "    \"\"\"Plot the ROC curve for the model predictions.\"\"\"\n",
    "    # predictions, labels = evaluate_model(model, data_loader, device)\n",
    "    \n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for batch_data, batch_labels, batch_patient_labels in data_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "\n",
    "            outputs, attention_weights, _ = model(batch_data)\n",
    "            outputs = outputs.squeeze()\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            labels.extend(batch_patient_labels.cpu().numpy())\n",
    "            \n",
    "    fpr, tpr, _ = roc_curve(labels, predictions)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(model, data_loader, device, likelihood=None):\n",
    "    \"\"\"Plot the confusion matrix for the model predictions.\"\"\"\n",
    "    predictions, labels = evaluate_model(model, data_loader, device, likelihood)\n",
    "    \n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.092339,
     "end_time": "2024-10-04T19:24:02.911187",
     "exception": false,
     "start_time": "2024-10-04T19:24:02.818848",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:11.360394Z",
     "iopub.execute_input": "2024-11-09T12:04:11.360796Z",
     "iopub.status.idle": "2024-11-09T12:04:11.429794Z",
     "shell.execute_reply.started": "2024-11-09T12:04:11.360761Z",
     "shell.execute_reply": "2024-11-09T12:04:11.428871Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:12.209070Z",
     "start_time": "2024-11-14T16:23:12.170038Z"
    }
   },
   "outputs": [],
   "execution_count": 114
  },
  {
   "cell_type": "markdown",
   "source": "### Data Processing Functions",
   "metadata": {
    "papermill": {
     "duration": 0.018543,
     "end_time": "2024-10-04T19:24:02.948830",
     "exception": false,
     "start_time": "2024-10-04T19:24:02.930287",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## Data Processing Functions\n",
    "def load_model(model_class, model_path):\n",
    "    \"\"\"Load a trained model from a file.\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "\n",
    "    model = model_class()\n",
    "    try:\n",
    "        state_dict = torch.load(model_path, map_location=torch.device('cuda'), weights_only=True)\n",
    "        if not state_dict:\n",
    "            raise ValueError(f\"The state dictionary loaded from {model_path} is empty\")\n",
    "        model.load_state_dict(state_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model from {model_path}: {str(e)}\")\n",
    "        print(\"Initializing model with random weights instead.\")\n",
    "        return model  # Return the model with random initialization\n",
    "\n",
    "    return model.eval()\n",
    "\n",
    "\n",
    "def get_test_results(model, test_loader, test_labels, device, likelihood=None):\n",
    "    \"\"\"Get test results including patient information.\"\"\"\n",
    "    predictions, _ = evaluate_model(model, test_loader, DEVICE, likelihood)\n",
    "    \n",
    "    results = []\n",
    "    for i, row in enumerate(test_labels.itertuples(index=False)):\n",
    "        result = {col: getattr(row, col) for col in test_labels.columns}\n",
    "        result['prediction'] = predictions[i]\n",
    "        results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.079014,
     "end_time": "2024-10-04T19:24:03.046531",
     "exception": false,
     "start_time": "2024-10-04T19:24:02.967517",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:11.430912Z",
     "iopub.execute_input": "2024-11-09T12:04:11.431237Z",
     "iopub.status.idle": "2024-11-09T12:04:11.497859Z",
     "shell.execute_reply.started": "2024-11-09T12:04:11.431205Z",
     "shell.execute_reply": "2024-11-09T12:04:11.496987Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:12.250264Z",
     "start_time": "2024-11-14T16:23:12.222419Z"
    }
   },
   "outputs": [],
   "execution_count": 115
  },
  {
   "cell_type": "markdown",
   "source": "## Visualizing Attention Weights and Images",
   "metadata": {
    "papermill": {
     "duration": 0.01837,
     "end_time": "2024-10-04T19:24:03.082997",
     "exception": false,
     "start_time": "2024-10-04T19:24:03.064627",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_label_attention_weights(model, data_loader, device='cuda', likelihood=None):\n",
    "    \"\"\"\n",
    "    Plot images with their labels and attention values in a single large plot.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained model\n",
    "    - data_loader: DataLoader containing test dataset\n",
    "    - device: Device to run the model on ('cuda' or 'cpu')\n",
    "    - CHANNELS: Number of channels in the image (e.g., 1 for grayscale, 3 for RGB)\n",
    "\n",
    "    Expected shapes:\n",
    "    - 1-channel images: (batch_size, num_images, 224, 224)\n",
    "    - 3-channel images: (batch_size, num_images, 3, 224, 224)\n",
    "    - attention: float value per image indicating attention weight\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    likelihood = likelihood.to(device)\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    num_images = 60\n",
    "    rows, cols = 10, 6  # Adjust to fit 60 images in a single plot\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch_data, batch_labels, batch_patients_label in data_loader:\n",
    "            # Move data to the appropriate device\n",
    "            batch_data = batch_data.to(device)\n",
    "            outputs, attention_weight_batch, _ = model(batch_data)\n",
    "\n",
    "            # Process each patient in the batch\n",
    "            for patient_idx in range(batch_data.size(0)):\n",
    "                if batch_patients_label[patient_idx].item() == 1:  # Check if patient has positive label\n",
    "                    # Create a new figure for this patient\n",
    "                    fig = plt.figure(figsize=(cols * 4, rows * 4 + 2))  # Increased height for suptitle\n",
    "\n",
    "                    for img_idx in range(num_images):\n",
    "                        # Get the image and its label\n",
    "                        img = batch_data[patient_idx, img_idx].cpu().numpy()\n",
    "                        img_label = batch_labels[patient_idx, img_idx].cpu().numpy()\n",
    "                        \n",
    "                        # Get attention value\n",
    "                        if attention_weight_batch.size(1) == batch_data.size(1):\n",
    "                            attention_value = attention_weight_batch[patient_idx, img_idx].cpu().item()\n",
    "                        else:\n",
    "                            attention_value = attention_weight_batch[patient_idx].cpu().item()\n",
    "                        \n",
    "                        # Plot image\n",
    "                        plt.subplot(rows, cols, img_idx + 1)\n",
    "                        if CHANNELS == 3:  # RGB image\n",
    "                            plt.imshow(img)\n",
    "                        else:  # Grayscale image\n",
    "                            if img.ndim == 3:  # If shape is (1, H, W)\n",
    "                                img = np.squeeze(img)  # Convert to (H, W)\n",
    "                            plt.imshow(img, cmap='gray')\n",
    "                        \n",
    "                        plt.title(f'Label: {img_label}\\nAttention: {attention_value:.4f}', fontsize=12)\n",
    "                        plt.axis('off')\n",
    "\n",
    "                    # Add overall title for the patient\n",
    "                    plt.suptitle(f'Patient Images (Patient Label: {batch_patients_label[patient_idx].cpu().numpy()})', fontsize=16)\n",
    "                    plt.tight_layout(rect=[0, 0, 1, 0.97])  # Adjust rect to make space for suptitle\n",
    "                    plt.show()\n",
    "                                      \n",
    "                    # Since we are plotting only for one patient, return after the first plot\n",
    "                    return"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.095451,
     "end_time": "2024-10-04T19:24:03.197071",
     "exception": false,
     "start_time": "2024-10-04T19:24:03.101620",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:11.499019Z",
     "iopub.execute_input": "2024-11-09T12:04:11.499350Z",
     "iopub.status.idle": "2024-11-09T12:04:11.569343Z",
     "shell.execute_reply.started": "2024-11-09T12:04:11.499317Z",
     "shell.execute_reply": "2024-11-09T12:04:11.568408Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:12.297943Z",
     "start_time": "2024-11-14T16:23:12.270251Z"
    }
   },
   "outputs": [],
   "execution_count": 116
  },
  {
   "cell_type": "markdown",
   "source": "## Main",
   "metadata": {
    "papermill": {
     "duration": 0.016248,
     "end_time": "2024-10-04T19:24:03.231225",
     "exception": false,
     "start_time": "2024-10-04T19:24:03.214977",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "def set_seed(seed=42):\n    \"\"\"Set seed for reproducibility.\"\"\"\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    np.random.seed(seed)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:11.570677Z",
     "iopub.execute_input": "2024-11-09T12:04:11.571424Z",
     "iopub.status.idle": "2024-11-09T12:04:11.634204Z",
     "shell.execute_reply.started": "2024-11-09T12:04:11.571366Z",
     "shell.execute_reply": "2024-11-09T12:04:11.633349Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:12.343388Z",
     "start_time": "2024-11-14T16:23:12.320783Z"
    }
   },
   "outputs": [],
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "source": [
    "def main(mode='train'):\n",
    "    # Initialize W&B\n",
    "    wandb.init(project=\"your_project_name\")\n",
    "    \n",
    "    # Log hyperparameters\n",
    "    config = wandb.config\n",
    "    config.learning_rate = LEARNING_RATE\n",
    "    config.batch_size = TRAIN_BATCH_SIZE\n",
    "    config.num_epochs = NUM_EPOCHS\n",
    "\n",
    "    set_seed()\n",
    "    train_labels, val_labels, test_labels = split_dataset(patient_scan_labels, test_size=TEST_SIZE)\n",
    "    train_loader = get_train_loader(dicom_dir, train_labels, batch_size=TRAIN_BATCH_SIZE)\n",
    "    val_loader = get_train_loader(dicom_dir, val_labels, batch_size=VALID_BATCH_SIZE)\n",
    "    test_loader = get_test_loader(dicom_dir, test_labels, batch_size=TEST_BATCH_SIZE)\n",
    "\n",
    "    set_seed()\n",
    "    \n",
    "    # Initialize model, criterion, and optimizer\n",
    "    model = MILResNet18()\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    likelihood = likelihood.to(device) # Move likelihood to device before passing to mll\n",
    "\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    mll = gpytorch.mlls.VariationalELBO(likelihood, model.gp_layer, num_data=train_loader.__len__())\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    variational_optimizer = gpytorch.optim.NGD(model.gp_layer.variational_parameters(), num_data=train_loader.__len__(), lr=0.01)\n",
    "\n",
    "    if mode == 'train':\n",
    "        # Watch the model to log gradients and parameters\n",
    "        wandb.watch(model)\n",
    "\n",
    "        # Train model\n",
    "        trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, config.num_epochs, config.learning_rate, DEVICE, variational_optimizer, mll, likelihood)\n",
    "\n",
    "        # Save model\n",
    "        torch.save(trained_model.state_dict(), MODEL_PATH)\n",
    "\n",
    "    # Load best model\n",
    "    trained_model = load_model(MILResNet18, MODEL_PATH)\n",
    "\n",
    "    # Evaluate model\n",
    "    predictions, labels = evaluate_model(trained_model, test_loader, DEVICE, likelihood)\n",
    "    metrics = calculate_metrics(predictions, labels)\n",
    "    \n",
    "    # Log metrics to W&B\n",
    "    wandb.log(metrics)\n",
    "\n",
    "    print_metrics(metrics)\n",
    "\n",
    "    # Visualizations\n",
    "    plot_roc_curve(trained_model, test_loader, DEVICE, likelihood)\n",
    "    plot_confusion_matrix(trained_model, test_loader, DEVICE, likelihood)\n",
    "\n",
    "    if mode == 'train':\n",
    "        required_columns = ['patient_id', 'study_instance_uid', 'patient_label']\n",
    "        temp_test_labels = test_labels[required_columns]\n",
    "        \n",
    "        # Save results\n",
    "        results_df = get_test_results(trained_model, test_loader, temp_test_labels, device, likelihood)\n",
    "        results_df.to_csv('results/results.csv', index=False)\n",
    "        print(results_df.head())\n",
    "\n",
    "        # Log results DataFrame as a table in W&B (optional)\n",
    "        wandb.log({\"results\": wandb.Table(dataframe=results_df)})\n",
    "\n",
    "    # Call the function with the test_loader\n",
    "    test_loader = get_test_loader(dicom_dir, test_labels, batch_size=TEST_BATCH_SIZE)\n",
    "    plot_label_attention_weights(trained_model, test_loader, device, likelihood)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(mode='train')"
   ],
   "metadata": {
    "papermill": {
     "duration": 24983.553969,
     "end_time": "2024-10-05T02:20:26.801619",
     "exception": false,
     "start_time": "2024-10-04T19:24:03.247650",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-11-09T12:04:11.635549Z",
     "iopub.execute_input": "2024-11-09T12:04:11.635991Z",
     "iopub.status.idle": "2024-11-09T12:18:52.781211Z",
     "shell.execute_reply.started": "2024-11-09T12:04:11.635946Z",
     "shell.execute_reply": "2024-11-09T12:18:52.780156Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:19.997878Z",
     "start_time": "2024-11-14T16:23:12.369188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing last run (ID:dofre5vb) before initializing another..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rosy-glitter-74</strong> at: <a href='https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/your_project_name/runs/dofre5vb' target=\"_blank\">https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/your_project_name/runs/dofre5vb</a><br/> View project at: <a href='https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/your_project_name' target=\"_blank\">https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/your_project_name</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20241114_232132-dofre5vb/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Successfully finished last run (ID:dofre5vb). Initializing new run:<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/media/hskha23/Kha/Brain-Stroke-Diagnosis/rsna/wandb/run-20241114_232312-fl7iyuqd</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/your_project_name/runs/fl7iyuqd' target=\"_blank\">lunar-pond-75</a></strong> to <a href='https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/your_project_name' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/your_project_name' target=\"_blank\">https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/your_project_name</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/your_project_name/runs/fl7iyuqd' target=\"_blank\">https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/your_project_name/runs/fl7iyuqd</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 11.71 GiB of which 56.31 MiB is free. Process 8962 has 524.00 MiB memory in use. Including non-PyTorch memory, this process has 10.53 GiB memory in use. Of the allocated memory 10.31 GiB is allocated by PyTorch, and 14.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[118], line 73\u001B[0m\n\u001B[1;32m     70\u001B[0m     plot_label_attention_weights(trained_model, test_loader, device, likelihood)\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 73\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[118], line 35\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(mode)\u001B[0m\n\u001B[1;32m     32\u001B[0m wandb\u001B[38;5;241m.\u001B[39mwatch(model)\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# Train model\u001B[39;00m\n\u001B[0;32m---> 35\u001B[0m trained_model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDEVICE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariational_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmll\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlikelihood\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# Save model\u001B[39;00m\n\u001B[1;32m     38\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(trained_model\u001B[38;5;241m.\u001B[39mstate_dict(), MODEL_PATH)\n",
      "Cell \u001B[0;32mIn[112], line 87\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, learning_rate, device, variational_optimizer, mll, likelihood)\u001B[0m\n\u001B[1;32m     83\u001B[0m best_model_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;66;03m# Training phase\u001B[39;00m\n\u001B[0;32m---> 87\u001B[0m     train_loss, train_predictions, train_labels \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariational_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmll\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m     train_metrics \u001B[38;5;241m=\u001B[39m calculate_metrics(train_predictions, train_labels)\n\u001B[1;32m     89\u001B[0m     print_epoch_stats(epoch, num_epochs, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m, train_loss, train_metrics)\n",
      "Cell \u001B[0;32mIn[112], line 13\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[0;34m(model, data_loader, criterion, optimizer, scheduler, device, variational_optimizer, mll)\u001B[0m\n\u001B[1;32m     10\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m outputs, attention_weights, gp_output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m outputs \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39msqueeze()\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# loss = combined_loss(outputs, model.gp_layer, batch_patient_labels, alpha)\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[109], line 30\u001B[0m, in \u001B[0;36mMILResNet18.forward\u001B[0;34m(self, bags)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# batch_size, num_instances, c, h, w = bags.size()\u001B[39;00m\n\u001B[1;32m     28\u001B[0m bags_flattened \u001B[38;5;241m=\u001B[39m bags\u001B[38;5;241m.\u001B[39mview(batch_size \u001B[38;5;241m*\u001B[39m num_instances, c, h, w)\n\u001B[0;32m---> 30\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbags_flattened\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m features \u001B[38;5;241m=\u001B[39m features\u001B[38;5;241m.\u001B[39mview(batch_size, num_instances, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     32\u001B[0m attended_features, attended_weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention(features)\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001B[0m, in \u001B[0;36mResNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 285\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torchvision/models/resnet.py:276\u001B[0m, in \u001B[0;36mResNet._forward_impl\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    274\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer2(x)\n\u001B[1;32m    275\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer3(x)\n\u001B[0;32m--> 276\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer4\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    278\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mavgpool(x)\n\u001B[1;32m    279\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mflatten(x, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 219\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torchvision/models/resnet.py:97\u001B[0m, in \u001B[0;36mBasicBlock.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     94\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out)\n\u001B[1;32m     96\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(out)\n\u001B[0;32m---> 97\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbn2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownsample \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    100\u001B[0m     identity \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownsample(x)\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:176\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    169\u001B[0m     bn_training \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_mean \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_var \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    171\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001B[39;00m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001B[39;00m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001B[39;00m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 176\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001B[39;49;00m\n\u001B[1;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_mean\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbn_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexponential_average_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/functional.py:2512\u001B[0m, in \u001B[0;36mbatch_norm\u001B[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[0m\n\u001B[1;32m   2509\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m training:\n\u001B[1;32m   2510\u001B[0m     _verify_batch_size(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize())\n\u001B[0;32m-> 2512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2513\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_mean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_var\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackends\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcudnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menabled\u001B[49m\n\u001B[1;32m   2514\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 11.71 GiB of which 56.31 MiB is free. Process 8962 has 524.00 MiB memory in use. Including non-PyTorch memory, this process has 10.53 GiB memory in use. Of the allocated memory 10.31 GiB is allocated by PyTorch, and 14.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "cell_type": "markdown",
   "source": "## Results",
   "metadata": {}
  }
 ]
}
