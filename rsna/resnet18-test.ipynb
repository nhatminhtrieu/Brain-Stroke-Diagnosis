{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 9596701,
     "sourceType": "datasetVersion",
     "datasetId": 5854070
    },
    {
     "sourceId": 9546002,
     "sourceType": "datasetVersion",
     "datasetId": 5705276
    }
   ],
   "dockerImageVersionId": 30787,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "\n",
    "# Third-party imports\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "\n",
    "# Torchvision imports\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import ResNet18_Weights"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-10-11T18:09:09.379210Z",
     "iopub.execute_input": "2024-10-11T18:09:09.379674Z",
     "iopub.status.idle": "2024-10-11T18:09:15.813031Z",
     "shell.execute_reply.started": "2024-10-11T18:09:09.379608Z",
     "shell.execute_reply": "2024-10-11T18:09:15.812227Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-13T15:49:01.116188Z",
     "start_time": "2024-10-13T15:48:48.085056Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T12:11:35.868380Z",
     "start_time": "2024-10-12T12:11:34.650667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"GPUs Available: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"- {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPUs available.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available: 1\n",
      "- NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "## Dataset and Directory Configuration\n",
    "DATASET_NAME = 'rsna-cnn-training'\n",
    "HPC_DIR = '/media02/tdhoang01/21127112-21127734/data'\n",
    "OUTPUT_DIR = '/media02/tdhoang01/python-debugging/rsna/results'\n",
    "\n",
    "ZIP_FILE_PATH = os.path.join(HPC_DIR, DATASET_NAME + '.zip')\n",
    "CHECKPOINTS_DIR = os.path.join(OUTPUT_DIR, 'checkpoints')\n",
    "FIGURES_DIR = os.path.join(OUTPUT_DIR, 'figures')\n",
    "DICOM_DIR = f'{DATASET_NAME}/'\n",
    "\n",
    "## File Paths\n",
    "CSV_PATH = f'{DATASET_NAME}/training_20_scan_subset.csv'\n",
    "SLICE_LABEL_PATH = 'sorted_training_dataset_with_labels.csv'\n",
    "\n",
    "## Image Processing Parameters\n",
    "MAX_SLICES = 60\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "\n",
    "## Training Hyperparameters\n",
    "BATCH_PATIENTS = 8\n",
    "NUM_EPOCHS = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "## Dataset Split Ratios\n",
    "VAL_SIZE = 0.15\n",
    "TEST_SIZE = 0.15\n",
    "\n",
    "## Target Columns\n",
    "TARGET_COLUMNS = [\n",
    "    'any',\n",
    "    'epidural',\n",
    "    'intraparenchymal',\n",
    "    'intraventricular',\n",
    "    'subarachnoid',\n",
    "    'subdural'\n",
    "]\n",
    "\n",
    "## Create Necessary Directories\n",
    "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "\n",
    "## Load CSVs from zip\n",
    "with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:\n",
    "    patient_scan_labels = pd.read_csv(zip_ref.open(CSV_PATH))\n",
    "    patient_slice_labels = pd.read_csv(zip_ref.open(SLICE_LABEL_PATH))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-11T18:09:15.814689Z",
     "iopub.execute_input": "2024-10-11T18:09:15.815115Z",
     "iopub.status.idle": "2024-10-11T18:09:20.329455Z",
     "shell.execute_reply.started": "2024-10-11T18:09:15.815082Z",
     "shell.execute_reply": "2024-10-11T18:09:20.328536Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-12T12:11:38.169536Z",
     "start_time": "2024-10-12T12:11:36.193009Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "patient_scan_labels.head(1)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-11T18:09:20.339498Z",
     "iopub.execute_input": "2024-10-11T18:09:20.339815Z",
     "iopub.status.idle": "2024-10-11T18:09:20.375537Z",
     "shell.execute_reply.started": "2024-10-11T18:09:20.339784Z",
     "shell.execute_reply": "2024-10-11T18:09:20.374624Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-12T12:11:38.284483Z",
     "start_time": "2024-10-12T12:11:38.261832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    patient_id study_instance_uid  any  epidural  intraparenchymal  \\\n",
       "0  ID_0002cd41      ID_66929e09d4    0         0                 0   \n",
       "\n",
       "   intraventricular  subarachnoid  subdural  \n",
       "0                 0             0         0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>study_instance_uid</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_0002cd41</td>\n",
       "      <td>ID_66929e09d4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "patient_slice_labels.head(1)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-11T18:09:20.377129Z",
     "iopub.execute_input": "2024-10-11T18:09:20.377456Z",
     "iopub.status.idle": "2024-10-11T18:09:20.396076Z",
     "shell.execute_reply.started": "2024-10-11T18:09:20.377421Z",
     "shell.execute_reply": "2024-10-11T18:09:20.394910Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-12T12:11:38.372075Z",
     "start_time": "2024-10-12T12:11:38.352050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           filename  any  epidural  intraparenchymal  intraventricular  \\\n",
       "0  ID_45785016b.dcm    0         0                 0                 0   \n",
       "\n",
       "   subarachnoid  subdural   patient_id study_instance_uid series_instance_uid  \\\n",
       "0             0         0  ID_0002cd41      ID_66929e09d4       ID_e22a5534e6   \n",
       "\n",
       "                 image_position  samples_per_pixel         pixel_spacing  \\\n",
       "0  [-125.000, -122.596, 35.968]                  1  [0.488281, 0.488281]   \n",
       "\n",
       "   pixel_representation window_center window_width  rescale_intercept  \\\n",
       "0                     1            30           80            -1024.0   \n",
       "\n",
       "   rescale_slope         ID  \n",
       "0            1.0  45785016b  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>study_instance_uid</th>\n",
       "      <th>series_instance_uid</th>\n",
       "      <th>image_position</th>\n",
       "      <th>samples_per_pixel</th>\n",
       "      <th>pixel_spacing</th>\n",
       "      <th>pixel_representation</th>\n",
       "      <th>window_center</th>\n",
       "      <th>window_width</th>\n",
       "      <th>rescale_intercept</th>\n",
       "      <th>rescale_slope</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_45785016b.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_0002cd41</td>\n",
       "      <td>ID_66929e09d4</td>\n",
       "      <td>ID_e22a5534e6</td>\n",
       "      <td>[-125.000, -122.596, 35.968]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.488281, 0.488281]</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45785016b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T12:11:38.466401Z",
     "start_time": "2024-10-12T12:11:38.440106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DatasetGenerator(Dataset):\n",
    "    def __init__(self, zip_file_path, patient_scan_labels, patient_slice_labels, max_slices, height, width, target_columns):\n",
    "        self.zip_file_path = zip_file_path\n",
    "        self.patient_scan_labels = patient_scan_labels\n",
    "        self.patient_slice_labels = patient_slice_labels\n",
    "        self.max_slices = max_slices\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.target_columns = target_columns\n",
    "        self.channels = 3\n",
    "        self.dicom_paths = self._get_dicom_paths()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((self.height, self.width))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dicom_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dicom_files, _ = self.dicom_paths[idx]\n",
    "        images, labels = self._process_dicom_files(dicom_files)\n",
    "        return self._pad_data(images, labels)\n",
    "\n",
    "    def _get_dicom_paths(self):\n",
    "        dicom_paths = []\n",
    "        with zipfile.ZipFile(self.zip_file_path, 'r') as dicom_zip:\n",
    "            zip_file_list = dicom_zip.namelist()\n",
    "            top_level_folder = f\"{DATASET_NAME}/{DATASET_NAME}/\"\n",
    "\n",
    "            for _, row in self.patient_scan_labels.iterrows():\n",
    "                patient_id = row['patient_id'].replace(\"ID_\", \"\")\n",
    "                study_instance_uid = row['study_instance_uid'].replace(\"ID_\", \"\")\n",
    "                dicom_dir_path = f\"{top_level_folder}{patient_id}_{study_instance_uid}/\"\n",
    "                dicom_files = [f for f in zip_file_list if f.startswith(dicom_dir_path) and f.endswith(\".dcm\")]\n",
    "                \n",
    "                if dicom_files:\n",
    "                    dicom_paths.append((dicom_files, row))\n",
    "                else:\n",
    "                    print(f\"No DICOM files found in {dicom_dir_path} within the zip file.\")\n",
    "        \n",
    "        return dicom_paths\n",
    "\n",
    "    def _process_dicom_files(self, dicom_files):\n",
    "        images = []\n",
    "        labels = []\n",
    "        with zipfile.ZipFile(self.zip_file_path, 'r') as dicom_zip:\n",
    "            for dicom_file in dicom_files:\n",
    "                with dicom_zip.open(dicom_file) as file:\n",
    "                    dicom = pydicom.dcmread(file)\n",
    "                    img = self._preprocess_slice(dicom)\n",
    "                    images.append(torch.from_numpy(img).float())\n",
    "                    labels.append(self._get_label(dicom_file))\n",
    "        \n",
    "        return torch.stack(images), torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def _preprocess_slice(self, dicom):\n",
    "        bsb_img = self._bsb_window(dicom)\n",
    "        return bsb_img.astype(np.float16)\n",
    "\n",
    "    def _get_label(self, dicom_file):\n",
    "        file_key = os.path.basename(dicom_file)\n",
    "        label_row = self.patient_slice_labels[self.patient_slice_labels['filename'] == file_key]\n",
    "        return 1.0 if not label_row.empty and np.any(label_row[self.target_columns].values == 1) else 0.0\n",
    "\n",
    "    def _pad_data(self, images, labels):\n",
    "        if images.shape[0] < self.max_slices:\n",
    "            padding = torch.zeros((self.max_slices - images.shape[0], self.channels, self.height, self.width))\n",
    "            images = torch.cat((images, padding), dim=0)\n",
    "            label_padding = torch.zeros(self.max_slices - labels.shape[0])\n",
    "            labels = torch.cat((labels, label_padding))\n",
    "        return images, labels\n",
    "\n",
    "    def _correct_dcm(self, dcm):\n",
    "        x = dcm.pixel_array + 1000\n",
    "        px_mode = 4096\n",
    "        x[x >= px_mode] -= px_mode\n",
    "        dcm.PixelData = x.tobytes()\n",
    "        dcm.RescaleIntercept = -1000\n",
    "\n",
    "    def _window_image(self, dcm, window_center, window_width):\n",
    "        if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):\n",
    "            self._correct_dcm(dcm)\n",
    "        \n",
    "        img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n",
    "        img = cv2.resize(img, (self.height, self.width), interpolation=cv2.INTER_LINEAR)\n",
    "       \n",
    "        img_min = window_center - window_width // 2\n",
    "        img_max = window_center + window_width // 2\n",
    "        img = np.clip(img, img_min, img_max)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def _bsb_window(self, dcm):\n",
    "        brain_img = self._window_image(dcm, 40, 80)\n",
    "        subdural_img = self._window_image(dcm, 80, 200)\n",
    "        soft_img = self._window_image(dcm, 40, 380)\n",
    "        \n",
    "        brain_img = (brain_img - 0) / 80\n",
    "        subdural_img = (subdural_img - (-20)) / 200\n",
    "        soft_img = (soft_img - (-150)) / 380\n",
    "        \n",
    "        bsb_img = np.stack([brain_img, subdural_img, soft_img], axis=0)\n",
    "        return bsb_img"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "class DataloaderManager:\n",
    "    def __init__(self, dataset, batch_size, val_size, test_size, num_workers=4):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.val_size = val_size\n",
    "        self.test_size = test_size\n",
    "        self.num_workers = num_workers\n",
    "        self.train_loader = None\n",
    "        self.validate_loader = None\n",
    "        self.test_loader = None\n",
    "        self._create_loaders()\n",
    "\n",
    "    def print_dataset_length(self):\n",
    "        print(f\"Length of dataset: {len(self.dataset)}\")\n",
    "\n",
    "    def print_lengths(self):\n",
    "        print(f\"Length of training dataset: {len(self.train_loader.dataset)}\")\n",
    "        print(f\"Length of validation dataset: {len(self.validate_loader.dataset)}\")\n",
    "        print(f\"Length of testing dataset: {len(self.test_loader.dataset)}\")\n",
    "    \n",
    "    def _create_loaders(self):\n",
    "        dataset_length = len(self.dataset)\n",
    "        print(f\"Dataset length: {dataset_length}\")\n",
    "\n",
    "        # Create masks for indices with and without label 1\n",
    "        label_mask = np.array([1 in sample[1].tolist() for sample in self.dataset])\n",
    "        indices_with_one = np.where(label_mask)[0]\n",
    "        indices_without_one = np.where(~label_mask)[0]\n",
    "\n",
    "        print(f\"Total indices with one: {len(indices_with_one)}\")\n",
    "\n",
    "        # Calculate split sizes\n",
    "        val_size = int(dataset_length * self.val_size)\n",
    "        test_size = int(dataset_length * self.test_size)\n",
    "\n",
    "        # Shuffle and split indices\n",
    "        np.random.shuffle(indices_with_one)\n",
    "        np.random.shuffle(indices_without_one)\n",
    "\n",
    "        val_one_count = int(len(indices_with_one) * self.val_size)\n",
    "        test_one_count = int(len(indices_with_one) * self.test_size)\n",
    "\n",
    "        val_indices = np.concatenate((\n",
    "            indices_with_one[:val_one_count],\n",
    "            indices_without_one[:val_size - val_one_count]\n",
    "        ))\n",
    "\n",
    "        test_indices = np.concatenate((\n",
    "            indices_with_one[val_one_count:val_one_count + test_one_count],\n",
    "            indices_without_one[val_size - val_one_count:val_size - val_one_count + test_size - test_one_count]\n",
    "        ))\n",
    "\n",
    "        train_indices = np.concatenate((\n",
    "            indices_with_one[val_one_count + test_one_count:],\n",
    "            indices_without_one[val_size - val_one_count + test_size - test_one_count:]\n",
    "        ))\n",
    "\n",
    "        # Create datasets from selected indices using Subset\n",
    "        train_dataset = Subset(self.dataset, train_indices)\n",
    "        val_dataset = Subset(self.dataset, val_indices)\n",
    "        test_dataset = Subset(self.dataset, test_indices)\n",
    "\n",
    "        # Create DataLoaders for each set\n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "        self.validate_loader = DataLoader(val_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def visualize_label_distribution(self):\n",
    "        for loader_name, loader in zip(['Training', 'Validation', 'Testing'], \n",
    "                                        [self.train_loader, self.validate_loader, self.test_loader]):\n",
    "            all_labels = []\n",
    "            for _, labels in loader:\n",
    "                all_labels.extend(labels.view(-1).numpy().tolist())\n",
    "\n",
    "            label_counts = Counter(all_labels)\n",
    "            counts = [label_counts.get(0, 0), label_counts.get(1, 0)]\n",
    "            labels = [0, 1]\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            bars = plt.bar(labels, counts, color='blue')\n",
    "            plt.xlabel('Labels')\n",
    "            plt.ylabel('Counts')\n",
    "            plt.title(f'Label Distribution - {loader_name} Set')\n",
    "            plt.xticks(labels)\n",
    "\n",
    "            for bar in bars:\n",
    "                yval = bar.get_height()\n",
    "                plt.text(bar.get_x() + bar.get_width()/2, yval, int(yval), ha='center', va='bottom')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-11T18:09:20.428840Z",
     "iopub.execute_input": "2024-10-11T18:09:20.429490Z",
     "iopub.status.idle": "2024-10-11T18:09:20.450111Z",
     "shell.execute_reply.started": "2024-10-11T18:09:20.429443Z",
     "shell.execute_reply": "2024-10-11T18:09:20.449233Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-12T12:11:38.630533Z",
     "start_time": "2024-10-12T12:11:38.608963Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = DatasetGenerator(\n",
    "    zip_file_path=ZIP_FILE_PATH,\n",
    "    patient_scan_labels=patient_scan_labels,\n",
    "    patient_slice_labels=patient_slice_labels,\n",
    "    max_slices=MAX_SLICES,\n",
    "    height=HEIGHT,\n",
    "    width=WIDTH,\n",
    "    target_columns=TARGET_COLUMNS\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-11T18:09:20.451320Z",
     "iopub.execute_input": "2024-10-11T18:09:20.451674Z",
     "iopub.status.idle": "2024-10-11T18:09:37.258880Z",
     "shell.execute_reply.started": "2024-10-11T18:09:20.451640Z",
     "shell.execute_reply": "2024-10-11T18:09:37.257901Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-12T12:11:41.267796Z",
     "start_time": "2024-10-12T12:11:38.758651Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": "images, labels = dataset[0]\n\nprint(images.shape, labels.shape)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-11T18:09:37.260451Z",
     "iopub.execute_input": "2024-10-11T18:09:37.260893Z",
     "iopub.status.idle": "2024-10-11T18:09:43.744706Z",
     "shell.execute_reply.started": "2024-10-11T18:09:37.260849Z",
     "shell.execute_reply": "2024-10-11T18:09:43.743680Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-12T12:11:43.685327Z",
     "start_time": "2024-10-12T12:11:41.441262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 3, 224, 224]) torch.Size([60])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "dataloader_manager = DataloaderManager(dataset, batch_size=BATCH_PATIENTS, val_size=VAL_SIZE, test_size=TEST_SIZE)\n",
    "\n",
    "# Accessing the loaders\n",
    "train_loader = dataloader_manager.train_loader\n",
    "validate_loader = dataloader_manager.validate_loader\n",
    "test_loader = dataloader_manager.test_loader"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-11T18:09:43.748011Z",
     "iopub.execute_input": "2024-10-11T18:09:43.748343Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-12T12:13:01.861765Z",
     "start_time": "2024-10-12T12:11:43.732648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dataloader_manager \u001B[38;5;241m=\u001B[39m \u001B[43mDataloaderManager\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBATCH_PATIENTS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mVAL_SIZE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mTEST_SIZE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Accessing the loaders\u001B[39;00m\n\u001B[1;32m      4\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m dataloader_manager\u001B[38;5;241m.\u001B[39mtrain_loader\n",
      "Cell \u001B[0;32mIn[8], line 11\u001B[0m, in \u001B[0;36mDataloaderManager.__init__\u001B[0;34m(self, dataset, batch_size, val_size, test_size, num_workers)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalidate_loader \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_loader \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_loaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 26\u001B[0m, in \u001B[0;36mDataloaderManager._create_loaders\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset length: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset_length\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Create masks for indices with and without label 1\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m label_mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01min\u001B[39;00m sample[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist() \u001B[38;5;28;01mfor\u001B[39;00m sample \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset])\n\u001B[1;32m     27\u001B[0m indices_with_one \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mwhere(label_mask)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     28\u001B[0m indices_without_one \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mwhere(\u001B[38;5;241m~\u001B[39mlabel_mask)[\u001B[38;5;241m0\u001B[39m]\n",
      "Cell \u001B[0;32mIn[8], line 26\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset length: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset_length\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Create masks for indices with and without label 1\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m label_mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01min\u001B[39;00m sample[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist() \u001B[38;5;28;01mfor\u001B[39;00m sample \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset])\n\u001B[1;32m     27\u001B[0m indices_with_one \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mwhere(label_mask)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     28\u001B[0m indices_without_one \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mwhere(\u001B[38;5;241m~\u001B[39mlabel_mask)[\u001B[38;5;241m0\u001B[39m]\n",
      "Cell \u001B[0;32mIn[7], line 21\u001B[0m, in \u001B[0;36mDatasetGenerator.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[1;32m     20\u001B[0m     dicom_files, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdicom_paths[idx]\n\u001B[0;32m---> 21\u001B[0m     images, labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_dicom_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdicom_files\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pad_data(images, labels)\n",
      "Cell \u001B[0;32mIn[7], line 49\u001B[0m, in \u001B[0;36mDatasetGenerator._process_dicom_files\u001B[0;34m(self, dicom_files)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dicom_file \u001B[38;5;129;01min\u001B[39;00m dicom_files:\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m dicom_zip\u001B[38;5;241m.\u001B[39mopen(dicom_file) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[0;32m---> 49\u001B[0m         dicom \u001B[38;5;241m=\u001B[39m \u001B[43mpydicom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdcmread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_preprocess_slice(dicom)\n\u001B[1;32m     51\u001B[0m         images\u001B[38;5;241m.\u001B[39mappend(torch\u001B[38;5;241m.\u001B[39mfrom_numpy(img)\u001B[38;5;241m.\u001B[39mfloat())\n",
      "File \u001B[0;32m/media02/tdhoang01/.virtualenvs/myenv/lib/python3.10/site-packages/pydicom/filereader.py:1078\u001B[0m, in \u001B[0;36mdcmread\u001B[0;34m(fp, defer_size, stop_before_pixels, force, specific_tags)\u001B[0m\n\u001B[1;32m   1076\u001B[0m     stop_when \u001B[38;5;241m=\u001B[39m _at_pixel_data\n\u001B[1;32m   1077\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1078\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[43mread_partial\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstop_when\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1081\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdefer_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize_in_bytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdefer_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[43m        \u001B[49m\u001B[43mspecific_tags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspecific_tags\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1085\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1086\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m caller_owns_file:\n",
      "File \u001B[0;32m/media02/tdhoang01/.virtualenvs/myenv/lib/python3.10/site-packages/pydicom/filereader.py:924\u001B[0m, in \u001B[0;36mread_partial\u001B[0;34m(fileobj, stop_when, defer_size, force, specific_tags)\u001B[0m\n\u001B[1;32m    920\u001B[0m \u001B[38;5;66;03m# Try and decode the dataset\u001B[39;00m\n\u001B[1;32m    921\u001B[0m \u001B[38;5;66;03m#   By this point we should be at the start of the dataset and have\u001B[39;00m\n\u001B[1;32m    922\u001B[0m \u001B[38;5;66;03m#   the transfer syntax (whether read from the file meta or guessed at)\u001B[39;00m\n\u001B[1;32m    923\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 924\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[43mread_dataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfileobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_implicit_VR\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    927\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_little_endian\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstop_when\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop_when\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    929\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdefer_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefer_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    930\u001B[0m \u001B[43m        \u001B[49m\u001B[43mspecific_tags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspecific_tags\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    931\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    932\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mEOFError\u001B[39;00m:\n\u001B[1;32m    933\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39msettings\u001B[38;5;241m.\u001B[39mreading_validation_mode \u001B[38;5;241m==\u001B[39m config\u001B[38;5;241m.\u001B[39mRAISE:\n",
      "File \u001B[0;32m/media02/tdhoang01/.virtualenvs/myenv/lib/python3.10/site-packages/pydicom/filereader.py:476\u001B[0m, in \u001B[0;36mread_dataset\u001B[0;34m(fp, is_implicit_VR, is_little_endian, bytelength, stop_when, defer_size, parent_encoding, specific_tags, at_top_level)\u001B[0m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    475\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m bytelength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 476\u001B[0m         raw_data_elements \u001B[38;5;241m=\u001B[39m {e\u001B[38;5;241m.\u001B[39mtag: e \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m de_gen}\n\u001B[1;32m    477\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    478\u001B[0m         \u001B[38;5;28;01mwhile\u001B[39;00m fp_tell() \u001B[38;5;241m-\u001B[39m fp_start \u001B[38;5;241m<\u001B[39m bytelength:\n",
      "File \u001B[0;32m/media02/tdhoang01/.virtualenvs/myenv/lib/python3.10/site-packages/pydicom/filereader.py:476\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    475\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m bytelength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 476\u001B[0m         raw_data_elements \u001B[38;5;241m=\u001B[39m {e\u001B[38;5;241m.\u001B[39mtag: e \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m de_gen}\n\u001B[1;32m    477\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    478\u001B[0m         \u001B[38;5;28;01mwhile\u001B[39;00m fp_tell() \u001B[38;5;241m-\u001B[39m fp_start \u001B[38;5;241m<\u001B[39m bytelength:\n",
      "File \u001B[0;32m/media02/tdhoang01/.virtualenvs/myenv/lib/python3.10/site-packages/pydicom/filereader.py:237\u001B[0m, in \u001B[0;36mdata_element_generator\u001B[0;34m(fp, is_implicit_VR, is_little_endian, stop_when, defer_size, encoding, specific_tags)\u001B[0m\n\u001B[1;32m    234\u001B[0m     fp_seek(fp_tell() \u001B[38;5;241m+\u001B[39m length)\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     value \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 237\u001B[0m         \u001B[43mfp_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlength\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    238\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m length \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    239\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m cast(\u001B[38;5;28mbytes\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, empty_value_for_VR(vr, raw\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[1;32m    240\u001B[0m     )\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m debugging:\n\u001B[1;32m    242\u001B[0m         dotdot \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m length \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m20\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m   \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/usr/lib/python3.10/zipfile.py:930\u001B[0m, in \u001B[0;36mZipExtFile.read\u001B[0;34m(self, n)\u001B[0m\n\u001B[1;32m    928\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_offset \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    929\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m n \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eof:\n\u001B[0;32m--> 930\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    931\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(data):\n\u001B[1;32m    932\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_readbuffer \u001B[38;5;241m=\u001B[39m data\n",
      "File \u001B[0;32m/usr/lib/python3.10/zipfile.py:1006\u001B[0m, in \u001B[0;36mZipExtFile._read1\u001B[0;34m(self, n)\u001B[0m\n\u001B[1;32m   1004\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compress_type \u001B[38;5;241m==\u001B[39m ZIP_DEFLATED:\n\u001B[1;32m   1005\u001B[0m     n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(n, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mMIN_READ_SIZE)\n\u001B[0;32m-> 1006\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_decompressor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecompress\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1007\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eof \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decompressor\u001B[38;5;241m.\u001B[39meof \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m   1008\u001B[0m                  \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compress_left \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m   1009\u001B[0m                  \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decompressor\u001B[38;5;241m.\u001B[39munconsumed_tail)\n\u001B[1;32m   1010\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eof:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": "dataloader_manager.print_lengths()",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "dataloader_manager.visualize_label_distribution()",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_image_grid(dataloader, grid_rows=10, max_slices=MAX_SLICES):\n",
    "    \"\"\"\n",
    "    Plot a grid of images from the given DataLoader.\n",
    "    \n",
    "    Args:\n",
    "    dataloader (DataLoader): DataLoader containing batches of images and labels.\n",
    "    grid_rows (int): Number of rows in the grid\n",
    "    max_slices (int): Maximum number of slices to plot\n",
    "    \"\"\"\n",
    "    # Get a first value in batch from the DataLoader\n",
    "    for batch_images, batch_labels in dataloader:\n",
    "        image_tensor = batch_images[0]\n",
    "        label_tensor = batch_labels[0]\n",
    "        break\n",
    "\n",
    "    num_slices = min(image_tensor.shape[0], max_slices)  # Ensure we don't exceed the number of slices\n",
    "    grid_cols = int(max_slices / grid_rows)  # Calculate number of columns\n",
    "    \n",
    "    # Calculate the figure size based on the image dimensions\n",
    "    img_size = HEIGHT # or WIDTH\n",
    "    dpi = plt.rcParams['figure.dpi']  # Get the default DPI\n",
    "    figsize = (grid_cols * img_size / dpi, grid_rows * img_size / dpi)\n",
    "    \n",
    "    fig, axes = plt.subplots(grid_rows, grid_cols, figsize=figsize)\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "    \n",
    "    # Loop through the number of slices and plot each image\n",
    "    for i in range(num_slices):\n",
    "        axes[i].imshow(image_tensor[i].permute(1, 2, 0).cpu().numpy())  # Convert to (height, width, channels) for plotting\n",
    "        axes[i].set_title(f\"Label: {label_tensor[i].item()}\")\n",
    "        axes[i].axis('off')  # Turn off axis for all subplots\n",
    "    \n",
    "    # Turn off any remaining empty subplots\n",
    "    for i in range(num_slices, grid_rows * grid_cols):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# plot_image_grid(test_loader)",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# 2. Model Definition\nclass ResNet18(nn.Module):\n    def __init__(self, num_classes=1):\n        super(ResNet18, self).__init__()\n        self.resnet = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n        self.dropout = nn.Dropout(p=0.3)  # Add dropout layer\n\n    def forward(self, x):\n        batch_patients, num_slices, channels, height, width = x.size()\n        x = x.view(-1, channels, height, width)\n        x = self.resnet(x)\n        return self.dropout(x)  # Apply dropout before returning\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = ResNet18().to(device)",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Loss and Optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "# mode: Monitors 'min' or 'max' changes in metrics.\n",
    "# factor: The multiplicative factor for reducing the learning rate. \n",
    "##  If the current learning rate is 0.01 and factor=0.5, the new learning rate will be 0.01 * 0.5 = 0.005\n",
    "# patience: Number of epochs to wait for improvement before reducing the learning rate."
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def train(model, train_loader, criterion, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image).squeeze()\n",
    "        label = label.reshape(-1)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted_label = (output > 0.5).float()\n",
    "        total += label.size(0)\n",
    "        correct += (predicted_label == label).sum().item()\n",
    "\n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f'Epoch {epoch+1}: Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}%')\n",
    "\n",
    "    scheduler.step(epoch_loss)\n",
    "    return epoch_loss"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def validate(model, validate_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (image, label) in enumerate(validate_loader):\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(image).squeeze()\n",
    "            label = label.reshape(-1)\n",
    "            \n",
    "            loss = criterion(output, label)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            predicted_label = (output > 0.5).float()\n",
    "            total += label.size(0)\n",
    "            correct += (predicted_label == label).sum().item()\n",
    "    \n",
    "    # Calculate average loss and accuracy for validation\n",
    "    val_loss = running_loss / len(validate_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.4f}%')\n",
    "    \n",
    "    return val_loss"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def save_checkpoint(model, optimizer, scheduler, epoch, loss):\n",
    "    checkpoint_path = os.path.join(CHECKPOINTS_DIR, f'checkpoint_epoch_{epoch+1}.pth')    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'loss': loss\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_checkpoint(checkpoint_path, model, optimizer, scheduler):\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f'Loaded checkpoint from {checkpoint_path} (Epoch: {epoch}, Loss: {loss:.4f})')\n",
    "    return epoch, loss"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_roc_curve(y_true, y_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(FIGURES_DIR, 'roc_curve.png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(FIGURES_DIR, 'confusion_matrix.png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def evaluate(model, test_loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    all_labels = []\n    all_predictions = []\n    all_scores = []\n\n    with torch.no_grad():\n        for image, label in test_loader:\n            image, label = image.to(device), label.to(device)\n            \n            output = model(image).squeeze()\n            label = label.reshape(-1)\n            \n            predicted_label = (output > 0.5).float()\n            total += label.size(0)\n            correct += (predicted_label == label).sum().item()\n            \n            # Collecting true labels and scores for ROC and confusion matrix\n            all_labels.extend(label.cpu().numpy())\n            all_predictions.extend(predicted_label.cpu().numpy())\n            all_scores.extend(output.cpu().numpy())\n\n    accuracy = 100 * correct / total\n    print(f'Test Accuracy: {accuracy:.4f}%')\n    \n    # Plot ROC Curve\n    plot_roc_curve(np.array(all_labels), np.array(all_scores))\n    \n    # Plot Confusion Matrix\n    plot_confusion_matrix(np.array(all_labels), np.array(all_predictions))",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, scheduler, device)\n",
    "    val_loss = validate(model, validate_loader, criterion, device)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        save_checkpoint(model, optimizer, scheduler, epoch, val_loss, val_accuracy)\n",
    "        best_val_loss = val_loss"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "evaluate(model, test_loader, device)",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
