{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage.transform import resize\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GPU Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "SEED = 202408\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Constants\n",
    "TEST_SIZE = 0.02\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "CHANNELS = 3\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "VALID_BATCH_SIZE = 1\n",
    "TEST_BATCH_SIZE = 1\n",
    "SHAPE = (HEIGHT, WIDTH, CHANNELS)\n",
    "\n",
    "# Folders\n",
    "DATA_DIR = './rsna-mil-training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_slice(slice, target_size=(WIDTH, HEIGHT)):\n",
    "    slice = resize(slice, target_size, anti_aliasing=True)\n",
    "    \n",
    "    slice = apply_windowing(slice)\n",
    "    \n",
    "    return slice\n",
    "\n",
    "def apply_windowing(slice):\n",
    "    brain_window = (40, 80, -100, 200)\n",
    "    slice = np.clip(slice, brain_window[2], brain_window[3])\n",
    "    slice = (slice - brain_window[2]) / (brain_window[3] - brain_window[2])\n",
    "    return slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dicom_folder(folder_path):\n",
    "    slices = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".dcm\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            ds = pydicom.dcmread(file_path)\n",
    "            slices.append(ds.pixel_array)\n",
    "    \n",
    "    # Add black images if the number of slices is less than 60\n",
    "    num_slices = len(slices)\n",
    "    if num_slices < 60:\n",
    "        black_slice = np.zeros_like(slices[0])\n",
    "        for _ in range(60 - num_slices):\n",
    "            slices.append(black_slice)\n",
    "    \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_patient_data(data_dir, row):\n",
    "    \"\"\"\n",
    "    Process data for a single patient based on the row from the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): The directory containing DICOM folders.\n",
    "        row (pd.Series): A row from the patient_scan_labels DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: Preprocessed slices and label.\n",
    "    \"\"\"\n",
    "    patient_id = row['patient_id'].replace('ID_', '')  # Remove 'ID_' prefix\n",
    "    study_instance_uid = row['study_instance_uid'].replace('ID_', '')  # Remove 'ID_' prefix\n",
    "    \n",
    "    # Construct folder path based on patient_id and study_instance_uid\n",
    "    folder_name = f\"{patient_id}_{study_instance_uid}\"\n",
    "    folder_path = os.path.join(data_dir, folder_name)\n",
    "    \n",
    "    # Read and preprocess DICOM slices\n",
    "    if os.path.exists(folder_path):\n",
    "        slices = read_dicom_folder(folder_path)\n",
    "        preprocessed_slices = [preprocess_slice(slice) for slice in slices]\n",
    "        \n",
    "        # Determine label based on any of the hemorrhage indicators\n",
    "        label = 1 if row[['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']].any() else 0\n",
    "        \n",
    "        return preprocessed_slices, label\n",
    "    else:\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        return None, None  # Handle the case where the folder is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDatasetGenerator(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class for training data.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, patient_scan_labels):\n",
    "        self.data_dir = data_dir\n",
    "        self.patient_scan_labels = patient_scan_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_scan_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.patient_scan_labels.iloc[idx]\n",
    "        preprocessed_slices, label = process_patient_data(self.data_dir, row)\n",
    "        \n",
    "        if preprocessed_slices is not None:\n",
    "            # Convert the list of numpy arrays to a single numpy array\n",
    "            preprocessed_slices = np.array(preprocessed_slices)  # Convert to numpy array\n",
    "            return torch.tensor(preprocessed_slices, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "        else:\n",
    "            return None, None  # Handle the case where the folder is not found\n",
    "\n",
    "class TestDatasetGenerator(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class for testing data.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, patient_scan_labels):\n",
    "        self.data_dir = data_dir\n",
    "        self.patient_scan_labels = patient_scan_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_scan_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.patient_scan_labels.iloc[idx]\n",
    "        preprocessed_slices, label = process_patient_data(self.data_dir, row)\n",
    "        \n",
    "        if preprocessed_slices is not None:\n",
    "            # Convert the list of numpy arrays to a single numpy array\n",
    "            preprocessed_slices = np.array(preprocessed_slices)  # Convert to numpy array\n",
    "            return torch.tensor(preprocessed_slices, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "        else:\n",
    "            return None, None  # Handle the case where the folder is not found\n",
    "        \n",
    "\n",
    "# Function to create DataLoader for training\n",
    "def get_train_loader(data_dir, patient_scan_labels, batch_size=TRAIN_BATCH_SIZE, shuffle=True):\n",
    "    train_dataset = TrainDatasetGenerator(data_dir, patient_scan_labels)\n",
    "    return DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# Function to create DataLoader for testing\n",
    "def get_test_loader(data_dir, patient_scan_labels, batch_size=TEST_BATCH_SIZE):\n",
    "    test_dataset = TestDatasetGenerator(data_dir, patient_scan_labels)\n",
    "    return DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNFeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN backbone to extract features from each slice\n",
    "    \"\"\"\n",
    "    def __init__(self, slice_size=(224, 224), num_slices=60, batch_size=10):\n",
    "        super().__init__()\n",
    "        self.slice_size = slice_size\n",
    "        self.num_slices = num_slices\n",
    "        self.batch_size = batch_size  # New parameter for batch processing\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * (slice_size[0] // 4) * (slice_size[1] // 4), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure input has the expected number of slices\n",
    "        if x.size(1) < self.num_slices:\n",
    "            padding = torch.zeros(x.size(0), self.num_slices - x.size(1), *self.slice_size, device=x.device)\n",
    "            x = torch.cat([x, padding], dim=1)\n",
    "        elif x.size(1) > self.num_slices:\n",
    "            x = x[:, :self.num_slices]\n",
    "\n",
    "        # Pass slices through CNN layers in batches\n",
    "        slice_features = []\n",
    "        for i in range(0, self.num_slices, self.batch_size):\n",
    "            slice_batch = x[:, i:i+self.batch_size]  # Select a batch of slices\n",
    "            slice_batch = slice_batch.unsqueeze(2)  # Shape: (batch_size, batch_size, 1, height, width)\n",
    "            slice_batch = slice_batch.view(-1, 1, *self.slice_size)  # Reshape for CNN input\n",
    "            \n",
    "            # Forward pass through CNN\n",
    "            batch_features = self.cnn(slice_batch)  # Shape: (batch_size * batch_size, feature_dim)\n",
    "            slice_features.append(batch_features.detach())  # Detach to save memory\n",
    "\n",
    "        # Stack features and reshape back to (batch_size, num_slices, feature_dim)\n",
    "        slice_features = torch.cat(slice_features, dim=0).view(x.size(0), self.num_slices, -1)\n",
    "\n",
    "        # Aggregate features across slices (mean, max, etc.)\n",
    "        aggregated_features = slice_features.mean(dim=1)  # Shape: (batch_size, feature_dim)\n",
    "\n",
    "        # Squeeze the output to match the target shape\n",
    "        output = aggregated_features.squeeze()  # Shape: (batch_size,)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention mechanism to aggregate slice features into bag features\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(input_dim, output_dim)\n",
    "        self.v = nn.Parameter(torch.rand(output_dim))\n",
    "        \n",
    "    def forward(self, features):\n",
    "        # Compute attention weights for each slice\n",
    "        att_weights = torch.softmax(torch.tanh(self.W(features)) @ self.v, dim=1)\n",
    "        return att_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class E2EAttGP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = CNNFeatureExtractor()\n",
    "        self.attention = AttentionLayer(input_dim=64, output_dim=32)  # Adjust input_dim based on CNN output\n",
    "        self.classifier = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is expected to be of shape (batch_size, num_slices, height, width)\n",
    "        slice_features = []\n",
    "\n",
    "        for i in range(x.size(1)):  # Loop over each slice in the batch\n",
    "            slice_input = x[:, i, :, :].unsqueeze(1)  # Shape: (batch_size, 1, height, width)\n",
    "            slice_feature = self.cnn(slice_input)  # Process each slice through CNN\n",
    "            slice_features.append(slice_feature)\n",
    "\n",
    "        slice_features = torch.stack(slice_features, dim=1)  # Shape: (batch_size, num_slices, feature_dim)\n",
    "        \n",
    "        # Compute attention weights for each slice\n",
    "        att_weights = self.attention(slice_features)\n",
    "        \n",
    "        # Aggregate slice features into bag feature using attention\n",
    "        bag_feature = (slice_features * att_weights.unsqueeze(-1)).sum(dim=1)  # Shape: (batch_size, 64)\n",
    "\n",
    "        # Pass bag feature through the classifier\n",
    "        logits = self.classifier(bag_feature)  # size (batch_size, 1)\n",
    "        probs = self.sigmoid(logits)\n",
    "        \n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './rsna-mil-training'\n",
    "patient_scan_labels = pd.read_csv('training_1000_scan_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_train_loader(data_dir, patient_scan_labels, batch_size=TRAIN_BATCH_SIZE)\n",
    "test_loader = get_test_loader(data_dir, patient_scan_labels, batch_size=TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "model = E2EAttGP().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print('############################################')\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "    model.train()\n",
    "    total_loss = 0  # To track total loss for the epoch\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    train_loader_tqdm = tqdm(train_loader, leave=False)\n",
    "    for batch_slices, batch_labels in train_loader_tqdm:\n",
    "        batch_slices = batch_slices.to(device)  # Move batch to GPU\n",
    "        batch_labels = batch_labels.to(device)  # Move labels to GPU\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_slices)\n",
    "        loss = criterion(outputs, batch_labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()  # Accumulate loss\n",
    "        predicted = (outputs >= 0.5).float()  # Convert outputs to binary predictions\n",
    "        correct += (predicted.squeeze() == batch_labels.float()).sum().item()  # Count correct predictions\n",
    "        total += batch_labels.size(0)  # Update total count\n",
    "\n",
    "        # Calculate accuracy for the batch\n",
    "        batch_accuracy = (predicted.squeeze() == batch_labels.float()).float().mean().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_loader_tqdm.set_description(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "        train_loader_tqdm.set_postfix(loss=loss.item(), accuracy=batch_accuracy)\n",
    "\n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_slices, batch_labels in test_loader:\n",
    "        outputs = model(batch_slices)\n",
    "        \n",
    "        # Convert outputs to binary predictions\n",
    "        predicted = (outputs >= 0.5).float()  # Assuming outputs are probabilities\n",
    "\n",
    "        # Update total and correct counts\n",
    "        total += batch_labels.size(0)  # Number of samples in the batch\n",
    "        correct += (predicted.squeeze() == batch_labels.float()).sum().item()  # Count correct predictions\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
