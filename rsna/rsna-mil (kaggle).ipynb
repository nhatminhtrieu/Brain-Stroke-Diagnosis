{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d8eb3a5",
   "metadata": {
    "papermill": {
     "duration": 0.006457,
     "end_time": "2024-09-15T19:42:09.942640",
     "exception": false,
     "start_time": "2024-09-15T19:42:09.936183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efefc47c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.120692Z",
     "start_time": "2024-09-14T07:28:36.048336Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-15T19:42:09.954885Z",
     "iopub.status.busy": "2024-09-15T19:42:09.954545Z",
     "iopub.status.idle": "2024-09-15T19:42:15.739819Z",
     "shell.execute_reply": "2024-09-15T19:42:15.738986Z"
    },
    "papermill": {
     "duration": 5.793894,
     "end_time": "2024-09-15T19:42:15.742104",
     "exception": false,
     "start_time": "2024-09-15T19:42:09.948210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage.transform import resize\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e961b6d8",
   "metadata": {
    "papermill": {
     "duration": 0.005445,
     "end_time": "2024-09-15T19:42:15.753415",
     "exception": false,
     "start_time": "2024-09-15T19:42:15.747970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Init GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94dad5eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.147624Z",
     "start_time": "2024-09-14T07:28:37.123291Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-15T19:42:15.766054Z",
     "iopub.status.busy": "2024-09-15T19:42:15.765529Z",
     "iopub.status.idle": "2024-09-15T19:42:15.851615Z",
     "shell.execute_reply": "2024-09-15T19:42:15.850379Z"
    },
    "papermill": {
     "duration": 0.094671,
     "end_time": "2024-09-15T19:42:15.853581",
     "exception": false,
     "start_time": "2024-09-15T19:42:15.758910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Tesla P100-PCIE-16GB is available.\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize GPU Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c6f4b2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.195720Z",
     "start_time": "2024-09-14T07:28:37.181737Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-15T19:42:15.866196Z",
     "iopub.status.busy": "2024-09-15T19:42:15.865877Z",
     "iopub.status.idle": "2024-09-15T19:42:15.912987Z",
     "shell.execute_reply": "2024-09-15T19:42:15.912290Z"
    },
    "papermill": {
     "duration": 0.055632,
     "end_time": "2024-09-15T19:42:15.914968",
     "exception": false,
     "start_time": "2024-09-15T19:42:15.859336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1073158c",
   "metadata": {
    "papermill": {
     "duration": 0.005288,
     "end_time": "2024-09-15T19:42:15.925846",
     "exception": false,
     "start_time": "2024-09-15T19:42:15.920558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "494bc12c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.241496Z",
     "start_time": "2024-09-14T07:28:37.226978Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-15T19:42:15.938367Z",
     "iopub.status.busy": "2024-09-15T19:42:15.937830Z",
     "iopub.status.idle": "2024-09-15T19:42:15.981106Z",
     "shell.execute_reply": "2024-09-15T19:42:15.980131Z"
    },
    "papermill": {
     "duration": 0.052165,
     "end_time": "2024-09-15T19:42:15.983645",
     "exception": false,
     "start_time": "2024-09-15T19:42:15.931480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "TEST_SIZE = 0.02\n",
    "HEIGHT = 512\n",
    "WIDTH = 512\n",
    "CHANNELS = 3\n",
    "TRAIN_BATCH_SIZE = 2\n",
    "VALID_BATCH_SIZE = 1\n",
    "TEST_BATCH_SIZE = 1\n",
    "MAX_SLICES = 60\n",
    "SHAPE = (HEIGHT, WIDTH, CHANNELS)\n",
    "\n",
    "# Folders\n",
    "DATA_DIR = '/kaggle/input/rsna-mil-training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed226c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.646853Z",
     "start_time": "2024-09-14T07:28:37.627110Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-15T19:42:15.998716Z",
     "iopub.status.busy": "2024-09-15T19:42:15.998316Z",
     "iopub.status.idle": "2024-09-15T19:42:16.060772Z",
     "shell.execute_reply": "2024-09-15T19:42:16.059788Z"
    },
    "papermill": {
     "duration": 0.072942,
     "end_time": "2024-09-15T19:42:16.063021",
     "exception": false,
     "start_time": "2024-09-15T19:42:15.990079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DICOM_DIR = DATA_DIR + 'rsna-mil-training'\n",
    "CSV_PATH = DATA_DIR + 'training_1000_scan_subset.csv'\n",
    "patient_scan_labels = pd.read_csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e66974e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.286525Z",
     "start_time": "2024-09-14T07:28:37.272027Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-15T19:42:16.075602Z",
     "iopub.status.busy": "2024-09-15T19:42:16.075250Z",
     "iopub.status.idle": "2024-09-15T19:42:16.118887Z",
     "shell.execute_reply": "2024-09-15T19:42:16.118203Z"
    },
    "papermill": {
     "duration": 0.052559,
     "end_time": "2024-09-15T19:42:16.121417",
     "exception": false,
     "start_time": "2024-09-15T19:42:16.068858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_slice(slice, target_size=(HEIGHT, WIDTH)):\n",
    "    slice = resize(slice, target_size, anti_aliasing=True)\n",
    "    brain_channel = apply_windowing(slice, window=(40, 80))\n",
    "    subdural_channel = apply_windowing(slice, window=(80, 200))\n",
    "    bone_channel = apply_windowing(slice, window=(600, 2800))\n",
    "    \n",
    "    multichannel_slice = np.stack([brain_channel, subdural_channel, bone_channel], axis=-1)\n",
    "    return multichannel_slice.astype(np.float16)  # Use float16 for reduced memory usage\n",
    "\n",
    "def apply_windowing(slice, window):\n",
    "    window_width, window_level = window\n",
    "    lower_bound = window_level - window_width // 2\n",
    "    upper_bound = window_level + window_width // 2\n",
    "    \n",
    "    windowed_slice = np.clip(slice, lower_bound, upper_bound)\n",
    "    windowed_slice = (windowed_slice - lower_bound) / (upper_bound - lower_bound)\n",
    "    return windowed_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d491d8ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.334765Z",
     "start_time": "2024-09-14T07:28:37.319238Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-15T19:42:16.134121Z",
     "iopub.status.busy": "2024-09-15T19:42:16.133818Z",
     "iopub.status.idle": "2024-09-15T19:42:16.176070Z",
     "shell.execute_reply": "2024-09-15T19:42:16.175403Z"
    },
    "papermill": {
     "duration": 0.05075,
     "end_time": "2024-09-15T19:42:16.178068",
     "exception": false,
     "start_time": "2024-09-15T19:42:16.127318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dicom_folder(folder_path):\n",
    "    slices = []\n",
    "    for filename in sorted(os.listdir(folder_path))[:MAX_SLICES]:  # Limit to MAX_SLICES\n",
    "        if filename.endswith(\".dcm\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            ds = pydicom.dcmread(file_path)\n",
    "            slices.append(ds.pixel_array)\n",
    "    \n",
    "    # Pad with black images if necessary\n",
    "    while len(slices) < MAX_SLICES:\n",
    "        slices.append(np.zeros_like(slices[0]))\n",
    "    \n",
    "    return slices[:MAX_SLICES]  # Ensure we return exactly MAX_SLICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d23b816c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.387325Z",
     "start_time": "2024-09-14T07:28:37.366621Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-15T19:42:16.190823Z",
     "iopub.status.busy": "2024-09-15T19:42:16.190537Z",
     "iopub.status.idle": "2024-09-15T19:42:16.233946Z",
     "shell.execute_reply": "2024-09-15T19:42:16.233246Z"
    },
    "papermill": {
     "duration": 0.052085,
     "end_time": "2024-09-15T19:42:16.235896",
     "exception": false,
     "start_time": "2024-09-15T19:42:16.183811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_patient_data(dicom_dir, row):\n",
    "    \"\"\"\n",
    "    Process data for a single patient based on the row from the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        dicom_dir (str): The directory containing DICOM folders.\n",
    "        row (pd.Series): A row from the patient_scan_labels DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: Preprocessed slices and label.\n",
    "    \"\"\"\n",
    "    patient_id = row['patient_id'].replace('ID_', '')  # Remove 'ID_' prefix\n",
    "    study_instance_uid = row['study_instance_uid'].replace('ID_', '')  # Remove 'ID_' prefix\n",
    "    \n",
    "    # Construct folder path based on patient_id and study_instance_uid\n",
    "    folder_name = f\"{patient_id}_{study_instance_uid}\"\n",
    "    folder_path = os.path.join(dicom_dir, folder_name)\n",
    "    \n",
    "    # Read and preprocess DICOM slices\n",
    "    if os.path.exists(folder_path):\n",
    "        slices = read_dicom_folder(folder_path)\n",
    "        preprocessed_slices = [preprocess_slice(slice) for slice in slices]\n",
    "        \n",
    "        # Determine label based on any of the hemorrhage indicators\n",
    "        label = 1 if row[['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']].any() else 0\n",
    "        \n",
    "        return preprocessed_slices, label\n",
    "    else:\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        return None, None  # Handle the case where the folder is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1d5fb79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.441645Z",
     "start_time": "2024-09-14T07:28:37.417416Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-15T19:42:16.251025Z",
     "iopub.status.busy": "2024-09-15T19:42:16.250593Z",
     "iopub.status.idle": "2024-09-15T19:42:16.309664Z",
     "shell.execute_reply": "2024-09-15T19:42:16.308464Z"
    },
    "papermill": {
     "duration": 0.070202,
     "end_time": "2024-09-15T19:42:16.311964",
     "exception": false,
     "start_time": "2024-09-15T19:42:16.241762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDatasetGenerator(Dataset):\n",
    "    def __init__(self, dicom_dir, patient_scan_labels):\n",
    "        self.dicom_dir = dicom_dir\n",
    "        self.patient_scan_labels = patient_scan_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_scan_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.patient_scan_labels.iloc[idx]\n",
    "        preprocessed_slices, label = process_patient_data(self.dicom_dir, row)\n",
    "        \n",
    "        if preprocessed_slices is not None:\n",
    "            preprocessed_slices = np.array(preprocessed_slices)\n",
    "            return torch.tensor(preprocessed_slices, dtype=torch.float16), torch.tensor(label, dtype=torch.long)\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "class TestDatasetGenerator(Dataset):\n",
    "    def __init__(self, dicom_dir, patient_scan_labels):\n",
    "        self.dicom_dir = dicom_dir\n",
    "        self.patient_scan_labels = patient_scan_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_scan_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.patient_scan_labels.iloc[idx]\n",
    "        preprocessed_slices, label = process_patient_data(self.dicom_dir, row)\n",
    "        \n",
    "        if preprocessed_slices is not None:\n",
    "            preprocessed_slices = np.array(preprocessed_slices)\n",
    "            return torch.tensor(preprocessed_slices, dtype=torch.float16), torch.tensor(label, dtype=torch.long)\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "def get_train_loader(dicom_dir, patient_scan_labels, batch_size=TRAIN_BATCH_SIZE, shuffle=True):\n",
    "    train_dataset = TrainDatasetGenerator(dicom_dir, patient_scan_labels)\n",
    "    return DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4, pin_memory=True)\n",
    "\n",
    "def get_test_loader(dicom_dir, patient_scan_labels, batch_size=TEST_BATCH_SIZE):\n",
    "    test_dataset = TestDatasetGenerator(dicom_dir, patient_scan_labels)\n",
    "    return DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a6dfe",
   "metadata": {
    "papermill": {
     "duration": 0.005579,
     "end_time": "2024-09-15T19:42:16.323547",
     "exception": false,
     "start_time": "2024-09-15T19:42:16.317968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CNN Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa8c8fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.496836Z",
     "start_time": "2024-09-14T07:28:37.473438Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-15T19:42:16.335820Z",
     "iopub.status.busy": "2024-09-15T19:42:16.335493Z",
     "iopub.status.idle": "2024-09-15T19:42:16.377426Z",
     "shell.execute_reply": "2024-09-15T19:42:16.376698Z"
    },
    "papermill": {
     "duration": 0.05037,
     "end_time": "2024-09-15T19:42:16.379380",
     "exception": false,
     "start_time": "2024-09-15T19:42:16.329010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.features = torch.nn.Sequential(*list(resnet18.children())[:-1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd66339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.545899Z",
     "start_time": "2024-09-14T07:28:37.524842Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-15T19:42:16.391651Z",
     "iopub.status.busy": "2024-09-15T19:42:16.391333Z",
     "iopub.status.idle": "2024-09-15T19:42:16.434508Z",
     "shell.execute_reply": "2024-09-15T19:42:16.433803Z"
    },
    "papermill": {
     "duration": 0.051582,
     "end_time": "2024-09-15T19:42:16.436535",
     "exception": false,
     "start_time": "2024-09-15T19:42:16.384953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_dim, attention_dim):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(input_dim, attention_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(attention_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, features):\n",
    "        weights = self.attention(features)\n",
    "        weights = torch.softmax(weights, dim=1)\n",
    "        weighted_features = torch.sum(weights * features, dim=1)\n",
    "        return weighted_features, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c41d187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.592904Z",
     "start_time": "2024-09-14T07:28:37.575334Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-15T19:42:16.449007Z",
     "iopub.status.busy": "2024-09-15T19:42:16.448732Z",
     "iopub.status.idle": "2024-09-15T19:42:16.492053Z",
     "shell.execute_reply": "2024-09-15T19:42:16.491393Z"
    },
    "papermill": {
     "duration": 0.051652,
     "end_time": "2024-09-15T19:42:16.493792",
     "exception": false,
     "start_time": "2024-09-15T19:42:16.442140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MILModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MILModel, self).__init__()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.attention = AttentionLayer(512, 256)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, num_images, height, width, channels = x.size()\n",
    "        x = x.view(-1, channels, height, width)\n",
    "        features = self.feature_extractor(x)\n",
    "        features = features.view(batch_size, num_images, -1)\n",
    "        weighted_features, attention_weights = self.attention(features)\n",
    "        output = self.classifier(weighted_features)\n",
    "        return output, attention_weights, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6daa9c82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:42:16.506286Z",
     "iopub.status.busy": "2024-09-15T19:42:16.506020Z",
     "iopub.status.idle": "2024-09-15T19:42:16.551205Z",
     "shell.execute_reply": "2024-09-15T19:42:16.550372Z"
    },
    "papermill": {
     "duration": 0.053743,
     "end_time": "2024-09-15T19:42:16.553219",
     "exception": false,
     "start_time": "2024-09-15T19:42:16.499476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, scaler, device, num_epochs, accumulation_steps):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        train_loader_tqdm = tqdm(train_loader, leave=False)\n",
    "        optimizer.zero_grad()\n",
    "        for i, (inputs, labels) in enumerate(train_loader_tqdm):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                outputs, _, _ = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), labels.float())\n",
    "                loss = loss / accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item() * accumulation_steps\n",
    "            predicted = (outputs.squeeze() >= 0.5).float()\n",
    "            correct += (predicted == labels.float()).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = correct / total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edee3c82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:42:16.565299Z",
     "iopub.status.busy": "2024-09-15T19:42:16.565011Z",
     "iopub.status.idle": "2024-09-15T19:53:38.804790Z",
     "shell.execute_reply": "2024-09-15T19:53:38.803352Z"
    },
    "papermill": {
     "duration": 682.248585,
     "end_time": "2024-09-15T19:53:38.807297",
     "exception": false,
     "start_time": "2024-09-15T19:42:16.558712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 187MB/s]\n",
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.6946, Acc: 0.5780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    patient_scan_labels = pd.read_csv(CSV_PATH)\n",
    "    \n",
    "    train_loader = get_train_loader(DICOM_DIR, patient_scan_labels, batch_size=TRAIN_BATCH_SIZE)\n",
    "    test_loader = get_test_loader(DICOM_DIR, patient_scan_labels, batch_size=TEST_BATCH_SIZE)\n",
    "\n",
    "    num_epochs = 1\n",
    "    model = MILModel(num_classes=1).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scaler = GradScaler()\n",
    "    accumulation_steps = 4\n",
    "\n",
    "    trained_model = train_model(model, train_loader, criterion, optimizer, scaler, device, num_epochs, accumulation_steps)\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(trained_model.state_dict(), 'optimized_mil_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5705276,
     "sourceId": 9399351,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 694.078257,
   "end_time": "2024-09-15T19:53:41.314730",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-15T19:42:07.236473",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
