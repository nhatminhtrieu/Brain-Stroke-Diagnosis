{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0926d999",
   "metadata": {
    "papermill": {
     "duration": 0.006445,
     "end_time": "2024-09-16T13:24:10.765856",
     "exception": false,
     "start_time": "2024-09-16T13:24:10.759411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7866982",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.120692Z",
     "start_time": "2024-09-14T07:28:36.048336Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T13:24:10.778938Z",
     "iopub.status.busy": "2024-09-16T13:24:10.778561Z",
     "iopub.status.idle": "2024-09-16T13:24:17.378800Z",
     "shell.execute_reply": "2024-09-16T13:24:17.377812Z"
    },
    "papermill": {
     "duration": 6.609569,
     "end_time": "2024-09-16T13:24:17.381281",
     "exception": false,
     "start_time": "2024-09-16T13:24:10.771712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage.transform import resize\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b02621e",
   "metadata": {
    "papermill": {
     "duration": 0.005751,
     "end_time": "2024-09-16T13:24:17.393107",
     "exception": false,
     "start_time": "2024-09-16T13:24:17.387356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Init GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d18b264f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.147624Z",
     "start_time": "2024-09-14T07:28:37.123291Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T13:24:17.406467Z",
     "iopub.status.busy": "2024-09-16T13:24:17.405481Z",
     "iopub.status.idle": "2024-09-16T13:24:17.486819Z",
     "shell.execute_reply": "2024-09-16T13:24:17.485687Z"
    },
    "papermill": {
     "duration": 0.090218,
     "end_time": "2024-09-16T13:24:17.488903",
     "exception": false,
     "start_time": "2024-09-16T13:24:17.398685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Tesla P100-PCIE-16GB is available.\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize GPU Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ca976d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.195720Z",
     "start_time": "2024-09-14T07:28:37.181737Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T13:24:17.501807Z",
     "iopub.status.busy": "2024-09-16T13:24:17.501457Z",
     "iopub.status.idle": "2024-09-16T13:24:17.551887Z",
     "shell.execute_reply": "2024-09-16T13:24:17.550805Z"
    },
    "papermill": {
     "duration": 0.059631,
     "end_time": "2024-09-16T13:24:17.554504",
     "exception": false,
     "start_time": "2024-09-16T13:24:17.494873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd75ab",
   "metadata": {
    "papermill": {
     "duration": 0.005869,
     "end_time": "2024-09-16T13:24:17.566742",
     "exception": false,
     "start_time": "2024-09-16T13:24:17.560873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d29b6930",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.241496Z",
     "start_time": "2024-09-14T07:28:37.226978Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T13:24:17.579631Z",
     "iopub.status.busy": "2024-09-16T13:24:17.579289Z",
     "iopub.status.idle": "2024-09-16T13:24:17.623821Z",
     "shell.execute_reply": "2024-09-16T13:24:17.623040Z"
    },
    "papermill": {
     "duration": 0.053593,
     "end_time": "2024-09-16T13:24:17.626164",
     "exception": false,
     "start_time": "2024-09-16T13:24:17.572571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "TEST_SIZE = 0.02\n",
    "HEIGHT = 512\n",
    "WIDTH = 512\n",
    "CHANNELS = 2\n",
    "TRAIN_BATCH_SIZE = 2\n",
    "VALID_BATCH_SIZE = 2\n",
    "TEST_BATCH_SIZE = 2\n",
    "MAX_SLICES = 80\n",
    "SHAPE = (HEIGHT, WIDTH, CHANNELS)\n",
    "\n",
    "# Folders\n",
    "DATA_DIR = '/kaggle/input/rsna-mil-training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7e4480",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.646853Z",
     "start_time": "2024-09-14T07:28:37.627110Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T13:24:17.640010Z",
     "iopub.status.busy": "2024-09-16T13:24:17.639688Z",
     "iopub.status.idle": "2024-09-16T13:24:17.708011Z",
     "shell.execute_reply": "2024-09-16T13:24:17.707061Z"
    },
    "papermill": {
     "duration": 0.078035,
     "end_time": "2024-09-16T13:24:17.710825",
     "exception": false,
     "start_time": "2024-09-16T13:24:17.632790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DICOM_DIR = DATA_DIR + 'rsna-mil-training'\n",
    "CSV_PATH = DATA_DIR + 'training_1000_scan_subset.csv'\n",
    "patient_scan_labels = pd.read_csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b35396fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.286525Z",
     "start_time": "2024-09-14T07:28:37.272027Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T13:24:17.726938Z",
     "iopub.status.busy": "2024-09-16T13:24:17.726521Z",
     "iopub.status.idle": "2024-09-16T13:24:17.777090Z",
     "shell.execute_reply": "2024-09-16T13:24:17.776287Z"
    },
    "papermill": {
     "duration": 0.06077,
     "end_time": "2024-09-16T13:24:17.779491",
     "exception": false,
     "start_time": "2024-09-16T13:24:17.718721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_slice(slice, target_size=(HEIGHT, WIDTH)):\n",
    "    slice = resize(slice, target_size, anti_aliasing=True)\n",
    "    brain_channel = apply_windowing(slice, window=(40, 80))\n",
    "    subdural_channel = apply_windowing(slice, window=(80, 200))\n",
    "    bone_channel = apply_windowing(slice, window=(600, 2800))\n",
    "    \n",
    "    multichannel_slice = np.stack([brain_channel, subdural_channel, bone_channel], axis=-1)\n",
    "    return multichannel_slice.astype(np.float16)  # Use float16 for reduced memory usage\n",
    "\n",
    "def apply_windowing(slice, window):\n",
    "    window_width, window_level = window\n",
    "    lower_bound = window_level - window_width // 2\n",
    "    upper_bound = window_level + window_width // 2\n",
    "    \n",
    "    windowed_slice = np.clip(slice, lower_bound, upper_bound)\n",
    "    windowed_slice = (windowed_slice - lower_bound) / (upper_bound - lower_bound)\n",
    "    return windowed_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e80321",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.334765Z",
     "start_time": "2024-09-14T07:28:37.319238Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T13:24:17.792792Z",
     "iopub.status.busy": "2024-09-16T13:24:17.792411Z",
     "iopub.status.idle": "2024-09-16T13:24:17.839407Z",
     "shell.execute_reply": "2024-09-16T13:24:17.838599Z"
    },
    "papermill": {
     "duration": 0.056041,
     "end_time": "2024-09-16T13:24:17.841652",
     "exception": false,
     "start_time": "2024-09-16T13:24:17.785611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dicom_folder(folder_path):\n",
    "    slices = []\n",
    "    for filename in sorted(os.listdir(folder_path))[:MAX_SLICES]:  # Limit to MAX_SLICES\n",
    "        if filename.endswith(\".dcm\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            ds = pydicom.dcmread(file_path)\n",
    "            slices.append(ds.pixel_array)\n",
    "    \n",
    "    # Pad with black images if necessary\n",
    "    while len(slices) < MAX_SLICES:\n",
    "        slices.append(np.zeros_like(slices[0]))\n",
    "    \n",
    "    return slices[:MAX_SLICES]  # Ensure we return exactly MAX_SLICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4e35a9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.387325Z",
     "start_time": "2024-09-14T07:28:37.366621Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T13:24:17.855161Z",
     "iopub.status.busy": "2024-09-16T13:24:17.854814Z",
     "iopub.status.idle": "2024-09-16T13:24:17.901278Z",
     "shell.execute_reply": "2024-09-16T13:24:17.900492Z"
    },
    "papermill": {
     "duration": 0.055716,
     "end_time": "2024-09-16T13:24:17.903563",
     "exception": false,
     "start_time": "2024-09-16T13:24:17.847847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_patient_data(dicom_dir, row):\n",
    "    \"\"\"\n",
    "    Process data for a single patient based on the row from the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        dicom_dir (str): The directory containing DICOM folders.\n",
    "        row (pd.Series): A row from the patient_scan_labels DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: Preprocessed slices and label.\n",
    "    \"\"\"\n",
    "    patient_id = row['patient_id'].replace('ID_', '')  # Remove 'ID_' prefix\n",
    "    study_instance_uid = row['study_instance_uid'].replace('ID_', '')  # Remove 'ID_' prefix\n",
    "    \n",
    "    # Construct folder path based on patient_id and study_instance_uid\n",
    "    folder_name = f\"{patient_id}_{study_instance_uid}\"\n",
    "    folder_path = os.path.join(dicom_dir, folder_name)\n",
    "    \n",
    "    # Read and preprocess DICOM slices\n",
    "    if os.path.exists(folder_path):\n",
    "        slices = read_dicom_folder(folder_path)\n",
    "        preprocessed_slices = [preprocess_slice(slice) for slice in slices]\n",
    "        \n",
    "        # Determine label based on any of the hemorrhage indicators\n",
    "        label = 1 if row[['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']].any() else 0\n",
    "        \n",
    "        return preprocessed_slices, label\n",
    "    else:\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        return None, None  # Handle the case where the folder is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f013bad2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.441645Z",
     "start_time": "2024-09-14T07:28:37.417416Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T13:24:17.917251Z",
     "iopub.status.busy": "2024-09-16T13:24:17.916907Z",
     "iopub.status.idle": "2024-09-16T13:24:17.967172Z",
     "shell.execute_reply": "2024-09-16T13:24:17.966184Z"
    },
    "papermill": {
     "duration": 0.06003,
     "end_time": "2024-09-16T13:24:17.969584",
     "exception": false,
     "start_time": "2024-09-16T13:24:17.909554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDatasetGenerator(Dataset):\n",
    "    def __init__(self, dicom_dir, patient_scan_labels):\n",
    "        self.dicom_dir = dicom_dir\n",
    "        self.patient_scan_labels = patient_scan_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_scan_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.patient_scan_labels.iloc[idx]\n",
    "        preprocessed_slices, label = process_patient_data(self.dicom_dir, row)\n",
    "        \n",
    "        if preprocessed_slices is not None:\n",
    "            preprocessed_slices = np.array(preprocessed_slices)\n",
    "            return torch.tensor(preprocessed_slices, dtype=torch.float16), torch.tensor(label, dtype=torch.long)\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "class TestDatasetGenerator(Dataset):\n",
    "    def __init__(self, dicom_dir, patient_scan_labels):\n",
    "        self.dicom_dir = dicom_dir\n",
    "        self.patient_scan_labels = patient_scan_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_scan_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.patient_scan_labels.iloc[idx]\n",
    "        preprocessed_slices, label = process_patient_data(self.dicom_dir, row)\n",
    "        \n",
    "        if preprocessed_slices is not None:\n",
    "            preprocessed_slices = np.array(preprocessed_slices)\n",
    "            return torch.tensor(preprocessed_slices, dtype=torch.float16), torch.tensor(label, dtype=torch.long)\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "def get_train_loader(dicom_dir, patient_scan_labels, batch_size=TRAIN_BATCH_SIZE, shuffle=True):\n",
    "    train_dataset = TrainDatasetGenerator(dicom_dir, patient_scan_labels)\n",
    "    return DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4, pin_memory=True)\n",
    "\n",
    "def get_test_loader(dicom_dir, patient_scan_labels, batch_size=TEST_BATCH_SIZE):\n",
    "    test_dataset = TestDatasetGenerator(dicom_dir, patient_scan_labels)\n",
    "    return DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830983c3",
   "metadata": {
    "papermill": {
     "duration": 0.005665,
     "end_time": "2024-09-16T13:24:17.981509",
     "exception": false,
     "start_time": "2024-09-16T13:24:17.975844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CNN Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca9637fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.496836Z",
     "start_time": "2024-09-14T07:28:37.473438Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T13:24:17.995295Z",
     "iopub.status.busy": "2024-09-16T13:24:17.994562Z",
     "iopub.status.idle": "2024-09-16T13:24:18.039650Z",
     "shell.execute_reply": "2024-09-16T13:24:18.038662Z"
    },
    "papermill": {
     "duration": 0.054641,
     "end_time": "2024-09-16T13:24:18.042087",
     "exception": false,
     "start_time": "2024-09-16T13:24:17.987446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.features = nn.Sequential(*list(resnet18.children())[:-1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebe02b35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.545899Z",
     "start_time": "2024-09-14T07:28:37.524842Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T13:24:18.055389Z",
     "iopub.status.busy": "2024-09-16T13:24:18.055073Z",
     "iopub.status.idle": "2024-09-16T13:24:18.100012Z",
     "shell.execute_reply": "2024-09-16T13:24:18.099229Z"
    },
    "papermill": {
     "duration": 0.054239,
     "end_time": "2024-09-16T13:24:18.102299",
     "exception": false,
     "start_time": "2024-09-16T13:24:18.048060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_dim, attention_dim):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(input_dim, attention_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(attention_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, features):\n",
    "        weights = self.attention(features)\n",
    "        weights = torch.softmax(weights, dim=1)\n",
    "        weighted_features = torch.sum(weights * features, dim=1)\n",
    "        return weighted_features, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7f3b1c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:28:37.592904Z",
     "start_time": "2024-09-14T07:28:37.575334Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T13:24:18.116265Z",
     "iopub.status.busy": "2024-09-16T13:24:18.115182Z",
     "iopub.status.idle": "2024-09-16T13:24:18.161856Z",
     "shell.execute_reply": "2024-09-16T13:24:18.161022Z"
    },
    "papermill": {
     "duration": 0.056061,
     "end_time": "2024-09-16T13:24:18.164277",
     "exception": false,
     "start_time": "2024-09-16T13:24:18.108216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MILModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MILModel, self).__init__()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.attention = AttentionLayer(512, 256)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)  # No Sigmoid here\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, num_images, channels, height, width = x.size()\n",
    "        x = x.view(-1, channels, height, width)\n",
    "        features = self.feature_extractor(x)\n",
    "        features = features.view(batch_size, num_images, -1)\n",
    "        weighted_features, attention_weights = self.attention(features)\n",
    "        output = self.classifier(weighted_features)\n",
    "        return output, attention_weights, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c3d79f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T13:24:18.177582Z",
     "iopub.status.busy": "2024-09-16T13:24:18.177250Z",
     "iopub.status.idle": "2024-09-16T13:24:18.226241Z",
     "shell.execute_reply": "2024-09-16T13:24:18.225381Z"
    },
    "papermill": {
     "duration": 0.058351,
     "end_time": "2024-09-16T13:24:18.228545",
     "exception": false,
     "start_time": "2024-09-16T13:24:18.170194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In train_model function\n",
    "def train_model(model, train_loader, criterion, optimizer, scaler, device, num_epochs, accumulation_steps):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        train_loader_tqdm = tqdm(train_loader, leave=False)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader_tqdm):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = inputs.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "            with autocast(device.type):\n",
    "                outputs, _, _ = model(inputs)\n",
    "                outputs = outputs.squeeze(1)\n",
    "                loss = criterion(outputs, labels.float()) / accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item() * accumulation_steps\n",
    "            predicted = (outputs >= 0.5).float()\n",
    "            correct += (predicted == labels.float()).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            train_loader_tqdm.set_description(f\"Epoch {epoch+1}/{num_epochs} - Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = correct / total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b02b504b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T13:24:18.242135Z",
     "iopub.status.busy": "2024-09-16T13:24:18.241308Z",
     "iopub.status.idle": "2024-09-16T13:39:48.138158Z",
     "shell.execute_reply": "2024-09-16T13:39:48.136725Z"
    },
    "papermill": {
     "duration": 929.905804,
     "end_time": "2024-09-16T13:39:48.140366",
     "exception": false,
     "start_time": "2024-09-16T13:24:18.234562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 203MB/s]\n",
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.6995, Acc: 0.5730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# In the main execution\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    train_loader = get_train_loader(DICOM_DIR, patient_scan_labels, batch_size=TRAIN_BATCH_SIZE)\n",
    "    test_loader = get_test_loader(DICOM_DIR, patient_scan_labels, batch_size=TEST_BATCH_SIZE)\n",
    "\n",
    "    num_epochs = 1\n",
    "    model = MILModel(num_classes=1).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scaler = GradScaler()\n",
    "    accumulation_steps = 16  # Increased from 4 to 16\n",
    "\n",
    "    trained_model = train_model(model, train_loader, criterion, optimizer, scaler, device, num_epochs, accumulation_steps)\n",
    "\n",
    "    torch.save(trained_model.state_dict(), 'optimized_mil_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5705276,
     "sourceId": 9399351,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 942.061217,
   "end_time": "2024-09-16T13:39:50.048842",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-16T13:24:07.987625",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
