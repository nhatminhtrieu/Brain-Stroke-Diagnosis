{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04ce7fc16269637",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "827de11a1d9590d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:56.878365Z",
     "start_time": "2025-02-24T14:53:55.284517Z"
    }
   },
   "source": [
    "from sched import scheduler\n",
    "!pip install gpytorch torchsummary iterative-stratification optuna pytorch_metric_learning wandb\n",
    "!pip install torch pydicom pandas scikit-learn scikit-image numpy opencv-python matplotlib"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpytorch in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (1.13)\r\n",
      "Requirement already satisfied: torchsummary in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (1.5.1)\r\n",
      "Requirement already satisfied: iterative-stratification in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (0.1.9)\r\n",
      "Requirement already satisfied: optuna in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (4.1.0)\r\n",
      "Requirement already satisfied: pytorch_metric_learning in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (2.8.1)\r\n",
      "Requirement already satisfied: wandb in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (0.18.5)\r\n",
      "Requirement already satisfied: jaxtyping==0.2.19 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (0.2.19)\r\n",
      "Requirement already satisfied: mpmath<=1.3,>=0.19 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (1.3.0)\r\n",
      "Requirement already satisfied: scikit-learn in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (1.4.0)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (1.10.1)\r\n",
      "Requirement already satisfied: linear-operator>=0.5.3 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (0.5.3)\r\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from jaxtyping==0.2.19->gpytorch) (1.26.4)\r\n",
      "Requirement already satisfied: typeguard>=2.13.3 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from jaxtyping==0.2.19->gpytorch) (4.2.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from jaxtyping==0.2.19->gpytorch) (4.12.2)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from optuna) (1.14.0)\r\n",
      "Requirement already satisfied: colorlog in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from optuna) (6.9.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from optuna) (24.1)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from optuna) (2.0.36)\r\n",
      "Requirement already satisfied: tqdm in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from optuna) (4.66.4)\r\n",
      "Requirement already satisfied: PyYAML in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from optuna) (6.0.1)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from pytorch_metric_learning) (2.4.0)\r\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (8.1.7)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (3.1.43)\r\n",
      "Requirement already satisfied: platformdirs in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (4.2.2)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (4.21.12)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (6.0.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (2.32.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (2.17.0)\r\n",
      "Requirement already satisfied: setproctitle in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (1.3.3)\r\n",
      "Requirement already satisfied: setuptools in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (72.1.0)\r\n",
      "Requirement already satisfied: Mako in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.8)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.0)\r\n",
      "Requirement already satisfied: filelock in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (3.13.1)\r\n",
      "Requirement already satisfied: sympy in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (2024.6.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (2.20.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\r\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (3.0.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->pytorch_metric_learning) (12.6.20)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-learn->gpytorch) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-learn->gpytorch) (3.5.0)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->pytorch_metric_learning) (2.1.3)\r\n",
      "Requirement already satisfied: torch in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (2.4.0)\r\n",
      "Requirement already satisfied: pydicom in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (2.4.4)\r\n",
      "Requirement already satisfied: pandas in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: scikit-learn in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (1.4.0)\r\n",
      "Requirement already satisfied: scikit-image in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (0.23.2)\r\n",
      "Requirement already satisfied: numpy in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (1.26.4)\r\n",
      "Requirement already satisfied: opencv-python in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (4.6.0)\r\n",
      "Requirement already satisfied: matplotlib in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (3.8.4)\r\n",
      "Requirement already satisfied: filelock in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (2024.6.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (2.20.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (3.0.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\r\n",
      "Requirement already satisfied: pillow>=9.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-image) (10.4.0)\r\n",
      "Requirement already satisfied: imageio>=2.33 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-image) (2.33.1)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-image) (2022.10.10)\r\n",
      "Requirement already satisfied: packaging>=21 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-image) (24.1)\r\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-image) (0.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib) (4.51.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib) (1.4.4)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "7a33c97468126c29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:58.307122Z",
     "start_time": "2025-02-24T14:53:56.882135Z"
    }
   },
   "source": [
    "import optuna\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from pytorch_metric_learning import losses\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, \\\n",
    "    multilabel_confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import models.mil_resnet as MILModels\n",
    "from utils import hard_negative_mining as hnm\n",
    "import gpytorch\n",
    "from layers.gaussian_process import SVGP_Model, PGLikelihood\n",
    "from utils.early_stopping import EarlyStoppingForOptimization, EarlyStopping\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "8a37479f6e74e822",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:58.331620Z",
     "start_time": "2025-02-24T14:53:58.329840Z"
    }
   },
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "14b411feb08f174a",
   "metadata": {},
   "source": [
    "# Configurations\n",
    "## GPU Configurations"
   ]
  },
  {
   "cell_type": "code",
   "id": "f4bc308439eee7c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:58.391167Z",
     "start_time": "2025-02-24T14:53:58.372584Z"
    }
   },
   "source": [
    "# Initialize GPU Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 4070 SUPER is available.\n",
      "cuda\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "8af9c65019e61153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:58.442724Z",
     "start_time": "2025-02-24T14:53:58.423377Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "90f07b41df278477",
   "metadata": {},
   "source": [
    "## Seed Everything"
   ]
  },
  {
   "cell_type": "code",
   "id": "389bfe8198c54df2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:58.486049Z",
     "start_time": "2025-02-24T14:53:58.467528Z"
    }
   },
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "59c5af8335d4fd7c",
   "metadata": {},
   "source": [
    "## Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "id": "efb1cdf72f6905c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:58.531673Z",
     "start_time": "2025-02-24T14:53:58.510930Z"
    }
   },
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"../config.yaml\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "DATASET = config['dataset']\n",
    "MODE = config['mode']\n",
    "\n",
    "# Accessing constants from config\n",
    "HEIGHT = config['height']\n",
    "WIDTH = config['width']\n",
    "CHANNELS = config['channels']\n",
    "\n",
    "TRAIN_BATCH_SIZE = config['train_batch_size']\n",
    "VALID_BATCH_SIZE = config['valid_batch_size']\n",
    "TEST_BATCH_SIZE = config['test_batch_size']\n",
    "TEST_SIZE = config['test_size']\n",
    "VALID_SIZE = config['valid_size']\n",
    "\n",
    "TRAINING_TYPE = config['training_type']\n",
    "DATA_REDUNDANCY = config['data_redundancy']\n",
    "GP_MODEL = config['gp_model']\n",
    "GP_KERNEL = config['kernel_type']\n",
    "MODEL_TYPE = config['model_type']\n",
    "CONTRASTIVE_LEARNING = config['contrastive_learning']\n",
    "\n",
    "MAX_SLICES = config['max_slices']\n",
    "SHAPE = tuple(config['shape'])\n",
    "\n",
    "NUM_EPOCHS = config['num_epochs']\n",
    "LEARNING_RATE = config['learning_rate']\n",
    "LEARNING_RATE_NGD = config['learning_rate_ngd']\n",
    "INDUCING_POINTS = config['inducing_points']\n",
    "THRESHOLD = config['threshold']\n",
    "POS_WEIGHT = config['pos_weight']\n",
    "\n",
    "NUM_CLASSES = config['num_classes']\n",
    "\n",
    "TARGET_LABELS = config['target_labels']\n",
    "\n",
    "MODEL_PATH = config['model_path']\n",
    "LIKELIHOOD_PATH = config['likelihood_path']\n",
    "DEVICE = config['device']\n",
    "\n",
    "PROJECTION_LOCATION = config['projection_location']\n",
    "PROJECTION_HIDDEN_DIM = config['projection_hidden_dim']\n",
    "PROJECTION_OUTPUT_DIM = config['projection_output_dim']\n",
    "\n",
    "ATTENTION_HIDDEN_DIM = config['attention_hidden_dim']"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "933cef7e185bd55c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:58.856653Z",
     "start_time": "2025-02-24T14:53:58.556186Z"
    }
   },
   "source": [
    "KAGGLE = os.path.exists(('kaggle/input'))\n",
    "REMOTE_SERVER = os.path.exists(('/workspace/rsna-ich-mil'))\n",
    "ROOT_DIR = None\n",
    "\n",
    "if KAGGLE:\n",
    "    DATA_DIR = ROOT_DIR + 'rsna-mil-training/'\n",
    "    DICOM_DIR = DATA_DIR\n",
    "    CSV_PATH = DICOM_DIR + 'training_1000_scan_subset.csv'\n",
    "elif REMOTE_SERVER:\n",
    "    DATA_DIR = '/root/rsna-ich-mil/'\n",
    "    DICOM_DIR = DATA_DIR\n",
    "    if DATA_REDUNDANCY:\n",
    "        CSV_PATH = DATA_DIR + 'training_dataset_1150_redundancy.csv'\n",
    "    else:\n",
    "        CSV_PATH = '/workspace/training_dataset_1150.csv'\n",
    "    print('Running on remote server.')\n",
    "else:\n",
    "    if DATASET == 'rsna':\n",
    "        DATA_DIR = '../rsna-ich-mil/'\n",
    "        DICOM_DIR = DATA_DIR\n",
    "        if DATA_REDUNDANCY:\n",
    "            CSV_PATH = './data_analyze/training_dataset_3_redundancy.csv'\n",
    "        else:\n",
    "            CSV_PATH = './data_analyze/training_dataset_3.csv'\n",
    "    elif DATASET == 'dongnai':\n",
    "        DATA_DIR = '../BVDongNai2/'\n",
    "        DICOM_DIR = DATA_DIR\n",
    "        CSV_PATH = DATA_DIR + 'PatientResult.csv'\n",
    "\n",
    "    print(f'CSV Path: {CSV_PATH}')\n",
    "\n",
    "# patient_scan_labels = pd.read_csv(CSV_PATH, nrows=1150)\n",
    "patient_scan_labels = pd.read_csv(CSV_PATH)\n",
    "dicom_dir = DICOM_DIR if KAGGLE else DATA_DIR"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Path: ./data_analyze/training_dataset_3_redundancy.csv\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "6c85475b0541e387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:58.893507Z",
     "start_time": "2025-02-24T14:53:58.867973Z"
    }
   },
   "source": [
    "patient_scan_labels.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            filename  \\\n",
       "0  ['ID_45785016b.dcm', 'ID_37f32aed2.dcm', 'ID_1...   \n",
       "1  ['ID_138d275c8.dcm', 'ID_447fa09d9.dcm', 'ID_0...   \n",
       "2  ['ID_c6f9f68c9.dcm', 'ID_520df89aa.dcm', 'ID_b...   \n",
       "3  ['ID_31b14de96.dcm', 'ID_203ef1efe.dcm', 'ID_9...   \n",
       "4  ['ID_0785539ea.dcm', 'ID_30c100dbc.dcm', 'ID_3...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                 any  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                            epidural  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                    intraparenchymal  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                    intraventricular  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                        subarachnoid  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                            subdural   patient_id  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ID_0002cd41   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ID_00054f3f   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ID_0006d192   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ID_00086119   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ID_000e5623   \n",
       "\n",
       "  study_instance_uid  ...                                  rescale_intercept  \\\n",
       "0      ID_66929e09d4  ...  [-1024.0, -1024.0, -1024.0, -1024.0, -1024.0, ...   \n",
       "1      ID_8a449ae31b  ...  [-1024.0, -1024.0, -1024.0, -1024.0, -1024.0, ...   \n",
       "2      ID_25690b4725  ...  [-1024.0, -1024.0, -1024.0, -1024.0, -1024.0, ...   \n",
       "3      ID_fdde2979b0  ...  [-1024.0, -1024.0, -1024.0, -1024.0, -1024.0, ...   \n",
       "4      ID_9a4be35b9a  ...  [-1024.0, -1024.0, -1024.0, -1024.0, -1024.0, ...   \n",
       "\n",
       "                                       rescale_slope patient_label  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...             0   \n",
       "1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...             0   \n",
       "2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...             0   \n",
       "3  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...             0   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...             0   \n",
       "\n",
       "  patient_any patient_subdural patient_epidural patient_intraparenchymal  \\\n",
       "0           0                0                0                        0   \n",
       "1           0                0                0                        0   \n",
       "2           0                0                0                        0   \n",
       "3           0                0                0                        0   \n",
       "4           0                0                0                        0   \n",
       "\n",
       "  patient_intraventricular  patient_subarachnoid  patient_labels  \n",
       "0                        0                     0               0  \n",
       "1                        0                     0               0  \n",
       "2                        0                     0               0  \n",
       "3                        0                     0               0  \n",
       "4                        0                     0               0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>labels</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>study_instance_uid</th>\n",
       "      <th>...</th>\n",
       "      <th>rescale_intercept</th>\n",
       "      <th>rescale_slope</th>\n",
       "      <th>patient_label</th>\n",
       "      <th>patient_any</th>\n",
       "      <th>patient_subdural</th>\n",
       "      <th>patient_epidural</th>\n",
       "      <th>patient_intraparenchymal</th>\n",
       "      <th>patient_intraventricular</th>\n",
       "      <th>patient_subarachnoid</th>\n",
       "      <th>patient_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ID_45785016b.dcm', 'ID_37f32aed2.dcm', 'ID_1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>ID_0002cd41</td>\n",
       "      <td>ID_66929e09d4</td>\n",
       "      <td>...</td>\n",
       "      <td>[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['ID_138d275c8.dcm', 'ID_447fa09d9.dcm', 'ID_0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>ID_00054f3f</td>\n",
       "      <td>ID_8a449ae31b</td>\n",
       "      <td>...</td>\n",
       "      <td>[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['ID_c6f9f68c9.dcm', 'ID_520df89aa.dcm', 'ID_b...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>ID_0006d192</td>\n",
       "      <td>ID_25690b4725</td>\n",
       "      <td>...</td>\n",
       "      <td>[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['ID_31b14de96.dcm', 'ID_203ef1efe.dcm', 'ID_9...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>ID_00086119</td>\n",
       "      <td>ID_fdde2979b0</td>\n",
       "      <td>...</td>\n",
       "      <td>[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['ID_0785539ea.dcm', 'ID_30c100dbc.dcm', 'ID_3...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>ID_000e5623</td>\n",
       "      <td>ID_9a4be35b9a</td>\n",
       "      <td>...</td>\n",
       "      <td>[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "95d276ee1c956192",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "cd63c1d38007ac61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:58.940978Z",
     "start_time": "2025-02-24T14:53:58.922454Z"
    }
   },
   "source": [
    "def split_dataset(patient_scan_labels, test_size=TEST_SIZE, val_size=VALID_SIZE, num_rows=None,random_state=42):\n",
    "    # Extract the labels from the DataFrame\n",
    "    labels = patient_scan_labels['patient_label']\n",
    "    if test_size > 0:\n",
    "        # First, split off the test set\n",
    "        train_val_labels, test_labels = train_test_split(\n",
    "            patient_scan_labels,\n",
    "            test_size=test_size,\n",
    "            stratify=labels,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        # Calculate the validation size relative to the train_val set\n",
    "        val_size_adjusted = val_size / (1 - test_size)\n",
    "\n",
    "        # Split the train_val set into train and validation sets\n",
    "        train_labels, val_labels = train_test_split(\n",
    "            train_val_labels,\n",
    "            test_size=val_size_adjusted,\n",
    "            stratify=train_val_labels['patient_label'],\n",
    "            random_state=random_state\n",
    "        )\n",
    "    else:\n",
    "        train_labels, val_labels = train_test_split(\n",
    "            patient_scan_labels,\n",
    "            test_size=val_size,\n",
    "            stratify=labels,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        test_labels = None\n",
    "\n",
    "    return train_labels, val_labels, test_labels\n",
    "\n",
    "def split_dataset_for_multilabel(patient_scan_labels, test_size=0.15, val_size=VALID_SIZE, num_rows=None,random_state=42):\n",
    "    # Extract the labels from the DataFrame\n",
    "    labels = patient_scan_labels[['patient_any', 'patient_epidural', 'patient_intraparenchymal',\n",
    "                                  'patient_intraventricular', 'patient_subarachnoid', 'patient_subdural']].values\n",
    "\n",
    "    if test_size > 0:\n",
    "        # First split: train + test\n",
    "        msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "        train_idx, test_idx = next(msss.split(patient_scan_labels, labels))\n",
    "\n",
    "        train_labels = patient_scan_labels.iloc[train_idx]\n",
    "        # Second split: train + validation\n",
    "        msss_val = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=val_size, random_state=random_state)\n",
    "        train_idx, val_idx = next(msss_val.split(train_labels, labels[train_idx]))\n",
    "\n",
    "        if num_rows:\n",
    "            num_train_rows = int(num_rows * (1 - test_size))\n",
    "            num_val_rows = int(num_train_rows * val_size)\n",
    "            num_test_rows = num_rows - num_train_rows\n",
    "            num_final_train_rows = num_train_rows - num_val_rows\n",
    "            train_idx = train_idx[:num_final_train_rows]\n",
    "            val_idx = val_idx[:num_val_rows]\n",
    "            test_idx = test_idx[:num_test_rows]\n",
    "\n",
    "        train_labels_final = train_labels.iloc[train_idx]\n",
    "        val_labels = train_labels.iloc[val_idx]\n",
    "        test_labels = patient_scan_labels.iloc[test_idx]\n",
    "\n",
    "    else:\n",
    "        # Only split into train and validation if test_size is 0\n",
    "        msss_val = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=val_size, random_state=random_state)\n",
    "        train_idx, val_idx = next(msss_val.split(patient_scan_labels, labels))\n",
    "\n",
    "        if num_rows:\n",
    "            num_trains = int(num_rows * (1 - val_size))\n",
    "            train_idx = train_idx[:num_trains]\n",
    "            val_idx = val_idx[:num_rows - num_trains]\n",
    "\n",
    "        train_labels_final = patient_scan_labels.iloc[train_idx]\n",
    "        val_labels = patient_scan_labels.iloc[val_idx]\n",
    "        test_labels = None\n",
    "\n",
    "    return train_labels_final, val_labels, test_labels"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "3226128a0da50755",
   "metadata": {},
   "source": [
    "## Dataset Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "id": "8fed4ff069d88fca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:58.984996Z",
     "start_time": "2025-02-24T14:53:58.964973Z"
    }
   },
   "source": [
    "class DatasetAugmentor:\n",
    "    def __init__(self, height, width, levels=2, seed=None):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.levels = levels  # Dynamic number of levels\n",
    "        self.seed = seed\n",
    "        self.params = []\n",
    "\n",
    "        # Create different levels of transforms based on the number of levels specified\n",
    "        for i in range(levels):\n",
    "            factor = (i + 1) / levels\n",
    "            self.params.append(\n",
    "                self._create_transform(\n",
    "                    degrees=int(15 * factor),\n",
    "                    translate_range=(0.2 * factor, 0.2 * factor),\n",
    "                    scale_range=(1 - 0.2 * factor, 1 + 0.2 * factor),\n",
    "                    brightness_range=0.2 * factor,\n",
    "                    contrast_range=0.2 * factor,\n",
    "                    blur_sigma_range=(0.5 * factor, 1.0 * factor),\n",
    "                    apply_elastic=(i >= levels // 2),\n",
    "                    level_name=f'level_{i + 1}'\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def _sample_value(self, value_range):\n",
    "        if isinstance(value_range, tuple):\n",
    "            random.seed(self.seed)\n",
    "            return random.uniform(value_range[0], value_range[1])\n",
    "        return value_range\n",
    "\n",
    "    def _create_transform(self, degrees, translate_range, scale_range, brightness_range, contrast_range,\n",
    "                          blur_sigma_range, apply_elastic, level_name):\n",
    "        print(f\"Creating '{level_name}' transform with parameters:\")\n",
    "        sampled_values = {\n",
    "            \"degrees\": abs(self._sample_value((-degrees, degrees))),\n",
    "            \"translate\": (abs(self._sample_value(translate_range[0])), abs(self._sample_value(translate_range[1]))),\n",
    "            \"scale\": self._sample_value(scale_range),\n",
    "            \"brightness\": self._sample_value(brightness_range),\n",
    "            \"contrast\": self._sample_value(contrast_range),\n",
    "            \"blur_sigma\": self._sample_value(blur_sigma_range),\n",
    "            \"apply_elastic\": apply_elastic\n",
    "        }\n",
    "\n",
    "        print(sampled_values)\n",
    "        return sampled_values\n",
    "\n",
    "    def apply_transform(self, image, level):\n",
    "        params = self.params[level]\n",
    "        transform = self._get_transform(params, channels=image.shape[0])\n",
    "        return transform(image)\n",
    "\n",
    "    def _get_transform(self, params, channels=3):\n",
    "        transform_list = [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomAffine(degrees=params[\"degrees\"], translate=params[\"translate\"],\n",
    "                                    scale=(params[\"scale\"], params[\"scale\"])),\n",
    "            transforms.ColorJitter(brightness=params[\"brightness\"], contrast=params[\"contrast\"]),\n",
    "            transforms.GaussianBlur(kernel_size=(3, 3), sigma=params[\"blur_sigma\"]),\n",
    "            transforms.RandomApply([transforms.ElasticTransform()] if params[\"apply_elastic\"] else [], p=0.3),\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(self.height),\n",
    "            # transforms.Compose([transforms.ToImage(), transforms.ToDtype(torch.float32, scale=True)])\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "\n",
    "        return transforms.Compose(transform_list)\n",
    "\n",
    "    def _channel_shuffle(self, tensor):\n",
    "        torch.manual_seed(self.seed)\n",
    "        channels = tensor.shape[0]\n",
    "        indices = torch.randperm(channels)\n",
    "        return tensor[indices]"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "17559ec86a6d7e5d",
   "metadata": {},
   "source": [
    "## Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "id": "638bfe32475d4cf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:59.030429Z",
     "start_time": "2025-02-24T14:53:59.012514Z"
    }
   },
   "source": [
    "if DATASET == 'rsna':\n",
    "    from dataset_generators.RSNA_Dataset import MedicalScanDataset\n",
    "elif DATASET == 'dongnai':\n",
    "    from dataset_generators.DongNai_Dataset import DongNaiDataset as MedicalScanDataset\n",
    "elif DATASET == 'cq500':\n",
    "    from dataset_generators.CQ500_Dataset import CQ500Dataset as MedicalScanDataset"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "17ba8c33a5b0e113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:59.073351Z",
     "start_time": "2025-02-24T14:53:59.055807Z"
    }
   },
   "source": [
    "class TrainDatasetGenerator(MedicalScanDataset):\n",
    "    \"\"\"Dataset class for training medical scan data.\"\"\"\n",
    "    def __init__(self, data_dir, patient_scan_labels, augmentor=None):\n",
    "        super().__init__(data_dir, patient_scan_labels, augmentor)\n",
    "\n",
    "\n",
    "class TestDatasetGenerator(MedicalScanDataset):\n",
    "    \"\"\"Dataset class for testing medical scan data.\"\"\"\n",
    "    def __init__(self, data_dir, patient_scan_labels, augmentor=None):\n",
    "        super().__init__(data_dir, patient_scan_labels, augmentor)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "37a74c9cafe700df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:59.118095Z",
     "start_time": "2025-02-24T14:53:59.100241Z"
    }
   },
   "source": [
    "augmentor = DatasetAugmentor(HEIGHT, WIDTH, levels=2, seed=42)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 'level_1' transform with parameters:\n",
      "{'degrees': 1.9519751784103718, 'translate': (0.1, 0.1), 'scale': 1.027885359691577, 'brightness': 0.1, 'contrast': 0.1, 'blur_sigma': 0.4098566996144709, 'apply_elastic': False}\n",
      "Creating 'level_2' transform with parameters:\n",
      "{'degrees': 4.182803953736514, 'translate': (0.2, 0.2), 'scale': 1.0557707193831534, 'brightness': 0.2, 'contrast': 0.2, 'blur_sigma': 0.8197133992289418, 'apply_elastic': True}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "2329e7da154e7ba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:01.516710Z",
     "start_time": "2025-02-24T14:53:59.146783Z"
    }
   },
   "source": [
    "original_dataset = TrainDatasetGenerator(dicom_dir, patient_scan_labels, augmentor=None)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/hskha23/Kha/Brain-Stroke-Diagnosis/dataset_generators/RSNA_Dataset.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[False False False ...  True  True False]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  patient_scan_labels.loc[:, 'patient_label'] = patient_scan_labels['patient_label'].astype(bool)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "ff3a0e8e7d9949c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:01.540414Z",
     "start_time": "2025-02-24T14:54:01.523665Z"
    }
   },
   "source": [
    "len(original_dataset)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21744"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "633e6442f44018f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:01.667355Z",
     "start_time": "2025-02-24T14:54:01.575111Z"
    }
   },
   "source": [
    "x, y, z, _ = original_dataset[0]\n",
    "print(x.shape, y.shape, z.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 224, 224, 1]) torch.Size([28]) torch.Size([])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "9e3831832ebcfe75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:01.696626Z",
     "start_time": "2025-02-24T14:54:01.680159Z"
    }
   },
   "source": [
    "def get_train_loader(dicom_dir, patient_scan_labels, batch_size=TRAIN_BATCH_SIZE):\n",
    "    original_dataset = TrainDatasetGenerator(dicom_dir, patient_scan_labels, augmentor=None)\n",
    "    return DataLoader(original_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True,\n",
    "                      drop_last=True)\n",
    "\n",
    "def get_test_loader(dicom_dir, patient_scan_labels, batch_size=TEST_BATCH_SIZE):\n",
    "    test_dataset = TestDatasetGenerator(dicom_dir, patient_scan_labels, augmentor=None)\n",
    "    return DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "ddc97374c2af6d64",
   "metadata": {},
   "source": [
    "# Utils\n",
    "## Augment batch for CL"
   ]
  },
  {
   "cell_type": "code",
   "id": "54c6d481ec68b7b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:01.742973Z",
     "start_time": "2025-02-24T14:54:01.720826Z"
    }
   },
   "source": [
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "# Version 2: Avg time taken: 0.05 seconds for 1 augmentation (w ResizedCrop)\n",
    "def augment_batch(batch_images):\n",
    "    # if CHANNELS == 1:\n",
    "    #     batch_size, num_instances, channels, height, width = batch_images.shape\n",
    "    # else:\n",
    "    #     batch_size, num_instances, height, width, channels = batch_images.shape\n",
    "    batch_size, num_instances, height, width, channels = batch_images.shape\n",
    "\n",
    "    # Define augmentation transformations using GPU-compatible operations\n",
    "    aug_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop((height, width), scale=(0.8, 1.1)),\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4)], p=0.6),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.Compose([transforms.ToImage(), transforms.ToDtype(torch.float32, scale=True)]),\n",
    "    ])\n",
    "\n",
    "    # Apply transformations directly on the tensor without converting to PIL\n",
    "    augmented_batch = torch.empty_like(batch_images)  # Preallocate memory for augmented images\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        for j in range(num_instances):\n",
    "            # if CHANNELS == 1:\n",
    "            #     augmented_batch[i, j] = aug_transform(batch_images[i, j])\n",
    "            # else:\n",
    "            augmented_batch[i, j] = aug_transform(batch_images[i, j].permute(2, 0, 1)).permute(1, 2, 0)\n",
    "\n",
    "    return augmented_batch.cuda()  # Move the augmented batch to GPU"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "2678537611fbb8e3",
   "metadata": {},
   "source": [
    "## NTXentLoss"
   ]
  },
  {
   "cell_type": "code",
   "id": "56ebdfa34632acbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:01.782443Z",
     "start_time": "2025-02-24T14:54:01.764616Z"
    }
   },
   "source": [
    "class NTXentLoss(losses.NTXentLoss):\n",
    "    def __init__(self, temperature, **kwargs):\n",
    "        super().__init__(temperature=temperature, **kwargs)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, embeddings, labels=None, hard_pairs=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "        if labels == None:\n",
    "            # Self-supervised labels\n",
    "            batch_size = feature_vectors_normalized.size(0) // 2  # Assuming equal size for both embeddings\n",
    "            labels = torch.cat([torch.arange(batch_size), torch.arange(batch_size)], dim=0)\n",
    "\n",
    "        # Compute logits\n",
    "        logits = torch.div(\n",
    "            torch.matmul(\n",
    "                feature_vectors_normalized, torch.transpose(feature_vectors_normalized, 0, 1)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "\n",
    "        if labels == None:\n",
    "            return losses.NTXentLoss(temperature=self.temperature)(logits, torch.squeeze(labels))\n",
    "        if hard_pairs == None:\n",
    "            return losses.SupConLoss(temperature=self.temperature)(logits, torch.squeeze(labels))\n",
    "        return losses.SupConLoss(temperature=self.temperature)(logits, torch.squeeze(labels), hard_pairs)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "ed3bff18aa94ccf5",
   "metadata": {},
   "source": [
    "# Training and Validation\n",
    "## Metrics Calculation\n",
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "id": "e37f682a8aaac35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:01.827322Z",
     "start_time": "2025-02-24T14:54:01.808794Z"
    }
   },
   "source": [
    "def calculate_metrics(predictions, labels, average='weighted'):\n",
    "    if NUM_CLASSES == 1:\n",
    "        if DATASET != 'dongnai':\n",
    "            return {\n",
    "                \"accuracy\": accuracy_score(labels, predictions),\n",
    "                \"precision\": precision_score(labels, predictions, average=average),\n",
    "                \"recall\": recall_score(labels, predictions, average=average),\n",
    "                \"f1\": f1_score(labels, predictions, average=average),\n",
    "                \"auc\": roc_auc_score(labels, predictions, average='weighted'),\n",
    "                \"cohen_kappa\": cohen_kappa_score(labels, predictions)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"accuracy\": accuracy_score(labels, predictions),\n",
    "                \"precision\": precision_score(labels, predictions, average=average),\n",
    "                \"recall\": recall_score(labels, predictions, average=average),\n",
    "                \"f1\": f1_score(labels, predictions, average=average),\n",
    "                \"auc\": 0,\n",
    "                \"cohen_kappa\": 0\n",
    "            }\n",
    "    else:\n",
    "        average = 'micro'\n",
    "        return {\n",
    "            \"accuracy\": accuracy_score(labels, predictions),\n",
    "            \"precision\": precision_score(labels, predictions, average=average),\n",
    "            \"recall\": recall_score(labels, predictions, average=average),\n",
    "            \"f1\": f1_score(labels, predictions, average=average),\n",
    "            \"auc\": 0,\n",
    "            \"cohen_kappa\": 0\n",
    "        }\n",
    "\n",
    "def print_epoch_stats(epoch, num_epochs, phase, loss, metrics):\n",
    "    \"\"\"Print statistics for an epoch.\"\"\"\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - {phase.capitalize()}:\")\n",
    "    print(f\"Loss: {loss:.4f}, Accuracy: {metrics['accuracy']:.4f}, \"\n",
    "          f\"Precision: {metrics['precision']:.4f}, Recall: {metrics['recall']:.4f}, \"\n",
    "          f\"F1: {metrics['f1']:.4f}, AUC: {metrics['auc']:.4f}\")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "7332fde37dac6987",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aaf3081e1ffe2c",
   "metadata": {},
   "source": [
    "### Training Phase 1: CNN + ATT"
   ]
  },
  {
   "cell_type": "code",
   "id": "bf02a694b73c3669",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:01.876318Z",
     "start_time": "2025-02-24T14:54:01.854030Z"
    }
   },
   "source": [
    "def train_phase_1(model, data_loader, criterion_cl, criterion_bce, optimizer, scheduler, device):\n",
    "    total_loss = 0.0\n",
    "    alpha = 0.5\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "        batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_labels = batch_patient_labels if NUM_CLASSES == 1 else batch_multi_labels\n",
    "\n",
    "        if CONTRASTIVE_LEARNING:\n",
    "            aug_data_1 = augment_batch(batch_data)\n",
    "            aug_data_2 = augment_batch(batch_data)\n",
    "            batch_data = torch.cat([aug_data_1, aug_data_2], dim=0)\n",
    "            train_labels = torch.cat([train_labels, train_labels], dim=0)\n",
    "\n",
    "            outputs, cnn_features, attention_weights, att_out = model(batch_data)\n",
    "            miner_func = hnm.ExamplePairMiner()\n",
    "            hard_pairs = miner_func(att_out, train_labels)\n",
    "            loss = criterion_cl(att_out, labels=train_labels, hard_pairs=hard_pairs) * alpha + \\\n",
    "                     criterion_bce(outputs, train_labels) * (1 - alpha)\n",
    "            loss = loss.mean()\n",
    "            preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "        else:\n",
    "            outputs, cnn_features, attention_weights, _ = model(batch_data)\n",
    "            loss = criterion_bce(outputs, train_labels)\n",
    "            loss = loss.mean()\n",
    "            preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "        predictions.extend(preds.cpu().detach().numpy())\n",
    "        labels.extend(train_labels.cpu().numpy())\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    return total_loss / len(data_loader), predictions, labels\n",
    "\n",
    "def validate_phase_1(model, data_loader, criterion_cl, criterion_bce, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    alpha = 0.5\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with (torch.inference_mode()):\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            val_labels = batch_patient_labels if NUM_CLASSES == 1 else batch_multi_labels\n",
    "\n",
    "            if CONTRASTIVE_LEARNING:\n",
    "                outputs, cnn_features, attention_weights, att_out = model(batch_data)\n",
    "                miner_func = hnm.ExamplePairMiner()\n",
    "                hard_pairs = miner_func(att_out, val_labels)\n",
    "                loss = criterion_cl(att_out, labels=val_labels, hard_pairs=hard_pairs) * alpha + \\\n",
    "                         criterion_bce(outputs, val_labels) * (1 - alpha)\n",
    "                loss = loss.mean()\n",
    "                preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "            else:\n",
    "                outputs, cnn_features, attention_weights, _ = model(batch_data)\n",
    "                loss = criterion_bce(outputs, val_labels)\n",
    "                loss = loss.mean()\n",
    "                preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "            predictions.extend(preds.cpu().detach().numpy())\n",
    "            labels.extend(val_labels.cpu().numpy())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader), predictions, labels\n",
    "\n",
    "def evaluate_phase_1(model, data_loader, criterion_cl, criterion_bce, device):\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    alpha = 0.5\n",
    "    total_loss = 0.0\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    labels = []\n",
    "\n",
    "    with (torch.inference_mode()):\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            eval_labels = batch_patient_labels if NUM_CLASSES == 1 else batch_multi_labels\n",
    "\n",
    "            if CONTRASTIVE_LEARNING:\n",
    "                outputs, cnn_features, attention_weights, att_out = model(batch_data)\n",
    "                loss = criterion_cl(att_out, labels=eval_labels) * (1 - alpha) + criterion_bce(outputs, eval_labels) * alpha\n",
    "                loss = loss.mean()\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                preds = (probs >= THRESHOLD).int()\n",
    "\n",
    "            else:\n",
    "                outputs, cnn_features, attention_weights, _ = model(batch_data)\n",
    "                loss = criterion_bce(outputs, eval_labels)\n",
    "                loss = loss.mean()\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                preds = (probs >= THRESHOLD).int()\n",
    "\n",
    "            probabilities.extend(probs.cpu().detach().numpy())\n",
    "            predictions.extend(preds.cpu().detach().numpy())\n",
    "            labels.extend(eval_labels.cpu().numpy())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return predictions, labels, probabilities\n",
    "\n",
    "def train_model_phase_1(model, train_loader, val_loader, criterion_cl, criterion_bce, optimizer, num_epochs, device):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_auc = 0.0\n",
    "    best_metrics = None\n",
    "    model.to(device)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE, steps_per_epoch=len(train_loader), epochs=num_epochs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                loss, predictions, labels = train_phase_1(model, train_loader, criterion_cl, criterion_bce,\n",
    "                                                           optimizer, scheduler, device)\n",
    "            else:\n",
    "                model.eval()\n",
    "                loss, predictions, labels = validate_phase_1(model, val_loader, criterion_cl, criterion_bce, device)\n",
    "\n",
    "            metrics = calculate_metrics(predictions, labels, average='binary')\n",
    "            print_epoch_stats(epoch, num_epochs, phase, loss, metrics)\n",
    "\n",
    "            if phase == 'val' and best_auc < metrics['accuracy']:\n",
    "            # if phase == 'val' and metrics['recall'] > 0.9 and best_auc < metrics['auc']:\n",
    "                best_auc = metrics['accuracy']\n",
    "                best_metrics = metrics\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "    print(f'Best Accuracy: {best_auc}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_metrics"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "f5f08020017b303c",
   "metadata": {},
   "source": [
    "### Training Phase 2: GP"
   ]
  },
  {
   "cell_type": "code",
   "id": "39dedb999d546a18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:01.927739Z",
     "start_time": "2025-02-24T14:54:01.901845Z"
    }
   },
   "source": [
    "def train_epoch(model, likelihoods, data_loader, criterion_cl, criterion_bce, mlls, optimizer,\n",
    "                variational_ngd_optimizer, scheduler, device):\n",
    "    total_loss = 0.0\n",
    "    alpha = 0.5\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    model.train()\n",
    "    likelihoods.train()\n",
    "\n",
    "    for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "        batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if GP_MODEL == 'single_task':\n",
    "            if NUM_CLASSES != 1:\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    variational_ngd_optimizer[i].zero_grad()\n",
    "            else:\n",
    "                variational_ngd_optimizer.zero_grad()\n",
    "\n",
    "        if TRAINING_TYPE == 'end_to_end':\n",
    "            if CONTRASTIVE_LEARNING:\n",
    "                aug_data_1 = augment_batch(batch_data)\n",
    "                aug_data_2 = augment_batch(batch_data)\n",
    "                batch_data = torch.cat([aug_data_1, aug_data_2], dim=0)\n",
    "                batch_labels = torch.cat([batch_labels, batch_labels], dim=0)\n",
    "                batch_multi_labels = torch.cat([batch_multi_labels, batch_multi_labels], dim=0)\n",
    "                batch_patient_labels = torch.cat([batch_patient_labels, batch_patient_labels], dim=0)\n",
    "\n",
    "            outputs, gp_outputs, _, att_outputs = model(batch_data)\n",
    "\n",
    "            if GP_MODEL == 'single_task' and NUM_CLASSES != 1:\n",
    "                loss = 0\n",
    "                gp_loss = 0\n",
    "                ntx_loss = 0\n",
    "\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    gp_loss += -mlls[i](gp_outputs[i], batch_multi_labels[:, i])\n",
    "\n",
    "                if CONTRASTIVE_LEARNING:\n",
    "                    miner_func = hnm.ExamplePairMiner()\n",
    "                    hard_pairs = miner_func(outputs, batch_multi_labels)\n",
    "                    ntx_loss = criterion_cl(outputs, labels=batch_multi_labels, hard_pairs=hard_pairs)\n",
    "                    loss = 0.3 * criterion_bce(outputs, batch_multi_labels) + 0.3 * gp_loss + ntx_loss * 0.4\n",
    "                else:\n",
    "                    loss = 0.5 * criterion_bce(outputs, batch_multi_labels) + 0.5 * gp_loss\n",
    "\n",
    "                loss = loss.mean()\n",
    "\n",
    "                # probs = [likelihoods[i](gp_outputs[i]).probs for i in range(NUM_CLASSES)]\n",
    "                probs = [torch.sigmoid(outputs[:, i]) for i in range(NUM_CLASSES)]\n",
    "                probabilities = torch.stack(probs, dim=1)\n",
    "                preds = (probabilities >= THRESHOLD).int()\n",
    "\n",
    "            elif GP_MODEL == 'single_task' and NUM_CLASSES == 1:\n",
    "                if CONTRASTIVE_LEARNING:\n",
    "                    miner_func = hnm.ExamplePairMiner()\n",
    "                    hard_pairs = miner_func(outputs, batch_patient_labels)\n",
    "                    ntx_loss = criterion_cl(outputs, labels=batch_patient_labels, hard_pairs=hard_pairs)\n",
    "                    # loss = 0.3 * criterion_bce(outputs.squeeze(-1), batch_patient_labels) + 0.3 * mlls(gp_outputs, batch_patient_labels) + ntx_loss * 0.4\n",
    "                    loss = ntx_loss * 0.5 + 0.5 * criterion_bce(outputs.squeeze(-1), batch_patient_labels)\n",
    "                    loss = loss.mean()\n",
    "                    loss += -mlls(gp_outputs, batch_patient_labels) * 0.5\n",
    "                else:\n",
    "                    # loss = -mlls(gp_outputs, batch_patient_labels) * 0.5 + 0.5 * criterion_bce(outputs.squeeze(-1), batch_patient_labels)\n",
    "                    loss = -mlls(gp_outputs, batch_patient_labels)\n",
    "\n",
    "                loss = loss.mean()\n",
    "                preds = likelihoods(gp_outputs).probs >= THRESHOLD\n",
    "                # preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "            predictions.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            if GP_MODEL == 'single_task':\n",
    "                if NUM_CLASSES != 1:\n",
    "                    for i in range(NUM_CLASSES):\n",
    "                        variational_ngd_optimizer[i].step()\n",
    "                else:\n",
    "                    variational_ngd_optimizer.step()\n",
    "\n",
    "        if NUM_CLASSES == 1:\n",
    "            labels.extend(batch_patient_labels.cpu().numpy())\n",
    "        else:\n",
    "            labels.extend(batch_multi_labels.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(data_loader), predictions, labels\n",
    "\n",
    "\n",
    "def validate(model, likelihoods, data_loader, criterion_cl, criterion_bce, mlls, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    likelihoods.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    alpha = 0.5\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with (torch.inference_mode()):\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                outputs, gp_outputs, _, att_outputs = model(batch_data)\n",
    "                if GP_MODEL == 'single_task':\n",
    "                    loss = 0\n",
    "                    if NUM_CLASSES != 1:\n",
    "                        for i in range(NUM_CLASSES):\n",
    "                            loss += -mlls[i](gp_outputs[i], batch_multi_labels[:, i])\n",
    "\n",
    "                        loss.mean()\n",
    "                        loss += 0.5 * criterion_bce(outputs, batch_multi_labels)\n",
    "                        total_loss += loss.item()\n",
    "\n",
    "                        probabilities = torch.stack([likelihoods[i](gp_outputs[i]).probs for i in range(NUM_CLASSES)],\n",
    "                                                    dim=1)\n",
    "                        preds = (probabilities >= THRESHOLD).int()\n",
    "                    else:\n",
    "                        loss = -mlls(gp_outputs, batch_patient_labels) * 0.5 + 0.5 * criterion_bce(outputs.squeeze(-1),\n",
    "                                                                                                   batch_patient_labels)\n",
    "                        # loss = -mlls(gp_outputs, batch_patient_labels)\n",
    "                        loss = loss.mean()\n",
    "                        total_loss += loss.item()\n",
    "                        preds = likelihoods(gp_outputs).probs >= THRESHOLD\n",
    "                        # preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "                predictions.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "            if NUM_CLASSES == 1:\n",
    "                labels.extend(batch_patient_labels.cpu().numpy())\n",
    "            else:\n",
    "                labels.extend(batch_multi_labels.cpu().numpy())\n",
    "    return total_loss / len(data_loader), predictions, labels\n",
    "\n",
    "\n",
    "def train_model(model, likelihoods, train_loader, val_loader, criterion_cl, criterion_bce, optimizer, num_epochs,\n",
    "                learning_rate, device='cuda'):\n",
    "    \"\"\"Train the model and return the best model based on validation accuracy.\"\"\"\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    likelihoods.train()\n",
    "\n",
    "    # Initialize Early Stopping\n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "\n",
    "    if GP_MODEL == 'single_task':\n",
    "        if NUM_CLASSES != 1:\n",
    "            mlls = [\n",
    "                gpytorch.mlls.VariationalELBO(likelihoods[i], model.gp_layers[i], num_data=len(train_loader.dataset))\n",
    "                for\n",
    "                i in range(NUM_CLASSES)]\n",
    "            mlls = [mll.to(device) for mll in mlls]\n",
    "\n",
    "            variational_ngd_optimizer = [\n",
    "                gpytorch.optim.NGD(model.gp_layers[i].variational_parameters(), num_data=len(train_loader.dataset),\n",
    "                                   lr=LEARNING_RATE_NGD) for i in range(NUM_CLASSES)]\n",
    "        else:\n",
    "            mlls = gpytorch.mlls.VariationalELBO(likelihoods, model.gp_layers, num_data=len(train_loader.dataset))\n",
    "            mlls = mlls.to(device)\n",
    "            variational_ngd_optimizer = gpytorch.optim.NGD(model.gp_layers.variational_parameters(),\n",
    "                                                           num_data=len(train_loader.dataset),\n",
    "                                                           lr=LEARNING_RATE_NGD)\n",
    "\n",
    "    # scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=len(train_loader), epochs=num_epochs)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-5)\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "    best_likelihood_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_predictions, train_labels = train_epoch(model, likelihoods, train_loader, criterion_cl,\n",
    "                                                                  criterion_bce,\n",
    "                                                                  mlls, optimizer, variational_ngd_optimizer,\n",
    "                                                                  scheduler, device)\n",
    "        train_metrics = calculate_metrics(train_predictions, train_labels)\n",
    "        print_epoch_stats(epoch, num_epochs, \"train\", train_loss, train_metrics)\n",
    "\n",
    "        wandb.log({\n",
    "            \"train/loss\": train_loss,\n",
    "            \"train/accuracy\": train_metrics[\"accuracy\"],\n",
    "            \"train/precision\": train_metrics[\"precision\"],\n",
    "            \"train/recall\": train_metrics[\"recall\"],\n",
    "            \"train/f1\": train_metrics[\"f1\"],\n",
    "            \"train/auc\": train_metrics[\"auc\"],\n",
    "            \"train/cohen_kappa\": train_metrics[\"cohen_kappa\"]\n",
    "        })\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, val_predictions, val_labels = validate(model, likelihoods, val_loader, criterion_cl, criterion_bce,\n",
    "                                                         mlls,\n",
    "                                                         device)\n",
    "        val_metrics = calculate_metrics(val_predictions, val_labels)\n",
    "        print_epoch_stats(epoch, num_epochs, \"validation\", val_loss, val_metrics)\n",
    "\n",
    "        wandb.log({\n",
    "            \"val/loss\": val_loss,\n",
    "            \"val/accuracy\": val_metrics[\"accuracy\"],\n",
    "            \"val/precision\": val_metrics[\"precision\"],\n",
    "            \"val/recall\": val_metrics[\"recall\"],\n",
    "            \"val/f1\": val_metrics[\"f1\"],\n",
    "            \"val/auc\": val_metrics[\"auc\"],\n",
    "            \"val/cohen_kappa\": val_metrics[\"cohen_kappa\"]\n",
    "        })\n",
    "\n",
    "        # Early Stopping Check\n",
    "        early_stopping(val_metrics[\"accuracy\"], model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        # Save best model\n",
    "        if val_metrics['accuracy'] > best_val_accuracy:\n",
    "            best_val_accuracy = val_metrics['accuracy']\n",
    "            best_model_state = model.state_dict()\n",
    "            best_likelihood_state = likelihoods.state_dict()\n",
    "\n",
    "    # Load best model\n",
    "    if best_model_state and best_likelihood_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        likelihoods.load_state_dict(best_likelihood_state)\n",
    "    # Optionally log the best model to W&B (if desired)\n",
    "    print(f'Best Validation Accuracy: {best_val_accuracy}')\n",
    "    wandb.log_artifact(wandb.Artifact(\"best_model\", type=\"model\", metadata={\"accuracy\": best_val_accuracy}))\n",
    "\n",
    "    return model, likelihoods"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "69eb82ef6c7a8f86",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "id": "967f6eb1fe5ef54f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:01.970224Z",
     "start_time": "2025-02-24T14:54:01.951620Z"
    }
   },
   "source": [
    "## Model Evaluation Functions\n",
    "def evaluate_model(model, likelihoods, data_loader, device='cuda'):\n",
    "    \"\"\"Evaluate the model on the given data loader.\"\"\"\n",
    "    model = model.to(device)\n",
    "    likelihoods = likelihoods.to(device)\n",
    "    model.eval()\n",
    "    likelihoods.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in data_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                outputs, gp_outputs, _, att_outputs = model(batch_data)\n",
    "                if GP_MODEL == 'single_task':\n",
    "                    if NUM_CLASSES > 1:\n",
    "                        probabilities = torch.stack([likelihoods[i](gp_outputs[i]).probs for i in range(NUM_CLASSES)],\n",
    "                                                    dim=1)\n",
    "                    else:\n",
    "                        probabilities = likelihoods(gp_outputs).probs\n",
    "                    preds = (probabilities >= THRESHOLD).int()\n",
    "                    # preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "                predictions.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "            if NUM_CLASSES == 1:\n",
    "                labels.extend(batch_patient_labels.cpu().numpy())\n",
    "            else:\n",
    "                labels.extend(batch_multi_labels.cpu().numpy())\n",
    "\n",
    "            probs.extend(probabilities.cpu().detach().numpy())\n",
    "\n",
    "    return np.array(predictions), np.array(labels), np.array(probs)\n",
    "\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    \"\"\"Print the calculated metrics.\"\"\"\n",
    "    print(f\"Test Accuracy: {metrics['accuracy']:.4f}, \"\n",
    "          f\"Precision: {metrics['precision']:.4f}, \"\n",
    "          f\"Recall: {metrics['recall']:.4f}, \"\n",
    "          f\"F1: {metrics['f1']:.4f}\",\n",
    "          f\"AUC: {metrics['auc']:.4f}\",\n",
    "          f\"Cohen Kappa: {metrics['cohen_kappa']:.4f}\")"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "387310f64ec783c7",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "id": "688ee14ca4c63b43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:02.027622Z",
     "start_time": "2025-02-24T14:54:02.004965Z"
    }
   },
   "source": [
    "## Visualization Functions\n",
    "def plot_roc_curve(model, likelihoods, data_loader, device):\n",
    "    \"\"\"Plot the ROC curve for the model predictions.\"\"\"\n",
    "    model.eval()\n",
    "    if likelihoods:\n",
    "        likelihoods.eval()\n",
    "    labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in data_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                outputs, gp_outputs, _, _ = model(batch_data)\n",
    "                if GP_MODEL == 'single_task':\n",
    "                    if NUM_CLASSES > 1:\n",
    "                        probabilities = torch.stack([likelihoods[i](gp_outputs[i]).probs for i in range(NUM_CLASSES)],\n",
    "                                                    dim=1)\n",
    "                    else:\n",
    "                        probabilities = likelihoods(gp_outputs).probs\n",
    "                    preds = probabilities\n",
    "\n",
    "                else:\n",
    "                    preds = torch.sigmoid(outputs)\n",
    "                predictions.extend(preds.cpu().detach().numpy())\n",
    "            else:\n",
    "                outputs, cnn_features, attention_weights, _ = model(batch_data)\n",
    "                preds = torch.sigmoid(outputs)\n",
    "                predictions.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "            if NUM_CLASSES == 1:  # Binary classification\n",
    "                labels.extend(batch_patient_labels.cpu().numpy())\n",
    "            else:\n",
    "                labels.extend(batch_multi_labels.cpu().numpy())\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    if NUM_CLASSES == 1:\n",
    "        fpr, tpr, _ = roc_curve(labels, predictions)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    else:\n",
    "        class_name = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "        for i in range(NUM_CLASSES):\n",
    "            fpr, tpr, _ = roc_curve(labels[:, i], predictions[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, lw=2,\n",
    "                     label=f'Class {class_name[i]} (AUC = {roc_auc:.4f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_auc(labels, scores):\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC AUC = {roc_auc:.4f}')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(model, likelihoods, data_loader, criterion_cl, criterion_bce, device):\n",
    "    \"\"\"Plot confusion matrix for classification tasks.\"\"\"\n",
    "    if likelihoods:\n",
    "        predictions, labels, _ = evaluate_model(model, likelihoods, data_loader, device)\n",
    "    else:\n",
    "        predictions, labels, _ = evaluate_phase_1(model, data_loader, criterion_cl, criterion_bce, device)\n",
    "    if NUM_CLASSES > 1:  # Multi-label/multi-class\n",
    "        cm = multilabel_confusion_matrix(labels, predictions)\n",
    "        _, ax = plt.subplots(1, NUM_CLASSES, figsize=(15, 3))\n",
    "        for i in range(NUM_CLASSES):\n",
    "            ConfusionMatrixDisplay(cm[i]).plot(ax=ax[i])\n",
    "            ax[i].set_title(f'Class {i}')\n",
    "    else:  # Binary\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        ConfusionMatrixDisplay(cm).plot()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "eb67abfc34676ddc",
   "metadata": {},
   "source": [
    "# Model Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "d3ea64ecd34312a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:02.072198Z",
     "start_time": "2025-02-24T14:54:02.054312Z"
    }
   },
   "source": [
    "## Data Processing Functions\n",
    "def load_model(model_class, model_path, params):\n",
    "    \"\"\"Load a trained model from a file.\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "\n",
    "    model = model_class(params)\n",
    "    try:\n",
    "        state_dict = torch.load(model_path, map_location=torch.device('cuda'), weights_only=True)\n",
    "        if not state_dict:\n",
    "            raise ValueError(f\"The state dictionary loaded from {model_path} is empty\")\n",
    "        model.load_state_dict(state_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model from {model_path}: {str(e)}\")\n",
    "        print(\"Initializing model with random weights instead.\")\n",
    "        return model  # Return the model with random initialization\n",
    "\n",
    "    return model.eval()\n",
    "\n",
    "\n",
    "def get_test_results(model, test_loader, test_labels, device=DEVICE):\n",
    "    \"\"\"Get test results including patient information.\"\"\"\n",
    "    predictions, _ = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    results = []\n",
    "    for i, row in enumerate(test_labels.itertuples(index=False)):\n",
    "        result = {col: getattr(row, col) for col in test_labels.columns}\n",
    "        result['prediction'] = predictions[i]\n",
    "        results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "17ee691aa362b802",
   "metadata": {},
   "source": [
    "### Extract Trained Features from the Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "349f2e095a06ef68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:02.122613Z",
     "start_time": "2025-02-24T14:54:02.103511Z"
    }
   },
   "source": [
    "def extract_features_for_df(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_instance_labels = []\n",
    "    all_bag_labels = []\n",
    "    all_bag_multi_labels = []\n",
    "    all_bag_ids = []\n",
    "    all_instance_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (bags, instance_labels, bag_labels, bag_multi_labels) in enumerate(data_loader):\n",
    "            bags = bags.to(device)\n",
    "            instance_labels = instance_labels.to(device)\n",
    "            bag_labels = bag_labels.to(device)\n",
    "            bag_multi_labels = bag_multi_labels.to(device)\n",
    "\n",
    "            _, cnn_features, _, _ = model(bags)\n",
    "\n",
    "            batch_size, num_instances, num_features = cnn_features.shape\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                bag_features = cnn_features[i].cpu().numpy()\n",
    "                bag_instance_labels = instance_labels[i].cpu().numpy()\n",
    "                bag_label = bag_labels[i].cpu().numpy()\n",
    "                bag_multi_label = bag_multi_labels[i].cpu().numpy()\n",
    "\n",
    "                all_features.append(bag_features)\n",
    "                all_instance_labels.append(bag_instance_labels)\n",
    "                all_bag_labels.append(np.repeat(bag_label, num_instances))\n",
    "                all_bag_multi_labels.append(np.tile(bag_multi_label, (num_instances, 1)))\n",
    "                all_bag_ids.append(np.repeat(batch_idx * batch_size + i, num_instances))\n",
    "                all_instance_ids.append(np.arange(num_instances))\n",
    "\n",
    "    return (np.concatenate(all_features),\n",
    "            np.concatenate(all_instance_labels),\n",
    "            np.concatenate(all_bag_labels),\n",
    "            np.concatenate(all_bag_multi_labels),\n",
    "            np.concatenate(all_bag_ids),\n",
    "            np.concatenate(all_instance_ids))\n",
    "\n",
    "def create_feature_df(data, num_classes):\n",
    "    features, instance_labels, bag_labels, bag_multi_labels, bag_ids, instance_ids = data\n",
    "\n",
    "    # Create column names for features\n",
    "    feature_columns = [f'feature_{i}' for i in range(features.shape[1])]\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(features, columns=feature_columns)\n",
    "    df['instance_label'] = instance_labels\n",
    "    df['bag_label'] = bag_labels\n",
    "\n",
    "    # Add multi-label columns\n",
    "    class_name = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "    for i in range(num_classes):\n",
    "        df[class_name[i]] = bag_multi_labels[:, i]\n",
    "\n",
    "    df['bag_name'] = bag_ids\n",
    "    df['instance_id'] = instance_ids\n",
    "\n",
    "    return df\n",
    "\n",
    "def combine_features(train_df, test_df, filename):\n",
    "    combined_df = pd.concat([train_df, test_df], axis=0)\n",
    "    print(f'Lengh of combined_df: {len(combined_df)}')\n",
    "    combined_df.to_csv(filename, index=False)\n",
    "    return combined_df"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "782c51e99ffa72cd",
   "metadata": {},
   "source": [
    "## Model Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "id": "bc6077893e01344c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:02.170746Z",
     "start_time": "2025-02-24T14:54:02.154089Z"
    }
   },
   "source": [
    "# If you need to use the Glorot (Xavier) uniform initialization\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "aa03f3cfc19f4215",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:02.220561Z",
     "start_time": "2025-02-24T14:54:02.195317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main(mode='train', use_cv=False, num_folds=5):\n",
    "    # os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "    current_time = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    run_name = f\"{TRAINING_TYPE}_experiment_{current_time}_{GP_MODEL}_refiner_fc_{PROJECTION_HIDDEN_DIM}_output_{PROJECTION_OUTPUT_DIM}_attention_{ATTENTION_HIDDEN_DIM}_kernel_{GP_KERNEL}_model_{MODEL_TYPE}\"\n",
    "\n",
    "    # Initialize W&B with a specific run name\n",
    "    wandb.init(project=\"MIL_Resnet_ICH\", name=run_name)\n",
    "\n",
    "    # Log hyperparameters\n",
    "    config = wandb.config\n",
    "    config.learning_rate = LEARNING_RATE\n",
    "    config.batch_size = TRAIN_BATCH_SIZE\n",
    "    config.num_epochs = NUM_EPOCHS\n",
    "\n",
    "    params = {\n",
    "        'channels': CHANNELS,  # Number of input channels (e.g., 1 for grayscale, 3 for RGB)\n",
    "        'num_classes': NUM_CLASSES,  # Number of output classes for classification\n",
    "        'drop_prob': 0.5,  # Dropout probability\n",
    "        'inducing_points': INDUCING_POINTS,  # Number of inducing points for the Gaussian Process layer\n",
    "        'projection_location': PROJECTION_LOCATION,  # Choose from 'after_resnet', 'after_attention', or 'after_gp'\n",
    "        'projection_hidden_dim': PROJECTION_HIDDEN_DIM,  # Hidden dimension size for the projection head\n",
    "        'projection_output_dim': PROJECTION_OUTPUT_DIM,  # Output dimension size for the projection head\n",
    "        'attention_hidden_dim': ATTENTION_HIDDEN_DIM,  # Hidden dimension size for the attention head\n",
    "        'gp_model': GP_MODEL,\n",
    "        'kernel_type': GP_KERNEL,\n",
    "        'model_type': MODEL_TYPE,\n",
    "        'contrastive_learning': CONTRASTIVE_LEARNING\n",
    "    }\n",
    "\n",
    "    if use_cv == False:\n",
    "        # if NUM_CLASSES == 1:\n",
    "        #     train_labels, val_labels, test_labels = split_dataset(patient_scan_labels, test_size=TEST_SIZE, num_rows=6000)\n",
    "        # else:\n",
    "        train_labels, val_labels, test_labels = split_dataset_for_multilabel(patient_scan_labels, val_size=0.289, test_size=0.046, num_rows=None)\n",
    "        print(f\"Length of train_labels: {len(train_labels)}\")\n",
    "        print(f\"Length of val_labels: {len(val_labels)}\")\n",
    "        print(f\"Length of test_labels: {len(test_labels)}\")\n",
    "        # test_dir = './data_analyze/testing_dataset_150_redundancy.csv' if DATA_REDUNDANCY else \\\n",
    "        #             './data_analyze/testing_dataset_150.csv'\n",
    "        # test_labels = pd.read_csv(test_dir)\n",
    "\n",
    "        train_loader = get_train_loader(dicom_dir, train_labels, batch_size=TRAIN_BATCH_SIZE)\n",
    "        val_loader = get_train_loader(dicom_dir, val_labels, batch_size=VALID_BATCH_SIZE)\n",
    "        test_loader = get_test_loader(dicom_dir, test_labels, batch_size=TEST_BATCH_SIZE)\n",
    "\n",
    "        if TRAINING_TYPE == 'end_to_end':\n",
    "            if GP_MODEL == 'single_task':\n",
    "                model = MILModels.CNN_ATT_GP_Multilabel(params)\n",
    "\n",
    "                if NUM_CLASSES != 1:\n",
    "                    likelihood = nn.ModuleList([PGLikelihood() for _ in range(NUM_CLASSES)])\n",
    "                else:\n",
    "                    likelihood = PGLikelihood()\n",
    "                optimizer = optim.Adam([\n",
    "                    {'params': model.parameters(), 'lr': config.learning_rate},\n",
    "                    {'params': likelihood.parameters(), 'lr': config.learning_rate}\n",
    "                ])\n",
    "        elif TRAINING_TYPE == 'cnn_att':\n",
    "            model = MILModels.CNN_Attention(params)\n",
    "            likelihood = None\n",
    "            optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "        criterion_cl = NTXentLoss(0.5)\n",
    "        if NUM_CLASSES == 1:\n",
    "            pos_weights = torch.tensor([POS_WEIGHT]).to(DEVICE)\n",
    "        else:\n",
    "            pos_weights = torch.tensor([POS_WEIGHT] * NUM_CLASSES).to(DEVICE)\n",
    "        criterion_bce = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "\n",
    "        if mode == 'train':\n",
    "            wandb.watch(model)  # Watch the model to log gradients and parameters\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                # model.apply(init_weights)\n",
    "                trained_model, likelihood = train_model(model, likelihood, train_loader, val_loader, criterion_cl,\n",
    "                                                        criterion_bce, optimizer, config.num_epochs, config.learning_rate, DEVICE)\n",
    "                predictions, labels, probabilities = evaluate_model(trained_model, likelihood, test_loader, DEVICE)\n",
    "            else:\n",
    "                print(\"Training Phase 1: CNN + ATT\")\n",
    "                trained_model, _ = train_model_phase_1(model, train_loader, val_loader, criterion_cl, criterion_bce,\n",
    "                                                        optimizer, config.num_epochs, DEVICE)\n",
    "                predictions, labels, probabilities = evaluate_phase_1(trained_model, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "\n",
    "            metrics = calculate_metrics(predictions, labels, average='binary')\n",
    "            wandb.log(metrics)\n",
    "            print_metrics(metrics)\n",
    "\n",
    "            plot_roc_curve(trained_model, likelihood, test_loader, DEVICE)\n",
    "            plot_confusion_matrix(trained_model, likelihood, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "            torch.save(trained_model.state_dict(), MODEL_PATH)\n",
    "            if likelihood:\n",
    "                torch.save(likelihood.state_dict(), LIKELIHOOD_PATH)\n",
    "        else:\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                if GP_MODEL == 'single_task':\n",
    "                    trained_model = load_model(MILModels.CNN_ATT_GP_Multilabel, MODEL_PATH, params)\n",
    "                    predictions, labels, probs = evaluate_model(trained_model, likelihood, test_loader, DEVICE)\n",
    "            else:\n",
    "                if DATASET == 'dongnai':\n",
    "                    test_labels = pd.read_csv(CSV_PATH)\n",
    "                    test_loader = get_test_loader(dicom_dir, test_labels, batch_size=TEST_BATCH_SIZE)\n",
    "                trained_model = load_model(MILModels.CNN_Attention, MODEL_PATH, params)\n",
    "                predictions, labels, probs = evaluate_phase_1(trained_model, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "\n",
    "            metrics = calculate_metrics(predictions, labels, average='binary')\n",
    "            wandb.log(metrics)\n",
    "            print_metrics(metrics)\n",
    "\n",
    "            plot_roc_curve(trained_model, likelihood, test_loader, DEVICE)\n",
    "            plot_confusion_matrix(trained_model, likelihood, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "\n",
    "        if TRAINING_TYPE != 'end_to_end' and mode == 'train':\n",
    "            train_data = extract_features_for_df(trained_model, train_loader, DEVICE)\n",
    "            val_data = extract_features_for_df(trained_model, val_loader, DEVICE)\n",
    "            test_data = extract_features_for_df(trained_model, test_loader, DEVICE)\n",
    "\n",
    "            df_train = create_feature_df(train_data, num_classes=6)\n",
    "            df_val = create_feature_df(val_data, num_classes=6)\n",
    "            df_test = create_feature_df(test_data, num_classes=6)\n",
    "\n",
    "            print(f'Lenght of df_train: {len(df_train)}')\n",
    "            print(f'Lenght of df_val: {len(df_val)}')\n",
    "            print(f'Lenght of df_test: {len(df_test)}')\n",
    "\n",
    "            # combine_features(df_train, df_val, \"data/cv_data/train_features.csv\")\n",
    "            df_train.to_csv(\"./data/cv_data/train_features.csv\", index=False)\n",
    "            df_val.to_csv(\"./data/cv_data/val_features.csv\", index=False)\n",
    "\n",
    "            df_test.to_csv(\"./data/cv_data/test_features.csv\", index=False)\n",
    "\n",
    "    else:\n",
    "        if NUM_CLASSES == 1:\n",
    "            trainval_labels, test_labels, _ = split_dataset(\n",
    "                patient_scan_labels,\n",
    "                val_size=TEST_SIZE,\n",
    "                test_size=0.0\n",
    "            )\n",
    "            # test_labels = pd.read_csv('./data_analyze/testing_dataset_150_redundancy.csv')\n",
    "        else:\n",
    "            trainval_labels, test_labels, _ = split_dataset_for_multilabel(\n",
    "                patient_scan_labels,\n",
    "                val_size=TEST_SIZE,\n",
    "                test_size=0.0\n",
    "            )\n",
    "\n",
    "        # Setup CV using trainval data\n",
    "        kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "        fold_metrics = []\n",
    "\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kf.split(trainval_labels)):\n",
    "            print(f\"\\nFold {fold_idx + 1}/{num_folds}\")\n",
    "\n",
    "            # Create fold splits\n",
    "            train_labels_fold = trainval_labels.iloc[train_idx]\n",
    "            val_labels_fold = trainval_labels.iloc[val_idx]\n",
    "\n",
    "            # Create data loaders\n",
    "            train_loader = get_train_loader(dicom_dir, train_labels_fold, TRAIN_BATCH_SIZE)\n",
    "            val_loader = get_train_loader(dicom_dir, val_labels_fold, VALID_BATCH_SIZE)\n",
    "            test_loader = get_test_loader(dicom_dir, test_labels, TEST_BATCH_SIZE)\n",
    "\n",
    "            # Initialize model\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                if GP_MODEL == 'single_task':\n",
    "                    model = MILModels.CNN_ATT_GP_Multilabel(params)\n",
    "                    if NUM_CLASSES != 1:\n",
    "                        likelihood = nn.ModuleList([PGLikelihood() for _ in range(NUM_CLASSES)])\n",
    "                    else:\n",
    "                        likelihood = PGLikelihood()\n",
    "                    optimizer = optim.Adam([\n",
    "                        {'params': model.parameters(), 'lr': config.learning_rate},\n",
    "                        {'params': likelihood.parameters(), 'lr': config.learning_rate}\n",
    "                    ])\n",
    "            elif TRAINING_TYPE == 'cnn_att':\n",
    "                model = MILModels.CNN_Attention(params)\n",
    "                likelihood = None\n",
    "                optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "            if NUM_CLASSES == 1:\n",
    "                pos_weights = torch.tensor([POS_WEIGHT]).to(DEVICE)\n",
    "            else:\n",
    "                pos_weights = torch.tensor([POS_WEIGHT] * NUM_CLASSES).to(DEVICE)\n",
    "            criterion_bce = nn.BCEWithLogitsLoss(pos_weight=pos_weights) # Weighted BCE Loss\n",
    "            criterion_cl = NTXentLoss(0.5) # Contrastive Learning Loss\n",
    "\n",
    "            # Train model\n",
    "            wandb.init(project=\"MIL_Resnet_ICH\", name=f\"{run_name}_fold_{fold_idx + 1}\")\n",
    "            wandb.watch(model)\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                trained_model, likelihood = train_model(model, likelihood, train_loader, val_loader, criterion_cl,\n",
    "                                                        criterion_bce,\n",
    "                                                        optimizer, config.num_epochs, config.learning_rate, DEVICE)\n",
    "                predictions, labels, probabilities = evaluate_model(trained_model, likelihood, test_loader, DEVICE)\n",
    "            else:\n",
    "                trained_model, _ = train_model_phase_1(model, train_loader, val_loader, criterion_cl, criterion_bce,\n",
    "                                                        optimizer, config.num_epochs, DEVICE)\n",
    "                predictions, labels, probabilities = evaluate_phase_1(trained_model, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "\n",
    "\n",
    "            metrics = calculate_metrics(predictions, labels)\n",
    "\n",
    "            # Log metrics\n",
    "            wandb.log(metrics)\n",
    "            print_metrics(metrics)\n",
    "            fold_metrics.append(metrics)\n",
    "\n",
    "            plot_roc_curve(trained_model, likelihood, test_loader, DEVICE)\n",
    "            plot_confusion_matrix(trained_model, likelihood, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "\n",
    "            # Save model\n",
    "            torch.save(trained_model.state_dict(), f\"{MODEL_PATH}_fold_{fold_idx + 1}\")\n",
    "            if likelihood:\n",
    "                torch.save(likelihood.state_dict(), f\"{LIKELIHOOD_PATH}_fold_{fold_idx + 1}\")\n",
    "\n",
    "            # Extract features for train and val sets\n",
    "            train_data = extract_features_for_df(trained_model, train_loader, DEVICE)\n",
    "            val_data = extract_features_for_df(trained_model, val_loader, DEVICE)\n",
    "            test_data = extract_features_for_df(trained_model, test_loader, DEVICE)\n",
    "\n",
    "            df_train = create_feature_df(train_data, num_classes=6)\n",
    "            df_val = create_feature_df(val_data, num_classes=6)\n",
    "            df_test = create_feature_df(test_data, num_classes=6)\n",
    "            # combine_features(df_train, df_val, filename)\n",
    "            print(f'Lenght of df_train: {len(df_train)}')\n",
    "            print(f'Lenght of df_val: {len(df_val)}')\n",
    "            print(f'Lenght of df_test: {len(df_test)}')\n",
    "            df_train.to_csv(f\"./data/cv_data/train_features_fold_{fold_idx + 1}.csv\", index=False)\n",
    "            df_val.to_csv(f\"./data/cv_data/val_features_fold_{fold_idx + 1}.csv\", index=False)\n",
    "            df_test.to_csv(f\"./data/cv_data/test_features_fold_{fold_idx + 1}.csv\", index=False)\n",
    "\n",
    "        # Calculate average metrics across all folds\n",
    "        avg_metrics = {}\n",
    "        for metric in fold_metrics[0].keys():\n",
    "            avg_metrics[metric] = np.mean([fold[metric] for fold in fold_metrics])\n",
    "        print(\"\\nAverage Metrics Across All Folds:\")\n",
    "        print_metrics(avg_metrics)\n",
    "        wandb.log(avg_metrics)"
   ],
   "id": "f2fa85bcea8796ea",
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "a5e68015552ccdc6",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "id": "1cf2cee20d2c1862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T15:14:12.937683Z",
     "start_time": "2025-02-24T14:54:02.246221Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(mode=MODE, use_cv=False, num_folds=5)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhuynhsikha2003\u001B[0m (\u001B[33mhuynhsikha2003-i-h-c-qu-c-gia-tp-hcm\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/media/hskha23/Kha/Brain-Stroke-Diagnosis/rsna/wandb/run-20250224_215403-2zfwj27x</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/MIL_Resnet_ICH/runs/2zfwj27x' target=\"_blank\">cnn_att_experiment_20250224_2154_single_task_refiner_fc_256_output_128_attention_64_kernel_rbf_model_resnet18</a></strong> to <a href='https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/MIL_Resnet_ICH' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/MIL_Resnet_ICH' target=\"_blank\">https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/MIL_Resnet_ICH</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/MIL_Resnet_ICH/runs/2zfwj27x' target=\"_blank\">https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/MIL_Resnet_ICH/runs/2zfwj27x</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_labels: 14748\n",
      "Length of val_labels: 5995\n",
      "Length of test_labels: 1001\n",
      "Training Phase 1: CNN + ATT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3687/3687 [06:58<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - Train:\n",
      "Loss: 0.6448, Accuracy: 0.7623, Precision: 0.6739, Recall: 0.8115, F1: 0.7364, AUC: 0.7699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1498/1498 [01:02<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - Val:\n",
      "Loss: 0.5321, Accuracy: 0.8178, Precision: 0.7336, Recall: 0.8677, F1: 0.7950, AUC: 0.8256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3687/3687 [07:01<00:00,  8.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2 - Train:\n",
      "Loss: 0.4274, Accuracy: 0.8757, Precision: 0.8356, Recall: 0.8667, F1: 0.8509, AUC: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1498/1498 [01:05<00:00, 23.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2 - Val:\n",
      "Loss: 0.3572, Accuracy: 0.9024, Precision: 0.8622, Recall: 0.9050, F1: 0.8831, AUC: 0.9028\n",
      "Best Accuracy: 0.902369826435247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 251/251 [00:11<00:00, 21.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8921, Precision: 0.8534, Recall: 0.8870, F1: 0.8699 AUC: 0.8913 Cohen Kappa: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 251/251 [00:09<00:00, 25.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of df_train: 412944\n",
      "Lenght of df_val: 167776\n",
      "Lenght of df_test: 28028\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
