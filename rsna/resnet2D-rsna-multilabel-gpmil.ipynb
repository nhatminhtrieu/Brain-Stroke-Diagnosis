{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04ce7fc16269637",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "827de11a1d9590d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:22.812160Z",
     "start_time": "2025-02-18T14:59:21.192634Z"
    }
   },
   "source": [
    "from sched import scheduler\n",
    "!pip install gpytorch torchsummary iterative-stratification optuna pytorch_metric_learning wandb\n",
    "!pip install torch pydicom pandas scikit-learn scikit-image numpy opencv-python matplotlib"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpytorch in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (1.13)\r\n",
      "Requirement already satisfied: torchsummary in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (1.5.1)\r\n",
      "Requirement already satisfied: iterative-stratification in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (0.1.9)\r\n",
      "Requirement already satisfied: optuna in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (4.1.0)\r\n",
      "Requirement already satisfied: pytorch_metric_learning in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (2.8.1)\r\n",
      "Requirement already satisfied: wandb in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (0.18.5)\r\n",
      "Requirement already satisfied: jaxtyping==0.2.19 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (0.2.19)\r\n",
      "Requirement already satisfied: mpmath<=1.3,>=0.19 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (1.3.0)\r\n",
      "Requirement already satisfied: scikit-learn in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (1.5.1)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (1.10.1)\r\n",
      "Requirement already satisfied: linear-operator>=0.5.3 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gpytorch) (0.5.3)\r\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from jaxtyping==0.2.19->gpytorch) (1.26.4)\r\n",
      "Requirement already satisfied: typeguard>=2.13.3 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from jaxtyping==0.2.19->gpytorch) (4.2.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from jaxtyping==0.2.19->gpytorch) (4.12.2)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from optuna) (1.14.0)\r\n",
      "Requirement already satisfied: colorlog in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from optuna) (6.9.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from optuna) (24.1)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from optuna) (2.0.36)\r\n",
      "Requirement already satisfied: tqdm in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from optuna) (4.66.4)\r\n",
      "Requirement already satisfied: PyYAML in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from optuna) (6.0.1)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from pytorch_metric_learning) (2.4.0)\r\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (8.1.7)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (3.1.43)\r\n",
      "Requirement already satisfied: platformdirs in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (4.2.2)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (4.21.12)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (6.0.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (2.32.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (2.17.0)\r\n",
      "Requirement already satisfied: setproctitle in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (1.3.3)\r\n",
      "Requirement already satisfied: setuptools in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from wandb) (72.1.0)\r\n",
      "Requirement already satisfied: Mako in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.8)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.0)\r\n",
      "Requirement already satisfied: filelock in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (3.13.1)\r\n",
      "Requirement already satisfied: sympy in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (2024.6.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (2.20.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\r\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (3.0.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->pytorch_metric_learning) (12.6.20)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-learn->gpytorch) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-learn->gpytorch) (3.5.0)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->pytorch_metric_learning) (2.1.3)\r\n",
      "Requirement already satisfied: torch in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (2.4.0)\r\n",
      "Requirement already satisfied: pydicom in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (2.4.4)\r\n",
      "Requirement already satisfied: pandas in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: scikit-learn in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (1.5.1)\r\n",
      "Requirement already satisfied: scikit-image in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (0.23.2)\r\n",
      "Requirement already satisfied: numpy in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (1.26.4)\r\n",
      "Requirement already satisfied: opencv-python in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (4.6.0)\r\n",
      "Requirement already satisfied: matplotlib in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (3.8.4)\r\n",
      "Requirement already satisfied: filelock in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (2024.6.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (2.20.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from torch) (3.0.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\r\n",
      "Requirement already satisfied: pillow>=9.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-image) (10.4.0)\r\n",
      "Requirement already satisfied: imageio>=2.33 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-image) (2.33.1)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-image) (2022.10.10)\r\n",
      "Requirement already satisfied: packaging>=21 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-image) (24.1)\r\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-image) (0.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib) (4.51.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib) (1.4.4)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "7a33c97468126c29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.156480Z",
     "start_time": "2025-02-18T14:59:22.826347Z"
    }
   },
   "source": [
    "import optuna\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from pytorch_metric_learning import losses\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, \\\n",
    "    multilabel_confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import models.mil_resnet as MILModels\n",
    "from utils import hard_negative_mining as hnm\n",
    "import gpytorch\n",
    "from layers.gaussian_process import SingletaskGPModel, PGLikelihood\n",
    "from utils.early_stopping import EarlyStoppingForOptimization, EarlyStopping\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "8a37479f6e74e822",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.180172Z",
     "start_time": "2025-02-18T14:59:24.178502Z"
    }
   },
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "14b411feb08f174a",
   "metadata": {},
   "source": [
    "# Configurations\n",
    "## GPU Configurations"
   ]
  },
  {
   "cell_type": "code",
   "id": "f4bc308439eee7c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.239256Z",
     "start_time": "2025-02-18T14:59:24.221460Z"
    }
   },
   "source": [
    "# Initialize GPU Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 4070 SUPER is available.\n",
      "cuda\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "8af9c65019e61153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.292541Z",
     "start_time": "2025-02-18T14:59:24.272433Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "90f07b41df278477",
   "metadata": {},
   "source": [
    "## Seed Everything"
   ]
  },
  {
   "cell_type": "code",
   "id": "389bfe8198c54df2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.336488Z",
     "start_time": "2025-02-18T14:59:24.316076Z"
    }
   },
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "59c5af8335d4fd7c",
   "metadata": {},
   "source": [
    "## Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "id": "efb1cdf72f6905c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.380637Z",
     "start_time": "2025-02-18T14:59:24.361047Z"
    }
   },
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"../config.yaml\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Accessing constants from config\n",
    "HEIGHT = config['height']\n",
    "WIDTH = config['width']\n",
    "CHANNELS = config['channels']\n",
    "\n",
    "TRAIN_BATCH_SIZE = config['train_batch_size']\n",
    "VALID_BATCH_SIZE = config['valid_batch_size']\n",
    "TEST_BATCH_SIZE = config['test_batch_size']\n",
    "TEST_SIZE = config['test_size']\n",
    "VALID_SIZE = config['valid_size']\n",
    "\n",
    "TRAINING_TYPE = config['training_type']\n",
    "DATA_REDUNDANCY = config['data_redundancy']\n",
    "GP_MODEL = config['gp_model']\n",
    "GP_KERNEL = config['kernel_type']\n",
    "MODEL_TYPE = config['model_type']\n",
    "CONTRASTIVE_LEARNING = config['contrastive_learning']\n",
    "\n",
    "MAX_SLICES = config['max_slices']\n",
    "SHAPE = tuple(config['shape'])\n",
    "\n",
    "NUM_EPOCHS = config['num_epochs']\n",
    "LEARNING_RATE = config['learning_rate']\n",
    "LEARNING_RATE_NGD = config['learning_rate_ngd']\n",
    "INDUCING_POINTS = config['inducing_points']\n",
    "THRESHOLD = config['threshold']\n",
    "\n",
    "NUM_CLASSES = config['num_classes']\n",
    "\n",
    "TARGET_LABELS = config['target_labels']\n",
    "\n",
    "MODEL_PATH = config['model_path']\n",
    "LIKELIHOOD_PATH = config['likelihood_path']\n",
    "DEVICE = config['device']\n",
    "\n",
    "PROJECTION_LOCATION = config['projection_location']\n",
    "PROJECTION_HIDDEN_DIM = config['projection_hidden_dim']\n",
    "PROJECTION_OUTPUT_DIM = config['projection_output_dim']\n",
    "\n",
    "ATTENTION_HIDDEN_DIM = config['attention_hidden_dim']"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "933cef7e185bd55c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.445378Z",
     "start_time": "2025-02-18T14:59:24.407690Z"
    }
   },
   "source": [
    "KAGGLE = os.path.exists(('kaggle/input'))\n",
    "REMOTE_SERVER = os.path.exists(('/workspace/rsna-ich-mil'))\n",
    "ROOT_DIR = None\n",
    "\n",
    "if KAGGLE:\n",
    "    DATA_DIR = ROOT_DIR + 'rsna-mil-training/'\n",
    "    DICOM_DIR = DATA_DIR\n",
    "    CSV_PATH = DICOM_DIR + 'training_1000_scan_subset.csv'\n",
    "elif REMOTE_SERVER:\n",
    "    DATA_DIR = '/root/rsna-ich-mil/'\n",
    "    DICOM_DIR = DATA_DIR\n",
    "    if DATA_REDUNDANCY:\n",
    "        CSV_PATH = DATA_DIR + 'training_dataset_1150_redundancy.csv'\n",
    "    else:\n",
    "        CSV_PATH = '/workspace/training_dataset_1150.csv'\n",
    "    print('Running on remote server.')\n",
    "else:\n",
    "    DATA_DIR = '../rsna-ich-mil/'\n",
    "    DICOM_DIR = DATA_DIR\n",
    "    if DATA_REDUNDANCY:\n",
    "        CSV_PATH = './data_analyze/training_dataset_1150_redundancy.csv'\n",
    "    else:\n",
    "        CSV_PATH = './data_analyze/training_dataset_1150.csv'\n",
    "    print(f'CSV Path: {CSV_PATH}')\n",
    "\n",
    "patient_scan_labels = pd.read_csv(CSV_PATH, nrows=1150)\n",
    "# patient_scan_labels = pd.read_csv(CSV_PATH)\n",
    "dicom_dir = DICOM_DIR if KAGGLE else DATA_DIR"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Path: ./data_analyze/training_dataset_1150_redundancy.csv\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "6c85475b0541e387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.478808Z",
     "start_time": "2025-02-18T14:59:24.457465Z"
    }
   },
   "source": [
    "patient_scan_labels.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            filename  \\\n",
       "0  ['ID_766be7451.dcm', 'ID_d1d35ed25.dcm', 'ID_4...   \n",
       "1  ['ID_0d5c28287.dcm', 'ID_dc5f5d774.dcm', 'ID_f...   \n",
       "2  ['ID_080e55858.dcm', 'ID_ad9ea42be.dcm', 'ID_9...   \n",
       "3  ['ID_6407b752d.dcm', 'ID_bff0001cf.dcm', 'ID_1...   \n",
       "4  ['ID_db255faea.dcm', 'ID_68ba9321f.dcm', 'ID_d...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                 any  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                            epidural  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                    intraparenchymal  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                    intraventricular  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                        subarachnoid  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                            subdural   patient_id  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ID_005f241d   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ID_0075b28c   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...  ID_00760731   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ID_00859e11   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ID_00a3b735   \n",
       "\n",
       "  study_instance_uid  ... patient_label  \\\n",
       "0      ID_07e2cf7b4b  ...             0   \n",
       "1      ID_0373dbdd02  ...             0   \n",
       "2      ID_006a2c59e4  ...             1   \n",
       "3      ID_01f49be39f  ...             1   \n",
       "4      ID_065682422f  ...             0   \n",
       "\n",
       "                                              z_axis  \\\n",
       "0  [66.486, 71.701, 76.915, 82.13, 87.344, 92.559...   \n",
       "1  [41.534897, 46.699394, 51.864895, 57.029396, 6...   \n",
       "2  [5.25, 10.25, 15.25, 20.25, 25.25, 30.25, 35.2...   \n",
       "3  [-1.452, 3.713, 8.877, 14.042, 19.206, 24.371,...   \n",
       "4  [69.9000244, 74.9000244, 79.9000244, 84.900024...   \n",
       "\n",
       "                                     slice_thickness  \\\n",
       "0  [2.61, 2.61, 2.61, 2.61, 2.61, 2.61, 2.61, 2.3...   \n",
       "1  [2.58, 2.58, 2.58, 2.58, 2.58, 2.58, 2.58, 2.7...   \n",
       "2  [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "3  [5.16, 5.16, 5.16, 5.16, 5.16, 5.16, 5.17, 5.1...   \n",
       "4  [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "\n",
       "                                    selected_indices patient_any  \\\n",
       "0  [1, 3, 5, 7, 9, 11, 13, 15, 16, 17, 18, 19, 20...           0   \n",
       "1  [1, 3, 5, 7, 9, 11, 13, 15, 16, 17, 18, 19, 20...           0   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...           1   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...           1   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...           0   \n",
       "\n",
       "  patient_subdural patient_epidural patient_intraparenchymal  \\\n",
       "0                0                0                        0   \n",
       "1                0                0                        0   \n",
       "2                1                0                        1   \n",
       "3                0                0                        1   \n",
       "4                0                0                        0   \n",
       "\n",
       "   patient_intraventricular patient_subarachnoid  \n",
       "0                         0                    0  \n",
       "1                         0                    0  \n",
       "2                         1                    1  \n",
       "3                         0                    0  \n",
       "4                         0                    0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>labels</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>study_instance_uid</th>\n",
       "      <th>...</th>\n",
       "      <th>patient_label</th>\n",
       "      <th>z_axis</th>\n",
       "      <th>slice_thickness</th>\n",
       "      <th>selected_indices</th>\n",
       "      <th>patient_any</th>\n",
       "      <th>patient_subdural</th>\n",
       "      <th>patient_epidural</th>\n",
       "      <th>patient_intraparenchymal</th>\n",
       "      <th>patient_intraventricular</th>\n",
       "      <th>patient_subarachnoid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ID_766be7451.dcm', 'ID_d1d35ed25.dcm', 'ID_4...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>ID_005f241d</td>\n",
       "      <td>ID_07e2cf7b4b</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[66.486, 71.701, 76.915, 82.13, 87.344, 92.559...</td>\n",
       "      <td>[2.61, 2.61, 2.61, 2.61, 2.61, 2.61, 2.61, 2.3...</td>\n",
       "      <td>[1, 3, 5, 7, 9, 11, 13, 15, 16, 17, 18, 19, 20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['ID_0d5c28287.dcm', 'ID_dc5f5d774.dcm', 'ID_f...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>ID_0075b28c</td>\n",
       "      <td>ID_0373dbdd02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[41.534897, 46.699394, 51.864895, 57.029396, 6...</td>\n",
       "      <td>[2.58, 2.58, 2.58, 2.58, 2.58, 2.58, 2.58, 2.7...</td>\n",
       "      <td>[1, 3, 5, 7, 9, 11, 13, 15, 16, 17, 18, 19, 20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['ID_080e55858.dcm', 'ID_ad9ea42be.dcm', 'ID_9...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>ID_00760731</td>\n",
       "      <td>ID_006a2c59e4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[5.25, 10.25, 15.25, 20.25, 25.25, 30.25, 35.2...</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['ID_6407b752d.dcm', 'ID_bff0001cf.dcm', 'ID_1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>ID_00859e11</td>\n",
       "      <td>ID_01f49be39f</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.452, 3.713, 8.877, 14.042, 19.206, 24.371,...</td>\n",
       "      <td>[5.16, 5.16, 5.16, 5.16, 5.16, 5.16, 5.17, 5.1...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['ID_db255faea.dcm', 'ID_68ba9321f.dcm', 'ID_d...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>ID_00a3b735</td>\n",
       "      <td>ID_065682422f</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[69.9000244, 74.9000244, 79.9000244, 84.900024...</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "95d276ee1c956192",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "cd63c1d38007ac61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.553209Z",
     "start_time": "2025-02-18T14:59:24.536113Z"
    }
   },
   "source": [
    "\n",
    "def split_dataset(patient_scan_labels, test_size=TEST_SIZE, val_size=VALID_SIZE, random_state=42):\n",
    "    # Extract the labels from the DataFrame\n",
    "    labels = patient_scan_labels['patient_label']\n",
    "    if test_size > 0:\n",
    "        # First, split off the test set\n",
    "        train_val_labels, test_labels = train_test_split(\n",
    "            patient_scan_labels,\n",
    "            test_size=test_size,\n",
    "            stratify=labels,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        # Calculate the validation size relative to the train_val set\n",
    "        val_size_adjusted = val_size / (1 - test_size)\n",
    "\n",
    "        # Split the train_val set into train and validation sets\n",
    "        train_labels, val_labels = train_test_split(\n",
    "            train_val_labels,\n",
    "            test_size=val_size_adjusted,\n",
    "            stratify=train_val_labels['patient_label'],\n",
    "            random_state=random_state\n",
    "        )\n",
    "    else:\n",
    "        train_labels, val_labels = train_test_split(\n",
    "            patient_scan_labels,\n",
    "            test_size=val_size,\n",
    "            stratify=labels,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        test_labels = None\n",
    "\n",
    "    return train_labels, val_labels, test_labels\n",
    "\n",
    "def split_dataset_for_multilabel(patient_scan_labels, test_size=0.15, val_size=VALID_SIZE, random_state=42):\n",
    "    # Extract the labels from the DataFrame\n",
    "    labels = patient_scan_labels[['patient_any', 'patient_epidural', 'patient_intraparenchymal',\n",
    "                                  'patient_intraventricular', 'patient_subarachnoid', 'patient_subdural']].values\n",
    "\n",
    "    if test_size > 0:\n",
    "        # First split: train + test\n",
    "        msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "        train_idx, test_idx = next(msss.split(patient_scan_labels, labels))\n",
    "\n",
    "        train_labels = patient_scan_labels.iloc[train_idx]\n",
    "        test_labels = patient_scan_labels.iloc[test_idx]\n",
    "\n",
    "        # Second split: train + validation\n",
    "        msss_val = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=val_size, random_state=random_state)\n",
    "        train_idx, val_idx = next(msss_val.split(train_labels, labels[train_idx]))\n",
    "\n",
    "        train_labels_final = train_labels.iloc[train_idx]\n",
    "        val_labels = train_labels.iloc[val_idx]\n",
    "\n",
    "    else:\n",
    "        # Only split into train and validation if test_size is 0\n",
    "        msss_val = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=val_size, random_state=random_state)\n",
    "        train_idx, val_idx = next(msss_val.split(patient_scan_labels, labels))\n",
    "\n",
    "        train_labels_final = patient_scan_labels.iloc[train_idx]\n",
    "        val_labels = patient_scan_labels.iloc[val_idx]\n",
    "        test_labels = None\n",
    "\n",
    "    return train_labels_final, val_labels, test_labels"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "3226128a0da50755",
   "metadata": {},
   "source": [
    "## Dataset Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "id": "8fed4ff069d88fca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.582725Z",
     "start_time": "2025-02-18T14:59:24.563523Z"
    }
   },
   "source": [
    "class DatasetAugmentor:\n",
    "    def __init__(self, height, width, levels=2, seed=None):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.levels = levels  # Dynamic number of levels\n",
    "        self.seed = seed\n",
    "        self.params = []\n",
    "\n",
    "        # Create different levels of transforms based on the number of levels specified\n",
    "        for i in range(levels):\n",
    "            factor = (i + 1) / levels\n",
    "            self.params.append(\n",
    "                self._create_transform(\n",
    "                    degrees=int(15 * factor),\n",
    "                    translate_range=(0.2 * factor, 0.2 * factor),\n",
    "                    scale_range=(1 - 0.2 * factor, 1 + 0.2 * factor),\n",
    "                    brightness_range=0.2 * factor,\n",
    "                    contrast_range=0.2 * factor,\n",
    "                    blur_sigma_range=(0.5 * factor, 1.0 * factor),\n",
    "                    apply_elastic=(i >= levels // 2),\n",
    "                    level_name=f'level_{i + 1}'\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def _sample_value(self, value_range):\n",
    "        if isinstance(value_range, tuple):\n",
    "            random.seed(self.seed)\n",
    "            return random.uniform(value_range[0], value_range[1])\n",
    "        return value_range\n",
    "\n",
    "    def _create_transform(self, degrees, translate_range, scale_range, brightness_range, contrast_range,\n",
    "                          blur_sigma_range, apply_elastic, level_name):\n",
    "        print(f\"Creating '{level_name}' transform with parameters:\")\n",
    "        sampled_values = {\n",
    "            \"degrees\": abs(self._sample_value((-degrees, degrees))),\n",
    "            \"translate\": (abs(self._sample_value(translate_range[0])), abs(self._sample_value(translate_range[1]))),\n",
    "            \"scale\": self._sample_value(scale_range),\n",
    "            \"brightness\": self._sample_value(brightness_range),\n",
    "            \"contrast\": self._sample_value(contrast_range),\n",
    "            \"blur_sigma\": self._sample_value(blur_sigma_range),\n",
    "            \"apply_elastic\": apply_elastic\n",
    "        }\n",
    "\n",
    "        print(sampled_values)\n",
    "        return sampled_values\n",
    "\n",
    "    def apply_transform(self, image, level):\n",
    "        params = self.params[level]\n",
    "        transform = self._get_transform(params, channels=image.shape[0])\n",
    "        return transform(image)\n",
    "\n",
    "    def _get_transform(self, params, channels=3):\n",
    "        transform_list = [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomAffine(degrees=params[\"degrees\"], translate=params[\"translate\"],\n",
    "                                    scale=(params[\"scale\"], params[\"scale\"])),\n",
    "            transforms.ColorJitter(brightness=params[\"brightness\"], contrast=params[\"contrast\"]),\n",
    "            transforms.GaussianBlur(kernel_size=(3, 3), sigma=params[\"blur_sigma\"]),\n",
    "            transforms.RandomApply([transforms.ElasticTransform()] if params[\"apply_elastic\"] else [], p=0.3),\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(self.height),\n",
    "            # transforms.Compose([transforms.ToImage(), transforms.ToDtype(torch.float32, scale=True)])\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "\n",
    "        return transforms.Compose(transform_list)\n",
    "\n",
    "    def _channel_shuffle(self, tensor):\n",
    "        torch.manual_seed(self.seed)\n",
    "        channels = tensor.shape[0]\n",
    "        indices = torch.randperm(channels)\n",
    "        return tensor[indices]"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "17559ec86a6d7e5d",
   "metadata": {},
   "source": [
    "## Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "id": "638bfe32475d4cf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.699205Z",
     "start_time": "2025-02-18T14:59:24.618074Z"
    }
   },
   "source": [
    "from dataset_generators.RSNA_Dataset import MedicalScanDataset"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "17ba8c33a5b0e113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.718424Z",
     "start_time": "2025-02-18T14:59:24.701456Z"
    }
   },
   "source": [
    "class TrainDatasetGenerator(MedicalScanDataset):\n",
    "    \"\"\"Dataset class for training medical scan data.\"\"\"\n",
    "    def __init__(self, data_dir, patient_scan_labels, augmentor=None):\n",
    "        super().__init__(data_dir, patient_scan_labels, augmentor)\n",
    "\n",
    "\n",
    "class TestDatasetGenerator(MedicalScanDataset):\n",
    "    \"\"\"Dataset class for testing medical scan data.\"\"\"\n",
    "    def __init__(self, data_dir, patient_scan_labels, augmentor=None):\n",
    "        super().__init__(data_dir, patient_scan_labels, augmentor)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "37a74c9cafe700df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.769848Z",
     "start_time": "2025-02-18T14:59:24.746964Z"
    }
   },
   "source": [
    "augmentor = DatasetAugmentor(HEIGHT, WIDTH, levels=2, seed=42)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 'level_1' transform with parameters:\n",
      "{'degrees': 1.9519751784103718, 'translate': (0.1, 0.1), 'scale': 1.027885359691577, 'brightness': 0.1, 'contrast': 0.1, 'blur_sigma': 0.4098566996144709, 'apply_elastic': False}\n",
      "Creating 'level_2' transform with parameters:\n",
      "{'degrees': 4.182803953736514, 'translate': (0.2, 0.2), 'scale': 1.0557707193831534, 'brightness': 0.2, 'contrast': 0.2, 'blur_sigma': 0.8197133992289418, 'apply_elastic': True}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "2329e7da154e7ba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.915798Z",
     "start_time": "2025-02-18T14:59:24.792272Z"
    }
   },
   "source": [
    "original_dataset = TrainDatasetGenerator(dicom_dir, patient_scan_labels, augmentor=None)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "ff3a0e8e7d9949c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:24.940721Z",
     "start_time": "2025-02-18T14:59:24.923430Z"
    }
   },
   "source": [
    "len(original_dataset)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "633e6442f44018f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:25.045156Z",
     "start_time": "2025-02-18T14:59:24.972898Z"
    }
   },
   "source": [
    "x, y, z, _ = original_dataset[0]\n",
    "print(x.shape, y.shape, z.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 224, 224, 1]) torch.Size([28]) torch.Size([])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "9e3831832ebcfe75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:25.072392Z",
     "start_time": "2025-02-18T14:59:25.055438Z"
    }
   },
   "source": [
    "def get_train_loader(dicom_dir, patient_scan_labels, batch_size=TRAIN_BATCH_SIZE):\n",
    "    original_dataset = TrainDatasetGenerator(dicom_dir, patient_scan_labels, augmentor=None)\n",
    "    return DataLoader(original_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True,\n",
    "                      drop_last=True)\n",
    "\n",
    "def get_test_loader(dicom_dir, patient_scan_labels, batch_size=TEST_BATCH_SIZE):\n",
    "    test_dataset = TestDatasetGenerator(dicom_dir, patient_scan_labels, augmentor=None)\n",
    "    return DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "ddc97374c2af6d64",
   "metadata": {},
   "source": [
    "# Utils\n",
    "## Augment batch for CL"
   ]
  },
  {
   "cell_type": "code",
   "id": "54c6d481ec68b7b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:25.125617Z",
     "start_time": "2025-02-18T14:59:25.100932Z"
    }
   },
   "source": [
    "# Version 2: Avg time taken: 0.05 seconds for 1 augmentation (w ResizedCrop)\n",
    "def augment_batch(batch_images):\n",
    "    if CHANNELS == 1:\n",
    "        batch_size, num_instances, channels, height, width = batch_images.shape\n",
    "    else:\n",
    "        batch_size, num_instances, height, width, channels = batch_images.shape\n",
    "\n",
    "    # Define augmentation transformations using GPU-compatible operations\n",
    "    aug_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop((height, width), scale=(0.8, 1.1)),\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4)], p=0.6),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.Compose([transforms.ToImage(), transforms.ToDtype(torch.float32, scale=True)]),\n",
    "    ])\n",
    "\n",
    "    # Apply transformations directly on the tensor without converting to PIL\n",
    "    augmented_batch = torch.empty_like(batch_images)  # Preallocate memory for augmented images\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        for j in range(num_instances):\n",
    "            if CHANNELS == 1:\n",
    "                augmented_batch[i, j] = aug_transform(batch_images[i, j])\n",
    "            else:\n",
    "                augmented_batch[i, j] = aug_transform(batch_images[i, j].permute(2, 0, 1)).permute(1, 2, 0)\n",
    "\n",
    "    return augmented_batch.cuda()  # Move the augmented batch to GPU"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "2678537611fbb8e3",
   "metadata": {},
   "source": [
    "## NTXentLoss"
   ]
  },
  {
   "cell_type": "code",
   "id": "56ebdfa34632acbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:25.167039Z",
     "start_time": "2025-02-18T14:59:25.149078Z"
    }
   },
   "source": [
    "class NTXentLoss(losses.NTXentLoss):\n",
    "    def __init__(self, temperature, **kwargs):\n",
    "        super().__init__(temperature=temperature, **kwargs)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, embeddings, labels=None, hard_pairs=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "        if labels == None:\n",
    "            # Self-supervised labels\n",
    "            batch_size = feature_vectors_normalized.size(0) // 2  # Assuming equal size for both embeddings\n",
    "            labels = torch.cat([torch.arange(batch_size), torch.arange(batch_size)], dim=0)\n",
    "\n",
    "        # Compute logits\n",
    "        logits = torch.div(\n",
    "            torch.matmul(\n",
    "                feature_vectors_normalized, torch.transpose(feature_vectors_normalized, 0, 1)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "\n",
    "        if labels == None:\n",
    "            return losses.NTXentLoss(temperature=self.temperature)(logits, torch.squeeze(labels))\n",
    "        if hard_pairs == None:\n",
    "            return losses.SupConLoss(temperature=self.temperature)(logits, torch.squeeze(labels))\n",
    "        return losses.SupConLoss(temperature=self.temperature)(logits, torch.squeeze(labels), hard_pairs)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "ed3bff18aa94ccf5",
   "metadata": {},
   "source": [
    "# Training and Validation\n",
    "## Metrics Calculation\n",
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "id": "e37f682a8aaac35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:25.215780Z",
     "start_time": "2025-02-18T14:59:25.194012Z"
    }
   },
   "source": [
    "def calculate_metrics(predictions, labels, average='weighted'):\n",
    "    if NUM_CLASSES == 1:\n",
    "        return {\n",
    "            \"accuracy\": accuracy_score(labels, predictions),\n",
    "            \"precision\": precision_score(labels, predictions, average=average),\n",
    "            \"recall\": recall_score(labels, predictions, average=average),\n",
    "            \"f1\": f1_score(labels, predictions, average=average),\n",
    "            \"auc\": roc_auc_score(labels, predictions, average='weighted'),\n",
    "            \"cohen_kappa\": cohen_kappa_score(labels, predictions)\n",
    "        }\n",
    "    else:\n",
    "\n",
    "        return {\n",
    "            \"accuracy\": accuracy_score(labels, predictions),\n",
    "            \"precision\": precision_score(labels, predictions, average='samples'),\n",
    "            \"recall\": recall_score(labels, predictions, average='samples'),\n",
    "            \"f1\": f1_score(labels, predictions, average='samples'),\n",
    "            \"auc\": roc_auc_score(labels, predictions, average='samples'),\n",
    "            \"cohen_kappa\": cohen_kappa_score(labels, predictions)\n",
    "        }\n",
    "\n",
    "def print_epoch_stats(epoch, num_epochs, phase, loss, metrics):\n",
    "    \"\"\"Print statistics for an epoch.\"\"\"\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - {phase.capitalize()}:\")\n",
    "    print(f\"Loss: {loss:.4f}, Accuracy: {metrics['accuracy']:.4f}, \"\n",
    "          f\"Precision: {metrics['precision']:.4f}, Recall: {metrics['recall']:.4f}, \"\n",
    "          f\"F1: {metrics['f1']:.4f}, AUC: {metrics['auc']:.4f}\")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "7332fde37dac6987",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aaf3081e1ffe2c",
   "metadata": {},
   "source": [
    "### Training Phase 1: CNN + ATT"
   ]
  },
  {
   "cell_type": "code",
   "id": "bf02a694b73c3669",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:25.263962Z",
     "start_time": "2025-02-18T14:59:25.239528Z"
    }
   },
   "source": [
    "def train_phase_1(model, data_loader, criterion_cl, criterion_bce, optimizer, scheduler, device):\n",
    "    total_loss = 0.0\n",
    "    alpha = 0.5\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "        batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_labels = batch_patient_labels if NUM_CLASSES == 1 else batch_multi_labels\n",
    "\n",
    "        if CONTRASTIVE_LEARNING:\n",
    "            aug_data_1 = augment_batch(batch_data)\n",
    "            aug_data_2 = augment_batch(batch_data)\n",
    "            batch_data = torch.cat([aug_data_1, aug_data_2], dim=0)\n",
    "            train_labels = torch.cat([train_labels, train_labels], dim=0)\n",
    "\n",
    "            outputs, cnn_features, attention_weights = model(batch_data)\n",
    "            miner_func = hnm.ExamplePairMiner()\n",
    "            hard_pairs = miner_func(outputs, train_labels)\n",
    "            loss = criterion_cl(outputs, labels=train_labels, hard_pairs=hard_pairs) * alpha + \\\n",
    "                     criterion_bce(outputs, train_labels) * (1 - alpha)\n",
    "            loss = loss.mean()\n",
    "            preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "        else:\n",
    "            outputs, cnn_features, attention_weights = model(batch_data)\n",
    "            loss = criterion_bce(outputs, train_labels)\n",
    "            loss = loss.mean()\n",
    "            preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "        predictions.extend(preds.cpu().detach().numpy())\n",
    "        labels.extend(train_labels.cpu().numpy())\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    return total_loss / len(data_loader), predictions, labels\n",
    "\n",
    "def validate_phase_1(model, data_loader, criterion_cl, criterion_bce, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    alpha = 0.5\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with (torch.inference_mode()):\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            val_labels = batch_patient_labels if NUM_CLASSES == 1 else batch_multi_labels\n",
    "\n",
    "            if CONTRASTIVE_LEARNING:\n",
    "                outputs, cnn_features, attention_weights = model(batch_data)\n",
    "                miner_func = hnm.ExamplePairMiner()\n",
    "                hard_pairs = miner_func(outputs, val_labels)\n",
    "                loss = criterion_cl(outputs, labels=val_labels, hard_pairs=hard_pairs) * alpha + \\\n",
    "                         criterion_bce(outputs, val_labels) * (1 - alpha)\n",
    "                loss = loss.mean()\n",
    "                preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "            else:\n",
    "                outputs, cnn_features, attention_weights = model(batch_data)\n",
    "                loss = criterion_bce(outputs, val_labels)\n",
    "                loss = loss.mean()\n",
    "                preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "            predictions.extend(preds.cpu().detach().numpy())\n",
    "            labels.extend(val_labels.cpu().numpy())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader), predictions, labels\n",
    "\n",
    "def evaluate_phase_1(model, data_loader, criterion_cl, criterion_bce, device):\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    labels = []\n",
    "\n",
    "    with (torch.inference_mode()):\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            eval_labels = batch_patient_labels if NUM_CLASSES == 1 else batch_multi_labels\n",
    "\n",
    "            if CONTRASTIVE_LEARNING:\n",
    "                outputs, cnn_features, attention_weights = model(batch_data)\n",
    "                loss = criterion_cl(outputs, labels=eval_labels) * 0.5 + criterion_bce(outputs, eval_labels) * 0.5\n",
    "                loss = loss.mean()\n",
    "                preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "            else:\n",
    "                outputs, cnn_features, attention_weights = model(batch_data)\n",
    "                loss = criterion_bce(outputs, eval_labels)\n",
    "                loss = loss.mean()\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                preds = (probs >= THRESHOLD).int()\n",
    "\n",
    "            probabilities.extend(probs.cpu().detach().numpy())\n",
    "            predictions.extend(preds.cpu().detach().numpy())\n",
    "            labels.extend(eval_labels.cpu().numpy())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return predictions, labels, probabilities\n",
    "\n",
    "def train_model_phase_1(model, train_loader, val_loader, criterion_cl, criterion_bce, optimizer, num_epochs, device):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_auc = 0.0\n",
    "    best_metrics = None\n",
    "    model.to(device)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE, steps_per_epoch=len(train_loader), epochs=num_epochs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                loss, predictions, labels = train_phase_1(model, train_loader, criterion_cl, criterion_bce,\n",
    "                                                           optimizer, scheduler, device)\n",
    "            else:\n",
    "                model.eval()\n",
    "                loss, predictions, labels = validate_phase_1(model, val_loader, criterion_cl, criterion_bce, device)\n",
    "\n",
    "            metrics = calculate_metrics(predictions, labels, average='binary')\n",
    "            print_epoch_stats(epoch, num_epochs, phase, loss, metrics)\n",
    "\n",
    "            if phase == 'val' and best_auc < metrics['auc']:\n",
    "                best_auc = metrics['auc']\n",
    "                best_metrics = metrics\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "    print(f'Best AUC: {best_auc}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_metrics"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "f5f08020017b303c",
   "metadata": {},
   "source": [
    "### Training Phase 2: GP"
   ]
  },
  {
   "cell_type": "code",
   "id": "39dedb999d546a18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:25.326304Z",
     "start_time": "2025-02-18T14:59:25.301200Z"
    }
   },
   "source": [
    "def train_epoch(model, likelihoods, data_loader, criterion_cl, criterion_bce, mlls, optimizer,\n",
    "                variational_ngd_optimizer, scheduler, device):\n",
    "    total_loss = 0.0\n",
    "    alpha = 0.5\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    model.train()\n",
    "    likelihoods.train()\n",
    "\n",
    "    for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "        batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if GP_MODEL == 'single_task':\n",
    "            if NUM_CLASSES != 1:\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    variational_ngd_optimizer[i].zero_grad()\n",
    "            else:\n",
    "                variational_ngd_optimizer.zero_grad()\n",
    "\n",
    "        if TRAINING_TYPE == 'end_to_end':\n",
    "            if CONTRASTIVE_LEARNING:\n",
    "                aug_data_1 = augment_batch(batch_data)\n",
    "                aug_data_2 = augment_batch(batch_data)\n",
    "                batch_data = torch.cat([aug_data_1, aug_data_2], dim=0)\n",
    "                batch_labels = torch.cat([batch_labels, batch_labels], dim=0)\n",
    "                batch_multi_labels = torch.cat([batch_multi_labels, batch_multi_labels], dim=0)\n",
    "                batch_patient_labels = torch.cat([batch_patient_labels, batch_patient_labels], dim=0)\n",
    "\n",
    "            outputs, gp_outputs, att_outputs = model(batch_data)\n",
    "\n",
    "            if GP_MODEL == 'single_task' and NUM_CLASSES != 1:\n",
    "                loss = 0\n",
    "                gp_loss = 0\n",
    "                ntx_loss = 0\n",
    "\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    gp_loss += -mlls[i](gp_outputs[i], batch_multi_labels[:, i])\n",
    "\n",
    "                if CONTRASTIVE_LEARNING:\n",
    "                    miner_func = hnm.ExamplePairMiner()\n",
    "                    hard_pairs = miner_func(outputs, batch_multi_labels)\n",
    "                    ntx_loss = criterion_cl(outputs, labels=batch_multi_labels, hard_pairs=hard_pairs)\n",
    "                    loss = 0.3 * criterion_bce(outputs, batch_multi_labels) + 0.3 * gp_loss + ntx_loss * 0.4\n",
    "                else:\n",
    "                    loss = 0.5 * criterion_bce(outputs, batch_multi_labels) + 0.5 * gp_loss\n",
    "\n",
    "                loss = loss.mean()\n",
    "\n",
    "                # probs = [likelihoods[i](gp_outputs[i]).probs for i in range(NUM_CLASSES)]\n",
    "                probs = [torch.sigmoid(outputs[:, i]) for i in range(NUM_CLASSES)]\n",
    "                probabilities = torch.stack(probs, dim=1)\n",
    "                preds = (probabilities >= THRESHOLD).int()\n",
    "\n",
    "            elif GP_MODEL == 'single_task' and NUM_CLASSES == 1:\n",
    "                if CONTRASTIVE_LEARNING:\n",
    "                    miner_func = hnm.ExamplePairMiner()\n",
    "                    hard_pairs = miner_func(outputs, batch_patient_labels)\n",
    "                    ntx_loss = criterion_cl(outputs, labels=batch_patient_labels, hard_pairs=hard_pairs)\n",
    "                    # loss = 0.3 * criterion_bce(outputs.squeeze(-1), batch_patient_labels) + 0.3 * mlls(gp_outputs, batch_patient_labels) + ntx_loss * 0.4\n",
    "                    loss = ntx_loss * 0.5 + 0.5 * criterion_bce(outputs.squeeze(-1), batch_patient_labels)\n",
    "                    loss = loss.mean()\n",
    "                    loss += -mlls(gp_outputs, batch_patient_labels) * 0.5\n",
    "                else:\n",
    "                    # loss = -mlls(gp_outputs, batch_patient_labels) * 0.5 + 0.5 * criterion_bce(outputs.squeeze(-1), batch_patient_labels)\n",
    "                    loss = -mlls(gp_outputs, batch_patient_labels)\n",
    "\n",
    "                loss = loss.mean()\n",
    "                preds = likelihoods(gp_outputs).probs >= THRESHOLD\n",
    "                # preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "            predictions.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            if GP_MODEL == 'single_task':\n",
    "                if NUM_CLASSES != 1:\n",
    "                    for i in range(NUM_CLASSES):\n",
    "                        variational_ngd_optimizer[i].step()\n",
    "                else:\n",
    "                    variational_ngd_optimizer.step()\n",
    "\n",
    "        if NUM_CLASSES == 1:\n",
    "            labels.extend(batch_patient_labels.cpu().numpy())\n",
    "        else:\n",
    "            labels.extend(batch_multi_labels.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(data_loader), predictions, labels\n",
    "\n",
    "\n",
    "def validate(model, likelihoods, data_loader, criterion_cl, criterion_bce, mlls, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    likelihoods.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    alpha = 0.5\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with (torch.inference_mode()):\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                outputs, gp_outputs, att_outputs = model(batch_data)\n",
    "                if GP_MODEL == 'single_task':\n",
    "                    loss = 0\n",
    "                    if NUM_CLASSES != 1:\n",
    "                        for i in range(NUM_CLASSES):\n",
    "                            loss += -mlls[i](gp_outputs[i], batch_multi_labels[:, i])\n",
    "\n",
    "                        loss.mean()\n",
    "                        loss += 0.5 * criterion_bce(outputs, batch_multi_labels)\n",
    "                        total_loss += loss.item()\n",
    "\n",
    "                        probabilities = torch.stack([likelihoods[i](gp_outputs[i]).probs for i in range(NUM_CLASSES)],\n",
    "                                                    dim=1)\n",
    "                        preds = (probabilities >= THRESHOLD).int()\n",
    "                    else:\n",
    "                        loss = -mlls(gp_outputs, batch_patient_labels) * 0.5 + 0.5 * criterion_bce(outputs.squeeze(-1),\n",
    "                                                                                                   batch_patient_labels)\n",
    "                        # loss = -mlls(gp_outputs, batch_patient_labels)\n",
    "                        loss = loss.mean()\n",
    "                        total_loss += loss.item()\n",
    "                        preds = likelihoods(gp_outputs).probs >= THRESHOLD\n",
    "                        # preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "                predictions.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "            if NUM_CLASSES == 1:\n",
    "                labels.extend(batch_patient_labels.cpu().numpy())\n",
    "            else:\n",
    "                labels.extend(batch_multi_labels.cpu().numpy())\n",
    "    return total_loss / len(data_loader), predictions, labels\n",
    "\n",
    "\n",
    "def train_model(model, likelihoods, train_loader, val_loader, criterion_cl, criterion_bce, optimizer, num_epochs,\n",
    "                learning_rate, device='cuda'):\n",
    "    \"\"\"Train the model and return the best model based on validation accuracy.\"\"\"\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    likelihoods.train()\n",
    "\n",
    "    # Initialize Early Stopping\n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "\n",
    "    if GP_MODEL == 'single_task':\n",
    "        if NUM_CLASSES != 1:\n",
    "            mlls = [\n",
    "                gpytorch.mlls.VariationalELBO(likelihoods[i], model.gp_layers[i], num_data=len(train_loader.dataset))\n",
    "                for\n",
    "                i in range(NUM_CLASSES)]\n",
    "            mlls = [mll.to(device) for mll in mlls]\n",
    "\n",
    "            variational_ngd_optimizer = [\n",
    "                gpytorch.optim.NGD(model.gp_layers[i].variational_parameters(), num_data=len(train_loader.dataset),\n",
    "                                   lr=LEARNING_RATE_NGD) for i in range(NUM_CLASSES)]\n",
    "        else:\n",
    "            mlls = gpytorch.mlls.VariationalELBO(likelihoods, model.gp_layers, num_data=len(train_loader.dataset))\n",
    "            mlls = mlls.to(device)\n",
    "            variational_ngd_optimizer = gpytorch.optim.NGD(model.gp_layers.variational_parameters(),\n",
    "                                                           num_data=len(train_loader.dataset),\n",
    "                                                           lr=LEARNING_RATE_NGD)\n",
    "\n",
    "    # scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=len(train_loader), epochs=num_epochs)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-5)\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "    best_likelihood_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_predictions, train_labels = train_epoch(model, likelihoods, train_loader, criterion_cl,\n",
    "                                                                  criterion_bce,\n",
    "                                                                  mlls, optimizer, variational_ngd_optimizer,\n",
    "                                                                  scheduler, device)\n",
    "        train_metrics = calculate_metrics(train_predictions, train_labels)\n",
    "        print_epoch_stats(epoch, num_epochs, \"train\", train_loss, train_metrics)\n",
    "\n",
    "        wandb.log({\n",
    "            \"train/loss\": train_loss,\n",
    "            \"train/accuracy\": train_metrics[\"accuracy\"],\n",
    "            \"train/precision\": train_metrics[\"precision\"],\n",
    "            \"train/recall\": train_metrics[\"recall\"],\n",
    "            \"train/f1\": train_metrics[\"f1\"],\n",
    "            \"train/auc\": train_metrics[\"auc\"],\n",
    "            \"train/cohen_kappa\": train_metrics[\"cohen_kappa\"]\n",
    "        })\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, val_predictions, val_labels = validate(model, likelihoods, val_loader, criterion_cl, criterion_bce,\n",
    "                                                         mlls,\n",
    "                                                         device)\n",
    "        val_metrics = calculate_metrics(val_predictions, val_labels)\n",
    "        print_epoch_stats(epoch, num_epochs, \"validation\", val_loss, val_metrics)\n",
    "\n",
    "        wandb.log({\n",
    "            \"val/loss\": val_loss,\n",
    "            \"val/accuracy\": val_metrics[\"accuracy\"],\n",
    "            \"val/precision\": val_metrics[\"precision\"],\n",
    "            \"val/recall\": val_metrics[\"recall\"],\n",
    "            \"val/f1\": val_metrics[\"f1\"],\n",
    "            \"val/auc\": val_metrics[\"auc\"],\n",
    "            \"val/cohen_kappa\": val_metrics[\"cohen_kappa\"]\n",
    "        })\n",
    "\n",
    "        # Early Stopping Check\n",
    "        early_stopping(val_metrics[\"auc\"], model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        # Save best model\n",
    "        if val_metrics['auc'] > best_val_accuracy:\n",
    "            best_val_accuracy = val_metrics['auc']\n",
    "            best_model_state = model.state_dict()\n",
    "            best_likelihood_state = likelihoods.state_dict()\n",
    "\n",
    "    # Load best model\n",
    "    if best_model_state and best_likelihood_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        likelihoods.load_state_dict(best_likelihood_state)\n",
    "    # Optionally log the best model to W&B (if desired)\n",
    "    print(f'Best Validation AUC: {best_val_accuracy}')\n",
    "    wandb.log_artifact(wandb.Artifact(\"best_model\", type=\"model\", metadata={\"accuracy\": best_val_accuracy}))\n",
    "\n",
    "    return model, likelihoods"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "69eb82ef6c7a8f86",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "id": "967f6eb1fe5ef54f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:25.367665Z",
     "start_time": "2025-02-18T14:59:25.344219Z"
    }
   },
   "source": [
    "## Model Evaluation Functions\n",
    "def evaluate_model(model, likelihoods, data_loader, device='cuda'):\n",
    "    \"\"\"Evaluate the model on the given data loader.\"\"\"\n",
    "    model = model.to(device)\n",
    "    likelihoods = likelihoods.to(device)\n",
    "    model.eval()\n",
    "    likelihoods.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in data_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                outputs, gp_outputs, att_outputs = model(batch_data)\n",
    "                if GP_MODEL == 'single_task':\n",
    "                    if NUM_CLASSES > 1:\n",
    "                        probabilities = torch.stack([likelihoods[i](gp_outputs[i]).probs for i in range(NUM_CLASSES)],\n",
    "                                                    dim=1)\n",
    "                    else:\n",
    "                        probabilities = likelihoods(gp_outputs).probs\n",
    "                    preds = (probabilities >= THRESHOLD).int()\n",
    "                    # preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "                predictions.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "            if NUM_CLASSES == 1:\n",
    "                labels.extend(batch_patient_labels.cpu().numpy())\n",
    "            else:\n",
    "                labels.extend(batch_multi_labels.cpu().numpy())\n",
    "\n",
    "            probs.extend(probabilities.cpu().detach().numpy())\n",
    "\n",
    "    return np.array(predictions), np.array(labels), np.array(probs)\n",
    "\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    \"\"\"Print the calculated metrics.\"\"\"\n",
    "    print(f\"Test Accuracy: {metrics['accuracy']:.4f}, \"\n",
    "          f\"Precision: {metrics['precision']:.4f}, \"\n",
    "          f\"Recall: {metrics['recall']:.4f}, \"\n",
    "          f\"F1: {metrics['f1']:.4f}\",\n",
    "          f\"AUC: {metrics['auc']:.4f}\",\n",
    "          f\"Cohen Kappa: {metrics['cohen_kappa']:.4f}\")"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "387310f64ec783c7",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "id": "688ee14ca4c63b43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:25.420175Z",
     "start_time": "2025-02-18T14:59:25.393508Z"
    }
   },
   "source": [
    "## Visualization Functions\n",
    "def plot_roc_curve(model, likelihoods, data_loader, device):\n",
    "    \"\"\"Plot the ROC curve for the model predictions.\"\"\"\n",
    "    model.eval()\n",
    "    if likelihoods:\n",
    "        likelihoods.eval()\n",
    "    labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in data_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                outputs, gp_outputs, _ = model(batch_data)\n",
    "                if GP_MODEL == 'single_task':\n",
    "                    if NUM_CLASSES > 1:\n",
    "                        probabilities = torch.stack([likelihoods[i](gp_outputs[i]).probs for i in range(NUM_CLASSES)],\n",
    "                                                    dim=1)\n",
    "                    else:\n",
    "                        probabilities = likelihoods(gp_outputs).probs\n",
    "                    preds = probabilities\n",
    "\n",
    "                else:\n",
    "                    preds = torch.sigmoid(outputs)\n",
    "                predictions.extend(preds.cpu().detach().numpy())\n",
    "            else:\n",
    "                outputs, cnn_features, attention_weights = model(batch_data)\n",
    "                preds = torch.sigmoid(outputs)\n",
    "                predictions.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "            if NUM_CLASSES == 1:  # Binary classification\n",
    "                labels.extend(batch_patient_labels.cpu().numpy())\n",
    "            else:\n",
    "                labels.extend(batch_multi_labels.cpu().numpy())\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    if NUM_CLASSES == 1:\n",
    "        fpr, tpr, _ = roc_curve(labels, predictions)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    else:\n",
    "        class_name = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "        for i in range(NUM_CLASSES):\n",
    "            fpr, tpr, _ = roc_curve(labels[:, i], predictions[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, lw=2,\n",
    "                     label=f'Class {class_name[i]} (AUC = {roc_auc:.4f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(model, likelihoods, data_loader, criterion_cl, criterion_bce, device):\n",
    "    \"\"\"Plot confusion matrix for classification tasks.\"\"\"\n",
    "    if likelihoods:\n",
    "        predictions, labels, _ = evaluate_model(model, likelihoods, data_loader, device)\n",
    "    else:\n",
    "        predictions, labels, _ = evaluate_phase_1(model, data_loader, criterion_cl, criterion_bce, device)\n",
    "    if NUM_CLASSES > 1:  # Multi-label/multi-class\n",
    "        cm = multilabel_confusion_matrix(labels, predictions)\n",
    "        _, ax = plt.subplots(1, NUM_CLASSES, figsize=(15, 3))\n",
    "        for i in range(NUM_CLASSES):\n",
    "            ConfusionMatrixDisplay(cm[i]).plot(ax=ax[i])\n",
    "            ax[i].set_title(f'Class {i}')\n",
    "    else:  # Binary\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        ConfusionMatrixDisplay(cm).plot()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "eb67abfc34676ddc",
   "metadata": {},
   "source": [
    "# Model Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "d3ea64ecd34312a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:25.470193Z",
     "start_time": "2025-02-18T14:59:25.446114Z"
    }
   },
   "source": [
    "## Data Processing Functions\n",
    "def load_model(model_class, model_path, params):\n",
    "    \"\"\"Load a trained model from a file.\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "\n",
    "    model = model_class(params)\n",
    "    try:\n",
    "        state_dict = torch.load(model_path, map_location=torch.device('cuda'), weights_only=True)\n",
    "        if not state_dict:\n",
    "            raise ValueError(f\"The state dictionary loaded from {model_path} is empty\")\n",
    "        model.load_state_dict(state_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model from {model_path}: {str(e)}\")\n",
    "        print(\"Initializing model with random weights instead.\")\n",
    "        return model  # Return the model with random initialization\n",
    "\n",
    "    return model.eval()\n",
    "\n",
    "\n",
    "def get_test_results(model, test_loader, test_labels, device=DEVICE):\n",
    "    \"\"\"Get test results including patient information.\"\"\"\n",
    "    predictions, _ = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    results = []\n",
    "    for i, row in enumerate(test_labels.itertuples(index=False)):\n",
    "        result = {col: getattr(row, col) for col in test_labels.columns}\n",
    "        result['prediction'] = predictions[i]\n",
    "        results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract Trained Features from the Model",
   "id": "17ee691aa362b802"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:25.512569Z",
     "start_time": "2025-02-18T14:59:25.493527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_features_for_df(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_instance_labels = []\n",
    "    all_bag_labels = []\n",
    "    all_bag_multi_labels = []\n",
    "    all_bag_ids = []\n",
    "    all_instance_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (bags, instance_labels, bag_labels, bag_multi_labels) in enumerate(data_loader):\n",
    "            bags = bags.to(device)\n",
    "            instance_labels = instance_labels.to(device)\n",
    "            bag_labels = bag_labels.to(device)\n",
    "            bag_multi_labels = bag_multi_labels.to(device)\n",
    "\n",
    "            _, cnn_features, _ = model(bags)\n",
    "\n",
    "            batch_size, num_instances, num_features = cnn_features.shape\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                bag_features = cnn_features[i].cpu().numpy()\n",
    "                bag_instance_labels = instance_labels[i].cpu().numpy()\n",
    "                bag_label = bag_labels[i].cpu().numpy()\n",
    "                bag_multi_label = bag_multi_labels[i].cpu().numpy()\n",
    "\n",
    "                all_features.append(bag_features)\n",
    "                all_instance_labels.append(bag_instance_labels)\n",
    "                all_bag_labels.append(np.repeat(bag_label, num_instances))\n",
    "                all_bag_multi_labels.append(np.tile(bag_multi_label, (num_instances, 1)))\n",
    "                all_bag_ids.append(np.repeat(batch_idx * batch_size + i, num_instances))\n",
    "                all_instance_ids.append(np.arange(num_instances))\n",
    "\n",
    "    return (np.concatenate(all_features),\n",
    "            np.concatenate(all_instance_labels),\n",
    "            np.concatenate(all_bag_labels),\n",
    "            np.concatenate(all_bag_multi_labels),\n",
    "            np.concatenate(all_bag_ids),\n",
    "            np.concatenate(all_instance_ids))\n",
    "\n",
    "def create_and_save_feature_df(data, num_classes, filename):\n",
    "    features, instance_labels, bag_labels, bag_multi_labels, bag_ids, instance_ids = data\n",
    "\n",
    "    # Create column names for features\n",
    "    feature_columns = [f'feature_{i}' for i in range(features.shape[1])]\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(features, columns=feature_columns)\n",
    "    df['instance_label'] = instance_labels\n",
    "    df['patient_label'] = bag_labels\n",
    "\n",
    "    # Add multi-label columns\n",
    "    for i in range(num_classes):\n",
    "        df[f'class_{i}'] = bag_multi_labels[:, i]\n",
    "\n",
    "    df['bag_id'] = bag_ids\n",
    "    df['instance_id'] = instance_ids\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved features to {filename}\")\n",
    "\n",
    "    return df"
   ],
   "id": "349f2e095a06ef68",
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "782c51e99ffa72cd",
   "metadata": {},
   "source": [
    "## Model Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "id": "bc6077893e01344c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:25.559989Z",
     "start_time": "2025-02-18T14:59:25.543141Z"
    }
   },
   "source": [
    "# If you need to use the Glorot (Xavier) uniform initialization\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "aa03f3cfc19f4215",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "id": "8b4d4931b72a2e3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:25.615660Z",
     "start_time": "2025-02-18T14:59:25.587028Z"
    }
   },
   "source": [
    "def main(mode='train', use_cv=False, num_folds=5):\n",
    "    # os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "    current_time = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    run_name = f\"{TRAINING_TYPE}_experiment_{current_time}_{GP_MODEL}_refiner_fc_{PROJECTION_HIDDEN_DIM}_output_{PROJECTION_OUTPUT_DIM}_attention_{ATTENTION_HIDDEN_DIM}_kernel_{GP_KERNEL}_model_{MODEL_TYPE}\"\n",
    "\n",
    "    # Initialize W&B with a specific run name\n",
    "    wandb.init(project=\"MIL_Resnet_ICH\", name=run_name)\n",
    "\n",
    "    # Log hyperparameters\n",
    "    config = wandb.config\n",
    "    config.learning_rate = LEARNING_RATE\n",
    "    config.batch_size = TRAIN_BATCH_SIZE\n",
    "    config.num_epochs = NUM_EPOCHS\n",
    "\n",
    "    params = {\n",
    "        'channels': CHANNELS,  # Number of input channels (e.g., 1 for grayscale, 3 for RGB)\n",
    "        'num_classes': NUM_CLASSES,  # Number of output classes for classification\n",
    "        'drop_prob': 0.5,  # Dropout probability\n",
    "        'inducing_points': INDUCING_POINTS,  # Number of inducing points for the Gaussian Process layer\n",
    "        'projection_location': PROJECTION_LOCATION,  # Choose from 'after_resnet', 'after_attention', or 'after_gp'\n",
    "        'projection_hidden_dim': PROJECTION_HIDDEN_DIM,  # Hidden dimension size for the projection head\n",
    "        'projection_output_dim': PROJECTION_OUTPUT_DIM,  # Output dimension size for the projection head\n",
    "        'attention_hidden_dim': ATTENTION_HIDDEN_DIM,  # Hidden dimension size for the attention head\n",
    "        'gp_model': GP_MODEL,\n",
    "        'kernel_type': GP_KERNEL,\n",
    "        'model_type': MODEL_TYPE,\n",
    "        'contrastive_learning': CONTRASTIVE_LEARNING\n",
    "    }\n",
    "\n",
    "    if use_cv == False:\n",
    "        if NUM_CLASSES == 1:\n",
    "            train_labels, val_labels, test_labels = split_dataset(patient_scan_labels, test_size=0.0)\n",
    "        else:\n",
    "            train_labels, val_labels, test_labels = split_dataset_for_multilabel(patient_scan_labels, test_size=0.0)\n",
    "            \n",
    "        test_dir = './data_analyze/testing_dataset_150_redundancy.csv' if DATA_REDUNDANCY else \\\n",
    "                    './data_analyze/testing_dataset_150.csv'\n",
    "        test_labels = pd.read_csv(test_dir)\n",
    "\n",
    "        train_loader = get_train_loader(dicom_dir, train_labels, batch_size=TRAIN_BATCH_SIZE)\n",
    "        val_loader = get_train_loader(dicom_dir, val_labels, batch_size=VALID_BATCH_SIZE)\n",
    "        test_loader = get_test_loader(dicom_dir, test_labels, batch_size=TEST_BATCH_SIZE)\n",
    "\n",
    "        if TRAINING_TYPE == 'end_to_end':\n",
    "            if GP_MODEL == 'single_task':\n",
    "                model = MILModels.CNN_ATT_GP_Multilabel(params)\n",
    "\n",
    "                if NUM_CLASSES != 1:\n",
    "                    likelihood = nn.ModuleList([PGLikelihood() for _ in range(NUM_CLASSES)])\n",
    "                else:\n",
    "                    likelihood = PGLikelihood()\n",
    "                    # likelihood = gpytorch.likelihoods.BernoulliLikelihood()\n",
    "                optimizer = optim.Adam([\n",
    "                    {'params': model.parameters(), 'lr': config.learning_rate},\n",
    "                    {'params': likelihood.parameters(), 'lr': config.learning_rate}\n",
    "                ])\n",
    "        elif TRAINING_TYPE == 'cnn_att':\n",
    "            model = MILModels.CNN_Attention(params)\n",
    "            likelihood = None\n",
    "            optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "        criterion_cl = NTXentLoss(0.5)\n",
    "        if NUM_CLASSES == 1:\n",
    "            pos_weights = torch.tensor([40.0]).to(DEVICE)\n",
    "        else:\n",
    "            pos_weights = torch.tensor([5.0] * NUM_CLASSES).to(DEVICE)\n",
    "        criterion_bce = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "\n",
    "        if mode == 'train':\n",
    "            wandb.watch(model)  # Watch the model to log gradients and parameters\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                # model.apply(init_weights)\n",
    "                trained_model, likelihood = train_model(model, likelihood, train_loader, val_loader, criterion_cl,\n",
    "                                                        criterion_bce, optimizer, config.num_epochs, config.learning_rate, DEVICE)\n",
    "                predictions, labels, _ = evaluate_model(trained_model, likelihood, test_loader, DEVICE)\n",
    "            else:\n",
    "                print(\"Training Phase 1: CNN + ATT\")\n",
    "                trained_model, _ = train_model_phase_1(model, train_loader, val_loader, criterion_cl, criterion_bce,\n",
    "                                                        optimizer, config.num_epochs, DEVICE)\n",
    "                predictions, labels, _ = evaluate_phase_1(trained_model, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "\n",
    "            metrics = calculate_metrics(predictions, labels, average='binary')\n",
    "            wandb.log(metrics)\n",
    "            print_metrics(metrics)\n",
    "\n",
    "            plot_roc_curve(trained_model, likelihood, test_loader, DEVICE)\n",
    "            plot_confusion_matrix(trained_model, likelihood, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "            torch.save(trained_model.state_dict(), MODEL_PATH)\n",
    "            if likelihood:\n",
    "                torch.save(likelihood.state_dict(), LIKELIHOOD_PATH)\n",
    "        else:\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                if GP_MODEL == 'single_task':\n",
    "                    trained_model = load_model(MILModels.CNN_ATT_GP_Multilabel, MODEL_PATH, params)\n",
    "                    predictions, labels, probs = evaluate_model(trained_model, likelihood, test_loader, DEVICE)\n",
    "            else:\n",
    "                trained_model = load_model(MILModels.CNN_Attention, MODEL_PATH, params)\n",
    "                predictions, labels, probs = evaluate_phase_1(trained_model, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "\n",
    "            metrics = calculate_metrics(predictions, labels)\n",
    "            wandb.log(metrics)\n",
    "            print_metrics(metrics)\n",
    "\n",
    "            plot_roc_curve(trained_model, likelihood, test_loader, DEVICE)\n",
    "            plot_confusion_matrix(trained_model, likelihood, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "\n",
    "            print(\"\\nProbabilities for each row in the test set:\")\n",
    "            for i, prob in enumerate(probs):\n",
    "                if NUM_CLASSES == 1:\n",
    "                    is_correct = predictions[i] == labels[i]\n",
    "                    print(\n",
    "                        f\"Row {i + 1}: Probs: {prob.item():.4f} | Prediction: {predictions[i]} | Label: {labels[i]} | Result: {'True' if is_correct else 'False'}\")\n",
    "                else:\n",
    "                    is_correct = np.array_equal(predictions[i], labels[i])\n",
    "                    print(\n",
    "                        f\"Row {i + 1}: Probs: {prob.tolist()} | Prediction: {predictions[i].tolist()} | Label: {labels[i].tolist()} | Result: {'True' if is_correct else 'False'}\")\n",
    "\n",
    "\n",
    "        train_data = extract_features_for_df(trained_model, train_loader, DEVICE)\n",
    "        val_data = extract_features_for_df(trained_model, val_loader, DEVICE)\n",
    "        # combined_data = [\n",
    "        #     np.concatenate([train_data[0], val_data[0]]),  # features\n",
    "        #     train_data[1] + val_data[1],  # instance_labels\n",
    "        #     train_data[2] + val_data[2],  # bag_labels\n",
    "        #     train_data[3] + val_data[3],  # bag_multi_labels\n",
    "        #     train_data[4] + val_data[4],  # bag_ids\n",
    "        #     train_data[5] + val_data[5],  # instance_ids\n",
    "        # ]\n",
    "        df = create_and_save_feature_df(train_data, num_classes=6, filename=\"train_features.csv\")\n",
    "        test_data = extract_features_for_df(trained_model, test_loader, DEVICE)\n",
    "        df = create_and_save_feature_df(test_data, num_classes=6, filename=\"test_features.csv\")\n",
    "\n",
    "        # Display first few rows of the DataFrame\n",
    "        print(df.head())\n",
    "\n",
    "    else:\n",
    "        if NUM_CLASSES == 1:\n",
    "            trainval_labels, test_labels, _ = split_dataset(\n",
    "                patient_scan_labels,\n",
    "                val_size=TEST_SIZE,\n",
    "                test_size=0.0\n",
    "            )\n",
    "            test_labels = pd.read_csv('./data_analyze/testing_dataset_150_redundancy.csv')\n",
    "        else:\n",
    "            trainval_labels, test_labels, _ = split_dataset_for_multilabel(\n",
    "                patient_scan_labels,\n",
    "                val_size=TEST_SIZE,\n",
    "                test_size=0.0\n",
    "            )\n",
    "\n",
    "        # Setup CV using trainval data\n",
    "        kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "        fold_metrics = []\n",
    "\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kf.split(trainval_labels)):\n",
    "            print(f\"\\nFold {fold_idx + 1}/{num_folds}\")\n",
    "\n",
    "            # Create fold splits\n",
    "            train_labels_fold = trainval_labels.iloc[train_idx]\n",
    "            val_labels_fold = trainval_labels.iloc[val_idx]\n",
    "\n",
    "            # Create data loaders\n",
    "            train_loader = get_train_loader(dicom_dir, train_labels_fold, TRAIN_BATCH_SIZE)\n",
    "            val_loader = get_train_loader(dicom_dir, val_labels_fold, VALID_BATCH_SIZE)\n",
    "            test_loader = get_test_loader(dicom_dir, test_labels, TEST_BATCH_SIZE)\n",
    "\n",
    "            # Initialize model\n",
    "            if GP_MODEL == 'single_task':\n",
    "                model = MILModels.CNN_ATT_GP_Multilabel(params)\n",
    "                if NUM_CLASSES != 1:\n",
    "                    likelihood = nn.ModuleList([PGLikelihood() for _ in range(NUM_CLASSES)])\n",
    "                else:\n",
    "                    likelihood = PGLikelihood()\n",
    "                optimizer = optim.Adam([\n",
    "                    {'params': model.parameters(), 'lr': config.learning_rate},\n",
    "                    {'params': likelihood.parameters(), 'lr': config.learning_rate}\n",
    "                ])\n",
    "\n",
    "\n",
    "            if NUM_CLASSES == 1:\n",
    "                pos_weights = torch.tensor([5.0]).to(DEVICE)\n",
    "            else:\n",
    "                pos_weights = torch.tensor([5.0] * NUM_CLASSES).to(DEVICE)\n",
    "            criterion_bce = nn.BCEWithLogitsLoss(pos_weight=pos_weights) # Weighted BCE Loss\n",
    "            criterion_cl = NTXentLoss(0.5) # Contrastive Learning Loss\n",
    "\n",
    "            # Train model\n",
    "            wandb.init(project=\"MIL_Resnet_ICH\", name=f\"{run_name}_fold_{fold_idx + 1}\")\n",
    "            wandb.watch(model)\n",
    "            trained_model, likelihood = train_model(model, likelihood, train_loader, val_loader, criterion_cl,\n",
    "                                                    criterion_bce,\n",
    "                                                    optimizer, config.num_epochs, config.learning_rate, DEVICE)\n",
    "\n",
    "            # Evaluate model\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                predictions, labels, _ = evaluate_model(trained_model, likelihood, test_loader, DEVICE)\n",
    "            else:\n",
    "                predictions, labels, _ = evaluate_phase_1(trained_model, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "            metrics = calculate_metrics(predictions, labels)\n",
    "\n",
    "            # Log metrics\n",
    "            wandb.log(metrics)\n",
    "            print_metrics(metrics)\n",
    "            fold_metrics.append(metrics)\n",
    "\n",
    "            plot_roc_curve(trained_model, likelihood, test_loader, DEVICE)\n",
    "            plot_confusion_matrix(trained_model, likelihood, test_loader, DEVICE)\n",
    "\n",
    "            # Save model\n",
    "            torch.save(trained_model.state_dict(), f\"{MODEL_PATH}_fold_{fold_idx + 1}\")\n",
    "            if likelihood:\n",
    "                torch.save(likelihood.state_dict(), f\"{LIKELIHOOD_PATH}_fold_{fold_idx + 1}\")\n",
    "\n",
    "        # Calculate average metrics across all folds\n",
    "        avg_metrics = {}\n",
    "        for metric in fold_metrics[0].keys():\n",
    "            avg_metrics[metric] = np.mean([fold[metric] for fold in fold_metrics])\n",
    "        print(\"\\nAverage Metrics Across All Folds:\")\n",
    "        print_metrics(avg_metrics)\n",
    "        wandb.log(avg_metrics)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "a5e68015552ccdc6",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "id": "1cf2cee20d2c1862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:31.688393Z",
     "start_time": "2025-02-18T14:59:25.640943Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(mode='train', use_cv=False, num_folds=5)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhuynhsikha2003\u001B[0m (\u001B[33mhuynhsikha2003-i-h-c-qu-c-gia-tp-hcm\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/media/hskha23/Kha/Brain-Stroke-Diagnosis/rsna/wandb/run-20250218_215926-p2kyz9gw</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/MIL_Resnet_ICH/runs/p2kyz9gw' target=\"_blank\">end_to_end_experiment_20250218_2159_single_task_refiner_fc_256_output_128_attention_64_kernel_rbf_model_resnet18</a></strong> to <a href='https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/MIL_Resnet_ICH' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/MIL_Resnet_ICH' target=\"_blank\">https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/MIL_Resnet_ICH</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/MIL_Resnet_ICH/runs/p2kyz9gw' target=\"_blank\">https://wandb.ai/huynhsikha2003-i-h-c-qu-c-gia-tp-hcm/MIL_Resnet_ICH/runs/p2kyz9gw</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/hskha23/Kha/Brain-Stroke-Diagnosis/dataset_generators/RSNA_Dataset.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  patient_scan_labels['filename'] = patient_scan_labels['filename'].apply(\n",
      "/media/hskha23/Kha/Brain-Stroke-Diagnosis/dataset_generators/RSNA_Dataset.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  patient_scan_labels['labels'] = patient_scan_labels['labels'].apply(\n",
      "/media/hskha23/Kha/Brain-Stroke-Diagnosis/dataset_generators/RSNA_Dataset.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  patient_scan_labels[column] = patient_scan_labels[column].apply(\n",
      "/media/hskha23/Kha/Brain-Stroke-Diagnosis/dataset_generators/RSNA_Dataset.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  patient_scan_labels['patient_label'] = patient_scan_labels['patient_label'].astype(bool)\n",
      "/media/hskha23/Kha/Brain-Stroke-Diagnosis/dataset_generators/RSNA_Dataset.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  patient_scan_labels['filename'] = patient_scan_labels['filename'].apply(\n",
      "/media/hskha23/Kha/Brain-Stroke-Diagnosis/dataset_generators/RSNA_Dataset.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  patient_scan_labels['labels'] = patient_scan_labels['labels'].apply(\n",
      "/media/hskha23/Kha/Brain-Stroke-Diagnosis/dataset_generators/RSNA_Dataset.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  patient_scan_labels[column] = patient_scan_labels[column].apply(\n",
      "/media/hskha23/Kha/Brain-Stroke-Diagnosis/dataset_generators/RSNA_Dataset.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  patient_scan_labels['patient_label'] = patient_scan_labels['patient_label'].astype(bool)\n",
      "  0%|          | 0/106 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined_features: torch.Size([8, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/106 [00:01<01:14,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined_features: torch.Size([8, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/106 [00:01<00:51,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined_features: torch.Size([8, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/106 [00:02<00:41,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined_features: torch.Size([8, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 5/106 [00:02<00:35,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined_features: torch.Size([8, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/106 [00:02<00:31,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined_features: torch.Size([8, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/106 [00:02<00:29,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined_features: torch.Size([8, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/106 [00:03<00:27,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined_features: torch.Size([8, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 9/106 [00:03<00:26,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined_features: torch.Size([8, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 10/106 [00:03<00:25,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined_features: torch.Size([8, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 10/106 [00:03<00:36,  2.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m----> 2\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_cv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_folds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[29], line 73\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(mode, use_cv, num_folds)\u001B[0m\n\u001B[1;32m     70\u001B[0m wandb\u001B[38;5;241m.\u001B[39mwatch(model)  \u001B[38;5;66;03m# Watch the model to log gradients and parameters\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m TRAINING_TYPE \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mend_to_end\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;66;03m# model.apply(init_weights)\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m     trained_model, likelihood \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlikelihood\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion_cl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mcriterion_bce\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDEVICE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m     predictions, labels, _ \u001B[38;5;241m=\u001B[39m evaluate_model(trained_model, likelihood, test_loader, DEVICE)\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "Cell \u001B[0;32mIn[23], line 181\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, likelihoods, train_loader, val_loader, criterion_cl, criterion_bce, optimizer, num_epochs, learning_rate, device)\u001B[0m\n\u001B[1;32m    178\u001B[0m best_likelihood_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m--> 181\u001B[0m     train_loss, train_predictions, train_labels \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlikelihoods\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion_cl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m                                                              \u001B[49m\u001B[43mcriterion_bce\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m                                                              \u001B[49m\u001B[43mmlls\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariational_ngd_optimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m                                                              \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    185\u001B[0m     train_metrics \u001B[38;5;241m=\u001B[39m calculate_metrics(train_predictions, train_labels)\n\u001B[1;32m    186\u001B[0m     print_epoch_stats(epoch, num_epochs, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m, train_loss, train_metrics)\n",
      "Cell \u001B[0;32mIn[23], line 33\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[0;34m(model, likelihoods, data_loader, criterion_cl, criterion_bce, mlls, optimizer, variational_ngd_optimizer, scheduler, device)\u001B[0m\n\u001B[1;32m     30\u001B[0m     batch_multi_labels \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([batch_multi_labels, batch_multi_labels], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     31\u001B[0m     batch_patient_labels \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([batch_patient_labels, batch_patient_labels], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 33\u001B[0m outputs, gp_outputs, att_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m GP_MODEL \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msingle_task\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m NUM_CLASSES \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     36\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/media/hskha23/Kha/Brain-Stroke-Diagnosis/models/mil_resnet.py:83\u001B[0m, in \u001B[0;36mCNN_ATT_GP_Multilabel.forward\u001B[0;34m(self, bag)\u001B[0m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention_layers)):\n\u001B[1;32m     82\u001B[0m     att_out, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention_layers[i](x)\n\u001B[0;32m---> 83\u001B[0m     gp_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgp_layers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfc\u001B[49m\u001B[43m(\u001B[49m\u001B[43matt_out\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     84\u001B[0m     att_outputs\u001B[38;5;241m.\u001B[39mappend(att_out)\n\u001B[1;32m     85\u001B[0m     gp_outputs\u001B[38;5;241m.\u001B[39mappend(gp_out)\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/models/approximate_gp.py:114\u001B[0m, in \u001B[0;36mApproximateGP.__call__\u001B[0;34m(self, inputs, prior, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    113\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvariational_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprior\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprior\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/variational/variational_strategy.py:272\u001B[0m, in \u001B[0;36mVariationalStrategy.__call__\u001B[0;34m(self, x, prior, **kwargs)\u001B[0m\n\u001B[1;32m    269\u001B[0m         \u001B[38;5;66;03m# Mark that we have updated the variational strategy\u001B[39;00m\n\u001B[1;32m    270\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdated_strategy\u001B[38;5;241m.\u001B[39mfill_(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 272\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprior\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprior\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/variational/_variational_strategy.py:347\u001B[0m, in \u001B[0;36m_VariationalStrategy.__call__\u001B[0;34m(self, x, prior, **kwargs)\u001B[0m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;66;03m# Get q(f)\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(variational_dist_u, MultivariateNormal):\n\u001B[0;32m--> 347\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m        \u001B[49m\u001B[43minducing_points\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m        \u001B[49m\u001B[43minducing_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvariational_dist_u\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvariational_inducing_covar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvariational_dist_u\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlazy_covariance_matrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(variational_dist_u, Delta):\n\u001B[1;32m    355\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\n\u001B[1;32m    356\u001B[0m         x, inducing_points, inducing_values\u001B[38;5;241m=\u001B[39mvariational_dist_u\u001B[38;5;241m.\u001B[39mmean, variational_inducing_covar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    357\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/module.py:31\u001B[0m, in \u001B[0;36mModule.__call__\u001B[0;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[Tensor, Distribution, LinearOperator]:\n\u001B[0;32m---> 31\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(outputs, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [_validate_module_outputs(output) \u001B[38;5;28;01mfor\u001B[39;00m output \u001B[38;5;129;01min\u001B[39;00m outputs]\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/variational/variational_strategy.py:197\u001B[0m, in \u001B[0;36mVariationalStrategy.forward\u001B[0;34m(self, x, inducing_points, inducing_values, variational_inducing_covar, **kwargs)\u001B[0m\n\u001B[1;32m    195\u001B[0m test_mean \u001B[38;5;241m=\u001B[39m full_output\u001B[38;5;241m.\u001B[39mmean[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, num_induc:]\n\u001B[1;32m    196\u001B[0m induc_induc_covar \u001B[38;5;241m=\u001B[39m full_covar[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, :num_induc, :num_induc]\u001B[38;5;241m.\u001B[39madd_jitter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjitter_val)\n\u001B[0;32m--> 197\u001B[0m induc_data_covar \u001B[38;5;241m=\u001B[39m \u001B[43mfull_covar\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43mnum_induc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_induc\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_dense\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    198\u001B[0m data_data_covar \u001B[38;5;241m=\u001B[39m full_covar[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, num_induc:, num_induc:]\n\u001B[1;32m    200\u001B[0m \u001B[38;5;66;03m# Compute interpolation terms\u001B[39;00m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;66;03m# K_ZZ^{-1/2} K_ZX\u001B[39;00m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;66;03m# K_ZZ^{-1/2} \\mu_Z\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/utils/memoize.py:59\u001B[0m, in \u001B[0;36m_cached.<locals>.g\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     57\u001B[0m kwargs_pkl \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mdumps(kwargs)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_in_cache(\u001B[38;5;28mself\u001B[39m, cache_name, \u001B[38;5;241m*\u001B[39margs, kwargs_pkl\u001B[38;5;241m=\u001B[39mkwargs_pkl):\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _add_to_cache(\u001B[38;5;28mself\u001B[39m, cache_name, \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;241m*\u001B[39margs, kwargs_pkl\u001B[38;5;241m=\u001B[39mkwargs_pkl)\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _get_from_cache(\u001B[38;5;28mself\u001B[39m, cache_name, \u001B[38;5;241m*\u001B[39margs, kwargs_pkl\u001B[38;5;241m=\u001B[39mkwargs_pkl)\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:410\u001B[0m, in \u001B[0;36mLazyEvaluatedKernelTensor.to_dense\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    408\u001B[0m \u001B[38;5;129m@cached\u001B[39m\n\u001B[1;32m    409\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto_dense\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 410\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate_kernel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto_dense()\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/utils/memoize.py:59\u001B[0m, in \u001B[0;36m_cached.<locals>.g\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     57\u001B[0m kwargs_pkl \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mdumps(kwargs)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_in_cache(\u001B[38;5;28mself\u001B[39m, cache_name, \u001B[38;5;241m*\u001B[39margs, kwargs_pkl\u001B[38;5;241m=\u001B[39mkwargs_pkl):\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _add_to_cache(\u001B[38;5;28mself\u001B[39m, cache_name, \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;241m*\u001B[39margs, kwargs_pkl\u001B[38;5;241m=\u001B[39mkwargs_pkl)\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _get_from_cache(\u001B[38;5;28mself\u001B[39m, cache_name, \u001B[38;5;241m*\u001B[39margs, kwargs_pkl\u001B[38;5;241m=\u001B[39mkwargs_pkl)\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:25\u001B[0m, in \u001B[0;36mrecall_grad_state.<locals>.wrapped\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(method)\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_grad_enabled):\n\u001B[0;32m---> 25\u001B[0m         output \u001B[38;5;241m=\u001B[39m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:355\u001B[0m, in \u001B[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    353\u001B[0m     temp_active_dims \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel\u001B[38;5;241m.\u001B[39mactive_dims\n\u001B[1;32m    354\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel\u001B[38;5;241m.\u001B[39mactive_dims \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 355\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkernel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    356\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    358\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdiag\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    359\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlast_dim_is_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlast_dim_is_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    362\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel\u001B[38;5;241m.\u001B[39mactive_dims \u001B[38;5;241m=\u001B[39m temp_active_dims\n\u001B[1;32m    364\u001B[0m \u001B[38;5;66;03m# Check the size of the output\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/kernels/kernel.py:539\u001B[0m, in \u001B[0;36mKernel.__call__\u001B[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001B[0m\n\u001B[1;32m    536\u001B[0m     res \u001B[38;5;241m=\u001B[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, last_dim_is_batch\u001B[38;5;241m=\u001B[39mlast_dim_is_batch, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    538\u001B[0m     res \u001B[38;5;241m=\u001B[39m to_linear_operator(\n\u001B[0;32m--> 539\u001B[0m         \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mKernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx1_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx2_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlast_dim_is_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlast_dim_is_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    540\u001B[0m     )\n\u001B[1;32m    541\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/module.py:31\u001B[0m, in \u001B[0;36mModule.__call__\u001B[0;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[Tensor, Distribution, LinearOperator]:\n\u001B[0;32m---> 31\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(outputs, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [_validate_module_outputs(output) \u001B[38;5;28;01mfor\u001B[39;00m output \u001B[38;5;129;01min\u001B[39;00m outputs]\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/kernels/scale_kernel.py:109\u001B[0m, in \u001B[0;36mScaleKernel.forward\u001B[0;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001B[0m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x1, x2, last_dim_is_batch\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, diag\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams):\n\u001B[0;32m--> 109\u001B[0m     orig_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_kernel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdiag\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdiag\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlast_dim_is_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlast_dim_is_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    110\u001B[0m     outputscales \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputscale\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m last_dim_is_batch:\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/kernels/rbf_kernel.py:79\u001B[0m, in \u001B[0;36mRBFKernel.forward\u001B[0;34m(self, x1, x2, diag, **params)\u001B[0m\n\u001B[1;32m     77\u001B[0m     x1_ \u001B[38;5;241m=\u001B[39m x1\u001B[38;5;241m.\u001B[39mdiv(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlengthscale)\n\u001B[1;32m     78\u001B[0m     x2_ \u001B[38;5;241m=\u001B[39m x2\u001B[38;5;241m.\u001B[39mdiv(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlengthscale)\n\u001B[0;32m---> 79\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m postprocess_rbf(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcovar_dist\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx1_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx2_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msquare_dist\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdiag\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdiag\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m RBFCovariance\u001B[38;5;241m.\u001B[39mapply(\n\u001B[1;32m     81\u001B[0m     x1,\n\u001B[1;32m     82\u001B[0m     x2,\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlengthscale,\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m x1, x2: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcovar_dist(x1, x2, square_dist\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, diag\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams),\n\u001B[1;32m     85\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/kernels/kernel.py:357\u001B[0m, in \u001B[0;36mKernel.covar_dist\u001B[0;34m(self, x1, x2, diag, last_dim_is_batch, square_dist, **params)\u001B[0m\n\u001B[1;32m    355\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    356\u001B[0m     dist_func \u001B[38;5;241m=\u001B[39m sq_dist \u001B[38;5;28;01mif\u001B[39;00m square_dist \u001B[38;5;28;01melse\u001B[39;00m dist\n\u001B[0;32m--> 357\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdist_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx1_eq_x2\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/kernels/kernel.py:33\u001B[0m, in \u001B[0;36msq_dist\u001B[0;34m(x1, x2, x1_eq_x2)\u001B[0m\n\u001B[1;32m     30\u001B[0m x1 \u001B[38;5;241m=\u001B[39m x1 \u001B[38;5;241m-\u001B[39m adjustment\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# Compute squared distance matrix using quadratic expansion\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m x1_norm \u001B[38;5;241m=\u001B[39m \u001B[43mx1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     34\u001B[0m x1_pad \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones_like(x1_norm)\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x1_eq_x2 \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m x1\u001B[38;5;241m.\u001B[39mrequires_grad \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m x2\u001B[38;5;241m.\u001B[39mrequires_grad:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "7f67acea19fa3408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:31.690476257Z",
     "start_time": "2025-02-18T14:53:12.504434Z"
    }
   },
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torchsummary\n",
    "#\n",
    "# class VGG(nn.Module):\n",
    "#     def __init__(self, input_channels=3):\n",
    "#         super(VGG, self).__init__()\n",
    "#\n",
    "#         self.features = nn.Sequential(\n",
    "#             # Conv1\n",
    "#             nn.Conv2d(input_channels, 16, kernel_size=5, padding=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#\n",
    "#             # Conv2\n",
    "#             nn.Conv2d(16, 32, kernel_size=3, padding=0),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Dropout(0.3),\n",
    "#\n",
    "#             # Conv3\n",
    "#             nn.Conv2d(32, 32, kernel_size=3, padding=0),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#\n",
    "#             # Conv4\n",
    "#             nn.Conv2d(32, 32, kernel_size=3, padding=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#\n",
    "#             # Conv5\n",
    "#             nn.Conv2d(32, 32, kernel_size=3, padding=0),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Dropout(0.3),\n",
    "#\n",
    "#             # Conv6\n",
    "#             nn.Conv2d(32, 32, kernel_size=3, padding=0),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "#\n",
    "#         self.flatten = nn.Flatten()\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = self.flatten(x)\n",
    "#         return x\n",
    "#\n",
    "# # Instantiate the model\n",
    "# model = VGG(input_channels=1)\n",
    "#\n",
    "# # If you need to use the Glorot (Xavier) uniform initialization\n",
    "# def init_weights(m):\n",
    "#     if type(m) == nn.Conv2d:\n",
    "#         torch.nn.init.xavier_uniform_(m.weight)\n",
    "#\n",
    "# model.apply(init_weights)\n",
    "#\n",
    "# # # Test the model with a sample input\n",
    "# # input_tensor = torch.randn(1, 1, 512, 512)\n",
    "# # output = model(input_tensor)\n",
    "# # print(f\"Output shape: {output.shape}\")\n",
    "#\n",
    "# # # Print the model architecture\n",
    "# model_info = torchsummary.summary(model, (1, 512, 512), device='cpu')\n",
    "# print(model_info)"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Phase 2\n",
    "## Pretrained Features"
   ],
   "id": "1c87f0eae5a39e4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:31.692473038Z",
     "start_time": "2025-02-18T14:53:12.544861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PretrainedFeaturesDataset(Dataset):\n",
    "    def __init__(self, data, num_classes):\n",
    "        self.data = data\n",
    "        self.num_classes = num_classes\n",
    "        self.bag_ids = self.data['bag_id'].unique()\n",
    "        self.grouped_data = {bag_id: self.data[self.data['bag_id'] == bag_id] for bag_id in self.bag_ids}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bag_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        bag_id = self.bag_ids[idx]\n",
    "        bag_data = self.grouped_data[bag_id]\n",
    "\n",
    "        # Extract features (all instances for this bag)\n",
    "        features = torch.FloatTensor(bag_data.filter(like='feature_').values)\n",
    "\n",
    "        # Extract instance labels (all instances for this bag)\n",
    "        instance_labels = torch.LongTensor(bag_data['instance_label'].values)\n",
    "\n",
    "        # Extract bag label (same for all instances in the bag)\n",
    "        bag_label = torch.FloatTensor([bag_data['patient_label'].iloc[0]])\n",
    "\n",
    "        # Extract bag multi-labels (same for all instances in the bag)\n",
    "        bag_multi_labels = torch.FloatTensor(bag_data.filter(like='class_').iloc[0].values)\n",
    "\n",
    "        return features, instance_labels, bag_label, bag_multi_labels\n",
    "\n",
    "def custom_collate(batch, pad_size=28):\n",
    "    # Separate the batch into individual components\n",
    "    features, instance_labels, bag_labels, bag_multi_labels = zip(*batch)\n",
    "\n",
    "    # Pad or truncate features and instance labels to fixed size\n",
    "    features_padded = torch.stack([F.pad(f, (0, 0, 0, pad_size - f.size(0))) if f.size(0) < pad_size\n",
    "                                   else f[:pad_size] for f in features])\n",
    "    instance_labels_padded = torch.stack([F.pad(il, (0, pad_size - il.size(0)), value=-1) if il.size(0) < pad_size\n",
    "                                          else il[:pad_size] for il in instance_labels])\n",
    "\n",
    "    # Stack bag labels and bag multi labels (they should all be the same size)\n",
    "    bag_labels = torch.stack(bag_labels)\n",
    "    bag_multi_labels = torch.stack(bag_multi_labels)\n",
    "\n",
    "    return features_padded, instance_labels_padded, bag_labels, bag_multi_labels\n",
    "\n",
    "def create_pretrained_features_loader(data, num_classes, batch_size, shuffle=True, num_workers=4, drop_last=False, pad_size=28):\n",
    "    dataset = PretrainedFeaturesDataset(data, num_classes)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers,\n",
    "                      drop_last=drop_last, collate_fn=lambda x: custom_collate(x, pad_size=pad_size))"
   ],
   "id": "2f06c565d4eca99",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Phase 2 Model",
   "id": "25f32dd2f490371e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:31.692657211Z",
     "start_time": "2025-02-18T14:53:12.593446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gpytorch\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution, VariationalStrategy\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, MaternKernel\n",
    "from gpytorch.means import ZeroMean, ConstantMean\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class PGLikelihood(gpytorch.likelihoods._OneDimensionalLikelihood):\n",
    "    # contribution to Eqn (10) in Reference [1].\n",
    "    def expected_log_prob(self, target, input, *args, **kwargs):\n",
    "        mean, variance = input.mean, input.variance\n",
    "        # Compute the expectation E[f_i^2]\n",
    "        raw_second_moment = variance + mean.pow(2)\n",
    "\n",
    "        # Translate targets to be -1, 1\n",
    "        target = target.to(mean.dtype).mul(2.).sub(1.)\n",
    "\n",
    "        # We detach the following variable since we do not want\n",
    "        # to differentiate through the closed-form PG update.\n",
    "        c = raw_second_moment.detach().sqrt()\n",
    "        # Compute mean of PG auxiliary variable omega: 0.5 * Expectation[omega]\n",
    "        # See Eqn (11) and Appendix A2 and A3 in Reference [1] for details.\n",
    "        half_omega = 0.25 * torch.tanh(0.5 * c) / c\n",
    "\n",
    "        # Expected log likelihood\n",
    "        res = 0.5 * target * mean - half_omega * raw_second_moment\n",
    "        # Sum over data points in mini-batch\n",
    "        res = res.sum(dim=-1)\n",
    "\n",
    "        return res\n",
    "\n",
    "    # define the likelihood\n",
    "    def forward(self, function_samples):\n",
    "        return torch.distributions.Bernoulli(logits=function_samples)\n",
    "\n",
    "    # define the marginal likelihood using Gauss Hermite quadrature\n",
    "    def marginal(self, function_dist):\n",
    "        prob_lambda = lambda function_samples: self.forward(function_samples).probs\n",
    "        probs = self.quadrature(prob_lambda, function_dist)\n",
    "        return torch.distributions.Bernoulli(probs=probs)\n",
    "\n",
    "\n",
    "class SingletaskGPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel_type='rbf', nu=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inducing_points (torch.Tensor):\n",
    "            kernel_type (str):\n",
    "            nu (float):\n",
    "        \"\"\"\n",
    "        variational_distribution = gpytorch.variational.NaturalVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super(SingletaskGPModel, self).__init__(variational_strategy)\n",
    "\n",
    "        # self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "\n",
    "        if kernel_type == 'rbf':\n",
    "            self.covar_module = ScaleKernel(RBFKernel())\n",
    "        elif kernel_type == 'matern_kernel':\n",
    "            self.covar_module = ScaleKernel(MaternKernel(nu=nu))\n",
    "        else:\n",
    "            raise ValueError(\"kernel_type must be either 'rbf' or 'matern_kernel'\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_instances, input_dim)\n",
    "        attention_weights = self.attention(x)\n",
    "        gate_weights = torch.sigmoid(self.gate(x))\n",
    "\n",
    "        weights = attention_weights * gate_weights\n",
    "        weights = F.softmax(weights, dim=1)\n",
    "\n",
    "        return (x * weights).sum(dim=1), weights.squeeze(-1)\n",
    "\n",
    "# Define the CNN_Att Model\n",
    "class CNN_Att(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim, output_dim, num_ind=50):\n",
    "        super(CNN_Att, self).__init__()\n",
    "        self.attention_layer = AttentionLayer(feature_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(feature_dim + 1, output_dim)  # Fully connected layer\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "\n",
    "        inducing_points = torch.rand(num_ind, 1) # Random\n",
    "        self.gp_layer = SingletaskGPModel(inducing_points)\n",
    "        with torch.inference_mode():\n",
    "            self.gp_layer.covar_module.base_kernel.lengthscale = torch.tensor([2.0])\n",
    "            self.gp_layer.covar_module.outputscale = torch.tensor([0.5])\n",
    "\n",
    "        self.fc_gp = nn.Linear(feature_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_instances, feature_dim)\n",
    "        attended_features, attention_weights = self.attention_layer(x)\n",
    "        attended_features = self.dropout(attended_features)\n",
    "        x = self.fc_gp(attended_features)\n",
    "        gp_output = self.gp_layer(x)\n",
    "        output = self.fc(torch.cat([attended_features, gp_output.mean.unsqueeze(-1)], dim=-1))\n",
    "\n",
    "        return output, gp_output, _"
   ],
   "id": "7b61a8b31595dfe1",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training and Evaluation Functions",
   "id": "ef6fee1e8e78ee87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:31.698730466Z",
     "start_time": "2025-02-18T14:53:12.643518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training function\n",
    "def train(model, dataloader, optimizer, criterion, device, likelihood, var_optimizer, mlls):\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    epoch_loss = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with gpytorch.settings.num_likelihood_samples(100):\n",
    "        # for features, instance_labels, patient_label, patient_multi_label in dataloader:\n",
    "        for features, patient_label in dataloader:\n",
    "            features, patient_label = features.to(device), patient_label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            var_optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            predictions, gp_output, _ = model(features)  # predictions shape: (batch_size, 1)\n",
    "\n",
    "            # loss = -mlls(gp_output, patient_label) * 0.5 + criterion(predictions, patient_label) * 0.5\n",
    "            loss = -mlls(gp_output, patient_label)\n",
    "            # loss = criterion(predictions, patient_label)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            var_optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            # preds = (torch.sigmoid(predictions) > 0.5).float()\n",
    "            preds = likelihood(gp_output).probs.ge(THRESHOLD).float()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(patient_label.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    average = 'weighted'\n",
    "    precision = precision_score(all_labels, all_preds, average=average)\n",
    "    recall = recall_score(all_labels, all_preds, average=average)\n",
    "    f1 = f1_score(all_labels, all_preds, average=average)\n",
    "\n",
    "    return epoch_loss / len(dataloader), accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, dataloader, criterion, device, likelihood, mlls):\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    epoch_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        # for features, instance_labels, patient_label, patient_multi_label in dataloader:\n",
    "        for features, patient_label in dataloader:\n",
    "            features, patient_label = features.to(device), patient_label.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions, gp_output, _ = model(features)  # predictions shape: (batch_size, 1)\n",
    "            # loss = -mlls(gp_output, labels) * 0.5 + criterion(predictions, labels) * 0.5\n",
    "            loss = -mlls(gp_output, patient_label)\n",
    "            # loss = criterion(predictions, patient_label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            all_labels.extend(patient_label.cpu().numpy())\n",
    "            probs = likelihood(gp_output).probs\n",
    "            # probs = torch.sigmoid(predictions)\n",
    "            preds = (probs >= THRESHOLD).float()\n",
    "            all_preds.extend((preds >= THRESHOLD).cpu().numpy())\n",
    "            all_scores.extend(probs.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    average = 'binary'\n",
    "    precision = precision_score(all_labels, all_preds, average=average)\n",
    "    recall = recall_score(all_labels, all_preds, average=average)\n",
    "    f1 = f1_score(all_labels, all_preds, average=average)\n",
    "    cohen_kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "\n",
    "    return epoch_loss / len(dataloader), accuracy, precision, recall, f1, cohen_kappa, all_labels, all_preds, all_scores\n",
    "\n",
    "# Function to plot ROC AUC curve\n",
    "def plot_roc_auc(labels, scores):\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC AUC = {roc_auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "def plot_pr_curve(y_true, y_scores):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "    auc_pr = auc(recall, precision)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='b', label=f'AUC-PR = {auc_pr:.2f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_scores):\n",
    "    y_pred = []\n",
    "    for score in y_scores:\n",
    "        if score >= THRESHOLD:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ],
   "id": "f0e478b0c7769ac1",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Main function",
   "id": "a07090fde231934"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:31.700798766Z",
     "start_time": "2025-02-18T14:53:12.696941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data from CSV\n",
    "def load_data(csv_file, num_instances=28, test_size=0.2, random_state=42):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Group features by bag_name\n",
    "    grouped = df.groupby('bag_id')\n",
    "\n",
    "    # Prepare feature lists and label lists\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for bag_name, group in grouped:\n",
    "        # Extract features for the current bag\n",
    "        feature_cols = [f'feature_{i}' for i in range(8)]\n",
    "        features = group[feature_cols].values\n",
    "\n",
    "        # Pad with zeros if the number of instances is less than num_instances\n",
    "        if len(features) < num_instances:\n",
    "            padding_size = num_instances - len(features)\n",
    "            padding = np.zeros((padding_size, 8))\n",
    "            features = np.vstack((features, padding))  # Vertically stack features and padding\n",
    "\n",
    "        # Truncate if the number of instances is greater than num_instances (shouldn't happen, but good to be safe)\n",
    "        elif len(features) > num_instances:\n",
    "            features = features[:num_instances]\n",
    "\n",
    "        feature_list.append(features)\n",
    "\n",
    "        # Get the bag label for the current bag\n",
    "        bag_label = group['patient_label'].values[0]\n",
    "        label_list.append(bag_label)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(feature_list)\n",
    "    y = np.array(label_list)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Define a custom Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ],
   "id": "523b3acd6e57e98a",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:59:31.704856812Z",
     "start_time": "2025-02-18T14:53:12.751804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main function\n",
    "def main(hidden_dim=64, learning_rate=0.0001, batch_size=16, num_epochs=200, num_instances=MAX_SLICES):\n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load the data\n",
    "    # patient_scan_labels = pd.read_csv('./train_features.csv')\n",
    "\n",
    "    # Split the dataset\n",
    "    # train_labels, val_labels, test_labels = split_dataset(patient_scan_labels, test_size=0.0)\n",
    "    # test_labels = pd.read_csv('./test_features.csv')\n",
    "\n",
    "    # # Create data loaders\n",
    "    # train_loader = create_pretrained_features_loader(\n",
    "    #     train_labels, num_classes=6, batch_size=batch_size, shuffle=True, drop_last=False, pad_size=num_instances\n",
    "    # )\n",
    "    #\n",
    "    # val_loader = create_pretrained_features_loader(\n",
    "    #     val_labels, num_classes=6, batch_size=batch_size, shuffle=False, drop_last=False, pad_size=num_instances\n",
    "    # )\n",
    "    #\n",
    "    # test_loader = create_pretrained_features_loader(\n",
    "    #     test_labels, num_classes=6, batch_size=TEST_BATCH_SIZE, shuffle=False, drop_last=False, pad_size=num_instances\n",
    "    # )\n",
    "\n",
    "    X_train, y_train = load_data('train_features.csv', num_instances=num_instances)\n",
    "    X_test, y_test = load_data('test_features.csv', num_instances=num_instances)\n",
    "\n",
    "    # Create Datasets and DataLoaders\n",
    "    train_dataset = CustomDataset(X_train, y_train)\n",
    "    test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    # Model, optimizer, and loss function\n",
    "    output_dim = 1\n",
    "    features_dim = 8\n",
    "    model = CNN_Att(features_dim, hidden_dim, output_dim, num_ind=50).to(device)\n",
    "    likelihood = PGLikelihood().to(device)\n",
    "\n",
    "    mlls = gpytorch.mlls.VariationalELBO(likelihood, model.gp_layer, num_data=len(train_loader))\n",
    "    variational_ngd_optim = gpytorch.optim.NGD(model.gp_layer.variational_parameters(), num_data=len(train_loader), lr=0.01)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    # pos_weights = torch.tensor([np.sum(y_train == 0) / np.sum(y_train == 1)], dtype=torch.float32).to(device)\n",
    "    pos_weights = torch.tensor([40.0], dtype=torch.float32).to(device)\n",
    "    print(f'Positive weights: {pos_weights.item()}')\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)  # Binary cross-entropy loss with logits\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc,  train_precision, train_recall, train_f1 = train(model, train_loader, optimizer, criterion, device, likelihood, variational_ngd_optim, mlls)\n",
    "        val_loss, val_acc, val_precision, val_recall, val_f1, _, _, _, _ = evaluate(model, test_loader, criterion, device, likelihood, mlls)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}: '\n",
    "              f'Train: Loss={train_loss:.4f}, Acc={train_acc:.4f}, Precision={train_precision:.4f}, Recall={train_recall:.4f}, F1={train_f1:.4f}')\n",
    "        print(f'Val: Loss={val_loss:.4f}, Acc={val_acc:.4f}, Precision={val_precision:.4f}, Recall={val_recall:.4f}, F1={val_f1:.4f} \\n')\n",
    "\n",
    "    # Plot ROC AUC curve\n",
    "    test_loss, test_acc, test_precision, test_recall, test_f1, test_co_kappa, test_labels, test_preds, test_scores = evaluate(model, test_loader, criterion, device, likelihood, mlls)\n",
    "    print(f'Test: Loss={test_loss:.4f}, Acc={test_acc:.4f}, Precision={test_precision:.4f}, Recall={test_recall:.4f}, F1={test_f1:.4f}, Cohen Kappa={test_co_kappa:.4f}')\n",
    "    plot_roc_auc(test_labels, test_scores)\n",
    "    plot_pr_curve(test_labels, test_scores)\n",
    "    plot_confusion_matrix(test_labels, test_scores)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    def seed_everything(seed=27):\n",
    "        random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    seed_everything()\n",
    "\n",
    "    main(hidden_dim=64, learning_rate=0.0001, batch_size=16, num_epochs=100, num_instances=MAX_SLICES)"
   ],
   "id": "5134b37178790066",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive weights: 40.0\n",
      "Starting training...\n",
      "Epoch 1/100: Train: Loss=0.0223, Acc=0.5601, Precision=0.4882, Recall=0.5601, F1=0.4703\n",
      "Val: Loss=0.0060, Acc=0.5270, Precision=0.0000, Recall=0.0000, F1=0.0000 \n",
      "\n",
      "Epoch 2/100: Train: Loss=-0.0096, Acc=0.6156, Precision=0.6026, Recall=0.6156, F1=0.5810\n",
      "Val: Loss=-0.0163, Acc=0.6284, Precision=1.0000, Recall=0.2143, F1=0.3529 \n",
      "\n",
      "Epoch 3/100: Train: Loss=-0.0320, Acc=0.7146, Precision=0.7119, Recall=0.7146, F1=0.7078\n",
      "Val: Loss=-0.0411, Acc=0.6892, Precision=1.0000, Recall=0.3429, F1=0.5106 \n",
      "\n",
      "Epoch 4/100: Train: Loss=-0.0750, Acc=0.8184, Precision=0.8198, Recall=0.8184, F1=0.8153\n",
      "Val: Loss=-0.0647, Acc=0.7365, Precision=0.9429, Recall=0.4714, F1=0.6286 \n",
      "\n",
      "Epoch 5/100: Train: Loss=-0.1038, Acc=0.8561, Precision=0.8560, Recall=0.8561, F1=0.8551\n",
      "Val: Loss=-0.0779, Acc=0.7568, Precision=0.9474, Recall=0.5143, F1=0.6667 \n",
      "\n",
      "Epoch 6/100: Train: Loss=-0.1256, Acc=0.8667, Precision=0.8729, Recall=0.8667, F1=0.8639\n",
      "Val: Loss=-0.0851, Acc=0.7635, Precision=0.9268, Recall=0.5429, F1=0.6847 \n",
      "\n",
      "Epoch 7/100: Train: Loss=-0.1337, Acc=0.8550, Precision=0.8619, Recall=0.8550, F1=0.8514\n",
      "Val: Loss=-0.0914, Acc=0.7905, Precision=0.9149, Recall=0.6143, F1=0.7350 \n",
      "\n",
      "Epoch 8/100: Train: Loss=-0.1478, Acc=0.8703, Precision=0.8786, Recall=0.8703, F1=0.8671\n",
      "Val: Loss=-0.0974, Acc=0.8041, Precision=0.9184, Recall=0.6429, F1=0.7563 \n",
      "\n",
      "Epoch 9/100: Train: Loss=-0.1538, Acc=0.8774, Precision=0.8838, Recall=0.8774, F1=0.8748\n",
      "Val: Loss=-0.1002, Acc=0.8041, Precision=0.9184, Recall=0.6429, F1=0.7563 \n",
      "\n",
      "Epoch 10/100: Train: Loss=-0.1752, Acc=0.8868, Precision=0.8928, Recall=0.8868, F1=0.8846\n",
      "Val: Loss=-0.1016, Acc=0.8041, Precision=0.9184, Recall=0.6429, F1=0.7563 \n",
      "\n",
      "Epoch 11/100: Train: Loss=-0.1680, Acc=0.8703, Precision=0.8759, Recall=0.8703, F1=0.8676\n",
      "Val: Loss=-0.1037, Acc=0.8108, Precision=0.9200, Recall=0.6571, F1=0.7667 \n",
      "\n",
      "Epoch 12/100: Train: Loss=-0.1901, Acc=0.8962, Precision=0.9032, Recall=0.8962, F1=0.8941\n",
      "Val: Loss=-0.1043, Acc=0.8041, Precision=0.9184, Recall=0.6429, F1=0.7563 \n",
      "\n",
      "Epoch 13/100: Train: Loss=-0.1852, Acc=0.8903, Precision=0.8957, Recall=0.8903, F1=0.8883\n",
      "Val: Loss=-0.1079, Acc=0.8176, Precision=0.9216, Recall=0.6714, F1=0.7769 \n",
      "\n",
      "Epoch 14/100: Train: Loss=-0.2161, Acc=0.9092, Precision=0.9110, Recall=0.9092, F1=0.9083\n",
      "Val: Loss=-0.1078, Acc=0.8176, Precision=0.9216, Recall=0.6714, F1=0.7769 \n",
      "\n",
      "Epoch 15/100: Train: Loss=-0.2075, Acc=0.9163, Precision=0.9209, Recall=0.9163, F1=0.9150\n",
      "Val: Loss=-0.1082, Acc=0.8108, Precision=0.9200, Recall=0.6571, F1=0.7667 \n",
      "\n",
      "Epoch 16/100: Train: Loss=-0.2152, Acc=0.9127, Precision=0.9162, Recall=0.9127, F1=0.9116\n",
      "Val: Loss=-0.1112, Acc=0.8176, Precision=0.9216, Recall=0.6714, F1=0.7769 \n",
      "\n",
      "Epoch 17/100: Train: Loss=-0.2200, Acc=0.9127, Precision=0.9166, Recall=0.9127, F1=0.9115\n",
      "Val: Loss=-0.1135, Acc=0.8243, Precision=0.9231, Recall=0.6857, F1=0.7869 \n",
      "\n",
      "Epoch 18/100: Train: Loss=-0.2227, Acc=0.9175, Precision=0.9207, Recall=0.9175, F1=0.9164\n",
      "Val: Loss=-0.1148, Acc=0.8176, Precision=0.8772, Recall=0.7143, F1=0.7874 \n",
      "\n",
      "Epoch 19/100: Train: Loss=-0.2335, Acc=0.9281, Precision=0.9304, Recall=0.9281, F1=0.9273\n",
      "Val: Loss=-0.1157, Acc=0.8108, Precision=0.8621, Recall=0.7143, F1=0.7812 \n",
      "\n",
      "Epoch 20/100: Train: Loss=-0.2468, Acc=0.9328, Precision=0.9338, Recall=0.9328, F1=0.9323\n",
      "Val: Loss=-0.1150, Acc=0.8108, Precision=0.8621, Recall=0.7143, F1=0.7812 \n",
      "\n",
      "Epoch 21/100: Train: Loss=-0.2474, Acc=0.9387, Precision=0.9395, Recall=0.9387, F1=0.9383\n",
      "Val: Loss=-0.1156, Acc=0.8108, Precision=0.8621, Recall=0.7143, F1=0.7812 \n",
      "\n",
      "Epoch 22/100: Train: Loss=-0.2532, Acc=0.9375, Precision=0.9394, Recall=0.9375, F1=0.9369\n",
      "Val: Loss=-0.1167, Acc=0.8176, Precision=0.8644, Recall=0.7286, F1=0.7907 \n",
      "\n",
      "Epoch 23/100: Train: Loss=-0.2550, Acc=0.9493, Precision=0.9512, Recall=0.9493, F1=0.9489\n",
      "Val: Loss=-0.1168, Acc=0.8176, Precision=0.8644, Recall=0.7286, F1=0.7907 \n",
      "\n",
      "Epoch 24/100: Train: Loss=-0.2526, Acc=0.9375, Precision=0.9389, Recall=0.9375, F1=0.9370\n",
      "Val: Loss=-0.1178, Acc=0.8176, Precision=0.8644, Recall=0.7286, F1=0.7907 \n",
      "\n",
      "Epoch 25/100: Train: Loss=-0.2696, Acc=0.9458, Precision=0.9460, Recall=0.9458, F1=0.9455\n",
      "Val: Loss=-0.1176, Acc=0.8176, Precision=0.8644, Recall=0.7286, F1=0.7907 \n",
      "\n",
      "Epoch 26/100: Train: Loss=-0.2858, Acc=0.9693, Precision=0.9696, Recall=0.9693, F1=0.9693\n",
      "Val: Loss=-0.1172, Acc=0.8176, Precision=0.8644, Recall=0.7286, F1=0.7907 \n",
      "\n",
      "Epoch 27/100: Train: Loss=-0.2740, Acc=0.9540, Precision=0.9552, Recall=0.9540, F1=0.9537\n",
      "Val: Loss=-0.1180, Acc=0.8176, Precision=0.8644, Recall=0.7286, F1=0.7907 \n",
      "\n",
      "Epoch 28/100: Train: Loss=-0.2784, Acc=0.9611, Precision=0.9614, Recall=0.9611, F1=0.9609\n",
      "Val: Loss=-0.1183, Acc=0.8176, Precision=0.8644, Recall=0.7286, F1=0.7907 \n",
      "\n",
      "Epoch 29/100: Train: Loss=-0.2834, Acc=0.9623, Precision=0.9628, Recall=0.9623, F1=0.9621\n",
      "Val: Loss=-0.1186, Acc=0.8176, Precision=0.8644, Recall=0.7286, F1=0.7907 \n",
      "\n",
      "Epoch 30/100: Train: Loss=-0.2848, Acc=0.9599, Precision=0.9599, Recall=0.9599, F1=0.9598\n",
      "Val: Loss=-0.1190, Acc=0.8176, Precision=0.8644, Recall=0.7286, F1=0.7907 \n",
      "\n",
      "Epoch 31/100: Train: Loss=-0.2804, Acc=0.9552, Precision=0.9560, Recall=0.9552, F1=0.9549\n",
      "Val: Loss=-0.1189, Acc=0.8176, Precision=0.8644, Recall=0.7286, F1=0.7907 \n",
      "\n",
      "Epoch 32/100: Train: Loss=-0.2923, Acc=0.9611, Precision=0.9614, Recall=0.9611, F1=0.9609\n",
      "Val: Loss=-0.1173, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 33/100: Train: Loss=-0.2932, Acc=0.9564, Precision=0.9571, Recall=0.9564, F1=0.9561\n",
      "Val: Loss=-0.1192, Acc=0.8176, Precision=0.8644, Recall=0.7286, F1=0.7907 \n",
      "\n",
      "Epoch 34/100: Train: Loss=-0.2903, Acc=0.9575, Precision=0.9589, Recall=0.9575, F1=0.9573\n",
      "Val: Loss=-0.1199, Acc=0.8176, Precision=0.8644, Recall=0.7286, F1=0.7907 \n",
      "\n",
      "Epoch 35/100: Train: Loss=-0.2896, Acc=0.9575, Precision=0.9582, Recall=0.9575, F1=0.9573\n",
      "Val: Loss=-0.1204, Acc=0.8176, Precision=0.8644, Recall=0.7286, F1=0.7907 \n",
      "\n",
      "Epoch 36/100: Train: Loss=-0.3074, Acc=0.9634, Precision=0.9638, Recall=0.9634, F1=0.9633\n",
      "Val: Loss=-0.1194, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 37/100: Train: Loss=-0.3024, Acc=0.9611, Precision=0.9621, Recall=0.9611, F1=0.9609\n",
      "Val: Loss=-0.1197, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 38/100: Train: Loss=-0.3087, Acc=0.9623, Precision=0.9630, Recall=0.9623, F1=0.9621\n",
      "Val: Loss=-0.1200, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 39/100: Train: Loss=-0.3072, Acc=0.9611, Precision=0.9617, Recall=0.9611, F1=0.9609\n",
      "Val: Loss=-0.1188, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 40/100: Train: Loss=-0.3134, Acc=0.9682, Precision=0.9686, Recall=0.9682, F1=0.9680\n",
      "Val: Loss=-0.1201, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 41/100: Train: Loss=-0.3239, Acc=0.9752, Precision=0.9753, Recall=0.9752, F1=0.9752\n",
      "Val: Loss=-0.1202, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 42/100: Train: Loss=-0.3192, Acc=0.9658, Precision=0.9663, Recall=0.9658, F1=0.9657\n",
      "Val: Loss=-0.1194, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 43/100: Train: Loss=-0.3214, Acc=0.9658, Precision=0.9658, Recall=0.9658, F1=0.9657\n",
      "Val: Loss=-0.1172, Acc=0.8243, Precision=0.8548, Recall=0.7571, F1=0.8030 \n",
      "\n",
      "Epoch 44/100: Train: Loss=-0.3298, Acc=0.9776, Precision=0.9777, Recall=0.9776, F1=0.9775\n",
      "Val: Loss=-0.1192, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 45/100: Train: Loss=-0.3161, Acc=0.9658, Precision=0.9663, Recall=0.9658, F1=0.9657\n",
      "Val: Loss=-0.1187, Acc=0.8176, Precision=0.8525, Recall=0.7429, F1=0.7939 \n",
      "\n",
      "Epoch 46/100: Train: Loss=-0.3400, Acc=0.9800, Precision=0.9800, Recall=0.9800, F1=0.9799\n",
      "Val: Loss=-0.1193, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 47/100: Train: Loss=-0.3303, Acc=0.9634, Precision=0.9643, Recall=0.9634, F1=0.9633\n",
      "Val: Loss=-0.1210, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 48/100: Train: Loss=-0.3333, Acc=0.9646, Precision=0.9649, Recall=0.9646, F1=0.9645\n",
      "Val: Loss=-0.1210, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 49/100: Train: Loss=-0.3320, Acc=0.9741, Precision=0.9741, Recall=0.9741, F1=0.9740\n",
      "Val: Loss=-0.1218, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 50/100: Train: Loss=-0.3427, Acc=0.9705, Precision=0.9707, Recall=0.9705, F1=0.9704\n",
      "Val: Loss=-0.1211, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 51/100: Train: Loss=-0.3466, Acc=0.9705, Precision=0.9707, Recall=0.9705, F1=0.9704\n",
      "Val: Loss=-0.1211, Acc=0.8176, Precision=0.8525, Recall=0.7429, F1=0.7939 \n",
      "\n",
      "Epoch 52/100: Train: Loss=-0.3346, Acc=0.9693, Precision=0.9695, Recall=0.9693, F1=0.9693\n",
      "Val: Loss=-0.1215, Acc=0.8176, Precision=0.8525, Recall=0.7429, F1=0.7939 \n",
      "\n",
      "Epoch 53/100: Train: Loss=-0.3504, Acc=0.9823, Precision=0.9823, Recall=0.9823, F1=0.9823\n",
      "Val: Loss=-0.1227, Acc=0.8243, Precision=0.8667, Recall=0.7429, F1=0.8000 \n",
      "\n",
      "Epoch 54/100: Train: Loss=-0.3466, Acc=0.9717, Precision=0.9718, Recall=0.9717, F1=0.9716\n",
      "Val: Loss=-0.1213, Acc=0.8176, Precision=0.8525, Recall=0.7429, F1=0.7939 \n",
      "\n",
      "Epoch 55/100: Train: Loss=-0.3521, Acc=0.9800, Precision=0.9800, Recall=0.9800, F1=0.9799\n",
      "Val: Loss=-0.1214, Acc=0.8176, Precision=0.8525, Recall=0.7429, F1=0.7939 \n",
      "\n",
      "Epoch 56/100: Train: Loss=-0.3419, Acc=0.9670, Precision=0.9674, Recall=0.9670, F1=0.9669\n",
      "Val: Loss=-0.1194, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060 \n",
      "\n",
      "Epoch 57/100: Train: Loss=-0.3485, Acc=0.9764, Precision=0.9765, Recall=0.9764, F1=0.9764\n",
      "Val: Loss=-0.1206, Acc=0.8311, Precision=0.8571, Recall=0.7714, F1=0.8120 \n",
      "\n",
      "Epoch 58/100: Train: Loss=-0.3434, Acc=0.9717, Precision=0.9718, Recall=0.9717, F1=0.9716\n",
      "Val: Loss=-0.1197, Acc=0.8311, Precision=0.8462, Recall=0.7857, F1=0.8148 \n",
      "\n",
      "Epoch 59/100: Train: Loss=-0.3593, Acc=0.9823, Precision=0.9823, Recall=0.9823, F1=0.9823\n",
      "Val: Loss=-0.1189, Acc=0.8311, Precision=0.8462, Recall=0.7857, F1=0.8148 \n",
      "\n",
      "Epoch 60/100: Train: Loss=-0.3590, Acc=0.9776, Precision=0.9777, Recall=0.9776, F1=0.9775\n",
      "Val: Loss=-0.1152, Acc=0.8243, Precision=0.8333, Recall=0.7857, F1=0.8088 \n",
      "\n",
      "Epoch 61/100: Train: Loss=-0.3645, Acc=0.9800, Precision=0.9800, Recall=0.9800, F1=0.9799\n",
      "Val: Loss=-0.1197, Acc=0.8311, Precision=0.8462, Recall=0.7857, F1=0.8148 \n",
      "\n",
      "Epoch 62/100: Train: Loss=-0.3592, Acc=0.9776, Precision=0.9777, Recall=0.9776, F1=0.9775\n",
      "Val: Loss=-0.1222, Acc=0.8243, Precision=0.8548, Recall=0.7571, F1=0.8030 \n",
      "\n",
      "Epoch 63/100: Train: Loss=-0.3589, Acc=0.9729, Precision=0.9732, Recall=0.9729, F1=0.9728\n",
      "Val: Loss=-0.1206, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060 \n",
      "\n",
      "Epoch 64/100: Train: Loss=-0.3711, Acc=0.9847, Precision=0.9847, Recall=0.9847, F1=0.9847\n",
      "Val: Loss=-0.1227, Acc=0.8311, Precision=0.8571, Recall=0.7714, F1=0.8120 \n",
      "\n",
      "Epoch 65/100: Train: Loss=-0.3791, Acc=0.9906, Precision=0.9906, Recall=0.9906, F1=0.9906\n",
      "Val: Loss=-0.1228, Acc=0.8243, Precision=0.8548, Recall=0.7571, F1=0.8030 \n",
      "\n",
      "Epoch 66/100: Train: Loss=-0.3739, Acc=0.9858, Precision=0.9859, Recall=0.9858, F1=0.9858\n",
      "Val: Loss=-0.1227, Acc=0.8243, Precision=0.8548, Recall=0.7571, F1=0.8030 \n",
      "\n",
      "Epoch 67/100: Train: Loss=-0.3701, Acc=0.9788, Precision=0.9789, Recall=0.9788, F1=0.9787\n",
      "Val: Loss=-0.1228, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060 \n",
      "\n",
      "Epoch 68/100: Train: Loss=-0.3642, Acc=0.9788, Precision=0.9791, Recall=0.9788, F1=0.9787\n",
      "Val: Loss=-0.1211, Acc=0.8311, Precision=0.8462, Recall=0.7857, F1=0.8148 \n",
      "\n",
      "Epoch 69/100: Train: Loss=-0.3733, Acc=0.9858, Precision=0.9859, Recall=0.9858, F1=0.9858\n",
      "Val: Loss=-0.1214, Acc=0.8311, Precision=0.8462, Recall=0.7857, F1=0.8148 \n",
      "\n",
      "Epoch 70/100: Train: Loss=-0.3729, Acc=0.9811, Precision=0.9812, Recall=0.9811, F1=0.9811\n",
      "Val: Loss=-0.1229, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060 \n",
      "\n",
      "Epoch 71/100: Train: Loss=-0.3766, Acc=0.9823, Precision=0.9825, Recall=0.9823, F1=0.9823\n",
      "Val: Loss=-0.1232, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060 \n",
      "\n",
      "Epoch 72/100: Train: Loss=-0.3851, Acc=0.9858, Precision=0.9858, Recall=0.9858, F1=0.9858\n",
      "Val: Loss=-0.1227, Acc=0.8311, Precision=0.8462, Recall=0.7857, F1=0.8148 \n",
      "\n",
      "Epoch 73/100: Train: Loss=-0.3828, Acc=0.9847, Precision=0.9847, Recall=0.9847, F1=0.9847\n",
      "Val: Loss=-0.1217, Acc=0.8311, Precision=0.8462, Recall=0.7857, F1=0.8148 \n",
      "\n",
      "Epoch 74/100: Train: Loss=-0.3891, Acc=0.9858, Precision=0.9859, Recall=0.9858, F1=0.9858\n",
      "Val: Loss=-0.1209, Acc=0.8311, Precision=0.8462, Recall=0.7857, F1=0.8148 \n",
      "\n",
      "Epoch 75/100: Train: Loss=-0.3888, Acc=0.9882, Precision=0.9882, Recall=0.9882, F1=0.9882\n",
      "Val: Loss=-0.1210, Acc=0.8311, Precision=0.8462, Recall=0.7857, F1=0.8148 \n",
      "\n",
      "Epoch 76/100: Train: Loss=-0.3850, Acc=0.9882, Precision=0.9882, Recall=0.9882, F1=0.9882\n",
      "Val: Loss=-0.1194, Acc=0.8243, Precision=0.8333, Recall=0.7857, F1=0.8088 \n",
      "\n",
      "Epoch 77/100: Train: Loss=-0.3853, Acc=0.9847, Precision=0.9847, Recall=0.9847, F1=0.9847\n",
      "Val: Loss=-0.1220, Acc=0.8311, Precision=0.8462, Recall=0.7857, F1=0.8148 \n",
      "\n",
      "Epoch 78/100: Train: Loss=-0.3911, Acc=0.9870, Precision=0.9870, Recall=0.9870, F1=0.9870\n",
      "Val: Loss=-0.1222, Acc=0.8311, Precision=0.8462, Recall=0.7857, F1=0.8148 \n",
      "\n",
      "Epoch 79/100: Train: Loss=-0.3941, Acc=0.9906, Precision=0.9906, Recall=0.9906, F1=0.9906\n",
      "Val: Loss=-0.1230, Acc=0.8311, Precision=0.8462, Recall=0.7857, F1=0.8148 \n",
      "\n",
      "Epoch 80/100: Train: Loss=-0.3976, Acc=0.9894, Precision=0.9894, Recall=0.9894, F1=0.9894\n",
      "Val: Loss=-0.1234, Acc=0.8311, Precision=0.8462, Recall=0.7857, F1=0.8148 \n",
      "\n",
      "Epoch 81/100: Train: Loss=-0.3997, Acc=0.9870, Precision=0.9870, Recall=0.9870, F1=0.9870\n",
      "Val: Loss=-0.1216, Acc=0.8243, Precision=0.8333, Recall=0.7857, F1=0.8088 \n",
      "\n",
      "Epoch 82/100: Train: Loss=-0.3905, Acc=0.9847, Precision=0.9847, Recall=0.9847, F1=0.9847\n",
      "Val: Loss=-0.1218, Acc=0.8243, Precision=0.8333, Recall=0.7857, F1=0.8088 \n",
      "\n",
      "Epoch 83/100: Train: Loss=-0.4010, Acc=0.9917, Precision=0.9917, Recall=0.9917, F1=0.9917\n",
      "Val: Loss=-0.1242, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060 \n",
      "\n",
      "Epoch 84/100: Train: Loss=-0.3977, Acc=0.9858, Precision=0.9859, Recall=0.9858, F1=0.9858\n",
      "Val: Loss=-0.1251, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060 \n",
      "\n",
      "Epoch 85/100: Train: Loss=-0.4023, Acc=0.9894, Precision=0.9894, Recall=0.9894, F1=0.9894\n",
      "Val: Loss=-0.1235, Acc=0.8176, Precision=0.8308, Recall=0.7714, F1=0.8000 \n",
      "\n",
      "Epoch 86/100: Train: Loss=-0.4066, Acc=0.9906, Precision=0.9906, Recall=0.9906, F1=0.9906\n",
      "Val: Loss=-0.1244, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060 \n",
      "\n",
      "Epoch 87/100: Train: Loss=-0.4070, Acc=0.9894, Precision=0.9894, Recall=0.9894, F1=0.9894\n",
      "Val: Loss=-0.1262, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060 \n",
      "\n",
      "Epoch 88/100: Train: Loss=-0.4060, Acc=0.9906, Precision=0.9906, Recall=0.9906, F1=0.9906\n",
      "Val: Loss=-0.1248, Acc=0.8176, Precision=0.8308, Recall=0.7714, F1=0.8000 \n",
      "\n",
      "Epoch 89/100: Train: Loss=-0.4043, Acc=0.9917, Precision=0.9917, Recall=0.9917, F1=0.9917\n",
      "Val: Loss=-0.1225, Acc=0.8176, Precision=0.8308, Recall=0.7714, F1=0.8000 \n",
      "\n",
      "Epoch 90/100: Train: Loss=-0.4090, Acc=0.9917, Precision=0.9918, Recall=0.9917, F1=0.9917\n",
      "Val: Loss=-0.1236, Acc=0.8176, Precision=0.8308, Recall=0.7714, F1=0.8000 \n",
      "\n",
      "Epoch 91/100: Train: Loss=-0.4203, Acc=0.9941, Precision=0.9941, Recall=0.9941, F1=0.9941\n",
      "Val: Loss=-0.1275, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060 \n",
      "\n",
      "Epoch 92/100: Train: Loss=-0.4154, Acc=0.9917, Precision=0.9918, Recall=0.9917, F1=0.9917\n",
      "Val: Loss=-0.1270, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060 \n",
      "\n",
      "Epoch 93/100: Train: Loss=-0.4055, Acc=0.9894, Precision=0.9894, Recall=0.9894, F1=0.9894\n",
      "Val: Loss=-0.1276, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060 \n",
      "\n",
      "Epoch 94/100: Train: Loss=-0.4197, Acc=0.9929, Precision=0.9929, Recall=0.9929, F1=0.9929\n",
      "Val: Loss=-0.1279, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060 \n",
      "\n",
      "Epoch 95/100: Train: Loss=-0.4136, Acc=0.9929, Precision=0.9929, Recall=0.9929, F1=0.9929\n",
      "Val: Loss=-0.1274, Acc=0.8176, Precision=0.8308, Recall=0.7714, F1=0.8000 \n",
      "\n",
      "Epoch 96/100: Train: Loss=-0.4200, Acc=0.9953, Precision=0.9953, Recall=0.9953, F1=0.9953\n",
      "Val: Loss=-0.1275, Acc=0.8176, Precision=0.8308, Recall=0.7714, F1=0.8000 \n",
      "\n",
      "Epoch 97/100: Train: Loss=-0.4236, Acc=0.9941, Precision=0.9941, Recall=0.9941, F1=0.9941\n",
      "Val: Loss=-0.1280, Acc=0.8176, Precision=0.8308, Recall=0.7714, F1=0.8000 \n",
      "\n",
      "Epoch 98/100: Train: Loss=-0.4247, Acc=0.9941, Precision=0.9941, Recall=0.9941, F1=0.9941\n",
      "Val: Loss=-0.1275, Acc=0.8176, Precision=0.8308, Recall=0.7714, F1=0.8000 \n",
      "\n",
      "Epoch 99/100: Train: Loss=-0.4182, Acc=0.9929, Precision=0.9929, Recall=0.9929, F1=0.9929\n",
      "Val: Loss=-0.1275, Acc=0.8176, Precision=0.8308, Recall=0.7714, F1=0.8000 \n",
      "\n",
      "Epoch 100/100: Train: Loss=-0.4284, Acc=0.9929, Precision=0.9929, Recall=0.9929, F1=0.9929\n",
      "Val: Loss=-0.1304, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060 \n",
      "\n",
      "Test: Loss=-0.1304, Acc=0.8243, Precision=0.8438, Recall=0.7714, F1=0.8060, Cohen Kappa=0.6461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAIhCAYAAADejQtoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9m0lEQVR4nO3deViU5f7H8c+AjmiYC4xpbpgLmoIiLqkYHjUzs5PoMamTFJlJKb/cWlxScfdYdnJJkVLDzCUtT5pZmW3HcjtHM00TtVJcEtwKQRCY3x9dzmlCk0HGwbnfr665Lud+nnme7/hH19fPfT/3WOx2u10AAAAwho+nCwAAAMD1RQMIAABgGBpAAAAAw9AAAgAAGIYGEAAAwDA0gAAAAIahAQQAADAMDSAAAIBhaAABAAAMQwMI3AD27dunESNGqGPHjgoJCVFYWJiioqKUlJSks2fPuvXe3333nR5++GGFh4crODhYixYtKvZ7BAcHa9asWcV+3at55513FBwcrODgYG3ZsqXAcbvdrrvuukvBwcHq27dvke6xZMkSvfPOOy59ZsuWLVesCQCKQylPFwDgz61YsUIJCQmqU6eO+vXrp3r16ik3N1e7d+/WsmXLtHPnTs2ZM8dt9x85cqSysrI0Y8YMVahQQdWrVy/2eyxfvlxVq1Yt9usW1k033aSVK1eqdevWTuNbt27V4cOHddNNNxX52kuXLlWlSpXUs2fPQn+mcePGWr58uerVq1fk+wLAn6EBBEqwHTt2aNy4cWrbtq1effVVWa1Wx7F27dopNjZWX375pVtrSElJUe/evRUZGem2ezRr1sxt1y6Mbt26ac2aNRo7dqz8/f0d4ytXrlRYWJgyMjKuSx0XL16UxWKRv7+/x/9OAHg3poCBEiwxMVEWi0UTJkxwav4usVqt6tSpk+N9fn6+kpKS1LVrVzVp0kRt2rTRs88+qxMnTjh9rm/fvurevbt27dqlhx56SE2bNlWnTp00f/585efnS/rf9Ghubq6WLl3qmCqVpFmzZjn+/HuXPpOamuoY+/rrr9W3b1+1bt1aoaGh6tChg+Lj45WVleU453JTwPv379eTTz6pli1bKiQkRPfff7/effddp3MuTZWuXbtWL7/8siIiItS8eXM9+uijOnToUGH/mnXvvfdKktauXesY+/XXX/XRRx+pV69el/3M7Nmz1bt3b7Vq1UrNmzdXVFSU3n77bdntdsc5HTt2VEpKirZu3er4++vYsaNT7atXr9bUqVPVvn17hYSE6KeffiowBXz69GlFRkYqOjpaFy9edFz/wIEDatasmZ555plCf1cAkEgAgRIrLy9PmzdvVuPGjVWtWrVCfWbcuHFavny5Hn74YXXo0EFHjx7VK6+8oq1bt+qdd95R5cqVHeempaXpmWeeUWxsrAYNGqSPP/5YL730kqpUqaIePXqoQ4cOWr58ufr06aO7775bjz32mMvfITU1VQMGDFCLFi00adIk3Xzzzfr555/15Zdf6uLFiypbtuxlP3fo0CFFR0crICBAo0aNUqVKlfTee+/p+eefV3p6uvr37+90/owZM9S8eXNNmjRJGRkZevHFF/Xkk09q3bp18vX1vWqd/v7+uvvuu7Vq1SpFR0dL+q0Z9PHx0T333KM33nijwGeOHj2qPn366NZbb5Uk7dy5UxMnTtTPP/+sQYMGSfqtSfy///s/lS9fXmPHjpWkAo38jBkz1KxZMyUkJMjHx0cBAQFKT093Oqdy5cqaMWOGYmJi9OKLL2rEiBHKysrS008/rWrVqikhIeGq3xEAfo8GECihzpw5o6ysLNWoUaNQ5x88eFDLly/XQw89pBdeeMExfvvtt6t379564403NGTIEMf42bNnlZSUpNDQUElS27ZttXXrVq1Zs0Y9evRQ5cqVHQ1jYGBgkaYk9+zZo+zsbD377LNq2LChY/y+++7708/Nnj1bFy9eVHJysqP5jYyM1C+//KI5c+YoOjpa5cuXd5xfr149vfjii473Pj4+Gjx4sL799ttC192rVy/FxMQoJSVF9evX16pVq9S1a1enKeHfmzJliuPP+fn5atWqlex2u5KTkzVw4EBZLBbdfvvt8vPz+9Mp3Vq1amnmzJlXrS88PFyDBw/Wiy++qJYtW2rDhg1KTU3VihUrVK5cuUJ9RwC4hClgwEtcmi6MiopyGg8NDVXdunX19ddfO43bbDZH83dJcHCwjh07Vmw1NWrUSKVLl9YLL7ygd999V0eOHCnU5zZv3qw2bdoUSD6joqKUlZWlHTt2OI1fmla95NL0tCvfpVWrVqpVq5ZWrVql77//Xt9+++0Vp3+l36a2H330UYWHh6tRo0Zq3LixZs6cqbNnz+rUqVOFvm+XLl0Kfe7jjz+uDh06aOjQoXr33Xc1evToy07FA8DV0AACJVSlSpVUtmxZp/V0f+bSdjBVqlQpcKxKlSoFtoupWLFigfOsVquys7NdLfWKatWqpUWLFikgIEDjx49X586d1blz58tOqf7e2bNnZbPZCoxf+m5X+y6XplkvXLhQ6FotFot69uyp9957T8uWLVNQUJBatGhx2XN37dqlfv36SZImTJigpUuXauXKlYqLi3P5vpf7nn9WY1RUlLKzs2Wz2XT//fcX+rMA8Hs0gEAJ5evrqzvuuEN79uwp8BDH5Vxqgk6ePFng2MmTJ1WpUqViq61MmTKSpJycHKfxM2fOFDi3RYsWmjdvnrZv364VK1aoWbNmmjx5st5///0rXr9ixYpKS0srMH7puxXnd/m9nj176syZM1q2bNmfpn/vv/++SpUqpcTERHXr1k3NmzdXSEhIke5psVgKfe7Jkyc1fvx4NWrUSGfPntU//vGPIt0TAGgAgRJswIABstvtGj16dIFmS/pt25CNGzdKku644w5J0nvvved0zq5du3Tw4EHH8eJwaS/Affv2OY1/+umnV/yMr6+vmjZt6ngYYs+ePVc8t02bNtq8ebN+/vlnp/F//etfKlu2rNu2SLnlllvUr18//eUvf1GPHj2ueJ7FYpGvr698fP73v9ALFy4U+LuXfksjXUkEryQvL0/Dhg2TxWJRUlKShg4dqsWLF+ujjz665msDMA8PgQAlWFhYmMaNG6eEhAT16tVL0dHRql+/vnJzc/Xdd99pxYoVql+/vjp27KjbbrtNffr00ZtvvikfHx/deeedjqeAq1WrpkcffbTY6oqMjFTFihU1atQoPf300/L19dW7776r48ePO523dOlSbd68WR06dFC1atWUnZ2tVatWSfrtoZMrGThwoD799FPFxMRo4MCBqlChgtasWaPPPvtMzzzzjNMDIMVt+PDhVz0nMjJSCxcu1LBhw9SnTx+dPXtWr7/++mW36mnQoIHef/99rVu3TjVq1FCZMmWKtG5v5syZ2r59uxYsWCCbzabHHntMW7du1ahRo9SoUSPVrFnT5WsCMBcNIFDCPfDAAwoNDdWiRYv02muvKS0tTaVLl1ZQUJC6d++uhx9+2HHuuHHjVLNmTa1cuVJvvfWW/P391b59ew0bNqxYp039/f2VlJSkyZMnOxqy3r17q3379ho9erTjvEaNGmnTpk2aNWuW0tLSVK5cOTVo0EBz585VRETEFa9/2223admyZZoxY4bGjx+vCxcuqG7dupoyZYpLv6jhLm3atNHkyZOVlJSkuLg43XLLLXrggQdUuXJljRo1yunc+Ph4paWlafTo0Tp//ryqV6/uSG0La9OmTZo/f76eeuoptWnTxjE+depURUVFaciQIXrrrbcu24ACwOVY7L/ftRQAAABejzWAAAAAhqEBBAAAMAwNIAAAgGFoAAEAAAxDAwgAAGAYGkAAAADD0AACAAAYxis3gi4bNsjTJQBwkzPbZnu6BABu4ufBrsSdvUPWjpL3/y0SQAAAAMN4ZQIIAADgEotZmRgNIAAAgMXi6QquK7PaXQAAAJAAAgAAmDYFbNa3BQAAAAkgAAAAawABAADg1UgAAQAAWAMIAAAAb0YCCAAAYNgaQBpAAAAApoABAADgzUgAAQAADJsCJgEEAAAwDAkgAAAAawABAADgzUgAAQAAWAMIAAAAb0YCCAAAYNgaQBpAAAAApoABAADgzUgAAQAADJsCNuvbAgAAgAQQAACABBAAAABejQQQAADAh6eAAQAA4MVIAAEAAAxbA0gDCAAAwEbQAAAA8GYkgAAAAIZNAZv1bQEAAEACCAAAwBpAAAAAeDUSQAAAANYAAgAAwJuRAAIAABi2BpAGEAAAgClgAAAAeDMSQAAAAMOmgEkAAQAADEMCCAAAwBpAAAAAeDMSQAAAANYAAgAAwJuRAAIAABi2BpAGEAAAwLAG0KxvCwAAABJAAAAAHgIBAACAVyMBBAAAYA0gAAAAvBkJIAAAAGsAAQAA4M1IAAEAAAxbA0gDCAAAwBQwAAAAvBkJIAAAMJ6FBBAAAACe8vPPP2v48OFq3bq1mjZtqvvvv1+7d+92HLfb7Zo1a5YiIiIUGhqqvn37KiUlxaV7kAACAADjlZQE8Ny5c3rwwQfVunVrJSUlqXLlyjpy5IhuvvlmxzlJSUlauHChpk6dqqCgIM2dO1exsbFav369/P39C3UfGkAAAAA3ysnJUU5OjtOY1WqV1WotcG5SUpKqVq2qKVOmOMZq1Kjh+LPdbldycrLi4uLUpUsXSdK0adPUtm1brV27VtHR0YWqiSlgAAAAi/teiYmJCg8Pd3olJiZetoyNGzeqSZMm+r//+z+1adNGPXr00IoVKxzHU1NTlZaWpoiICMeY1WpVy5YttWPHjkJ/XRJAAAAANxowYIBiY2Odxi6X/knSkSNHtHTpUsXGxiouLk67du3SxIkTZbVa1aNHD6WlpUmSAgICnD4XGBioY8eOFbomGkAAAGA8d64BvNJ07+XY7XY1adJEQ4cOlSTdfvvtOnDggJYuXaoePXo4zvtjvXa73aWamAIGAADGs1gsbnu5wmazqW7duk5jt912myPds9lskqT09HSnc06dOqXAwMBC34cGEAAAoIRo3ry5fvjhB6exH3/8UdWrV5f02wMhNptNmzZtchzPycnRtm3bFBYWVuj70AACAADjlZQE8JFHHtE333yjefPm6aefftKaNWu0YsUKPfTQQ446Y2JilJiYqI8//lj79+/XiBEj5Ofnp+7duxf6PqwBBAAAKCFCQ0M1e/ZszZgxQ3PmzFGNGjU0cuRI/fWvf3Wc079/f2VnZyshIUHnzp1T06ZNtWDBgkLvAShJFrurqwZvAGXDBnm6BABucmbbbE+XAMBN/DwYS1V4cLHbrn1uaV+3XbuomAIGAAAwDFPAAAAAJeOX4K4bEkAAAADDkAACAADjuXMj6JKIBBAAAMAwJIAAAMB4piWANIAAAMB4pjWATAEDAAAYhgQQAAAYjwQQAAAAXo0EEAAAwKwAkAQQAADANCSAAADAeKwBBAAAgFcjAQQAAMYzLQGkAQQAAMYzrQFkChgAAMAwJIAAAABmBYAkgAAAAKYhAQQAAMZjDSAAAAC8GgkgAAAwHgkgAAAAvBoJIAAAMJ5pCSANIAAAMJ5pDSBTwAAAAIYhAQQAADArACQBBAAAMA0JIAAAMB5rAAEAAODVSAABAIDxSAABAADg1UgAAQCA8UxLAGkAAQAAzOr/mAIGAAAwDQkgAAAwnmlTwCSAAAAAhiEBBAAAxiMBBAAAgFejAcQN4VZbBS2YGKPUT6fp1FcztHnZ8wprVNNx/KayVr38XG8dWD9Bp7+eoR2rRqt/7wgPVgygsP6zfZvin4pT5w4Rato4WBs/2eB03G63a+6cWercIUKtmoeq36N9deBAioeqhbeyWCxue5VETAGjxKtYvqw2Lhqqz7elqMegV3Xy9K+6rWagzv6a5TjnH8N7KbJFA8WOStZPx06pc5tGemXEAzqedk5rP/vWg9UDuJqsrEwFBwfr/qieGjY4vsDxha8nafEbCzV+0lTVDgpSUuJcxT0eq3+9v1433eTvgYqBGx8NIEq8YbF3KfXEGQ0Y96Zj7PDx007ntA6tozfXbtGX//ktFVjwzib169VOzW+vRQMIlHAR7SMV0T7yssfsdruWLE7W40/EqfNdXSRJEydPU8c722rd+2vV+4Ho61kqvFhJTercxaMN4IkTJ7R06VL997//VXp6uiwWiwICAtS8eXNFR0erWrVqniwPJcS9kSHa8NVeLfnHY4oIr69jJ89q/oovtfDdrxznfLXzkLpHhih59dc6lnZOd7aor/q1q+iZ6Ss9WDmAa3U0NVXp6Wlq0+5/SzqsVqvCW7TUNzt20ACi+JjV/3muAdy+fbv69++vatWqqV27dgoMDJTdbtepU6e0YcMGLV68WElJSQoPD/dUiSgh6lQPVP/e7TXzzY36x+sfqUWT2nrp2b8p+2Ku3lq7VZI0bNrbenXMQzr40SRdvJinfHu+nhz/lr7aecjD1QO4FunpaZKkgIAAp/GAgEAdO3bMEyUBXsFjDeCUKVPUu3dvjRw58rLHJ0+erMmTJ2vVqlXXuTKUND4+Fv33u8MaO3uNJOmb71N1e91qeqJ3e0cDOPDBDmoVEqReT8/T4eOnFdG8nl4Z0Ucn0n/Rp1u+92T5AIrBH6fn7Ha7DJuxg5uZNgXssaeAU1JSFB195ei+T58+SknhKS9IJ9J/0d5DJ5zG9v1wQjWrVpIk+ZUprYT4+/TcS+9o3Re7tTvlmOYt/0IrP/qvBvft5ImSARSTwECbJCk9Pd1p/PTpUwoICPRESYBX8FgDaLPZtGPHjise37lzp2w223WsCCXV1zsPqUHtKk5j9WtVcTwIUrqUr6ylSynfbnc6Jy8vXz4+Zv2LDvA21WvUUGCgTZu/2uQYu5iTo/9s36amYWEerAzehm1grpPHHntMY8eO1Z49e9S2bVsFBgbKYrEoLS1NX331ld5+++0rTg/DLLPe3KhPFw3TM4910aqP/6uWjYP0WK92GjRhqSTp1/MX9MX2FE0e3ENZFy7q8PHTah9eT3/v3krPzXjHw9UDuJrM8+d1+PBhx/ujqanat3evKlSooGq33qq/943R60mJqlU7SLVq19br8xPl5+enbvd292DVwI3NYrf/ITa5jtatW6dFixZpz549ysvLkyT5+vqqcePGevTRR9WtW7ciXbds2KDiLBMlwD3tm2h8/F9Vr5ZNPx49pZlvbnR6CviWgPIaH3+/OrdpqEo3l9Ph46e14J2vNPPNjR6sGu5wZttsT5eAYrZt6xY9HhtTYPyv90dpwuSpstvtmvfqbK1csVy//HJOIaFNNWL0GNWv38AD1cKd/Dy4N0m94R+47doHXrzHbdcuKo82gJdcvHhRZ86ckSRVqlRJpUuXvqbr0QAC3osGEPBeNIDXT4nYCLp06dKqUqXK1U8EAABwg5K6Vs9dSkQDCAAA4EmG9X+eewoYAAAAnkECCAAAjGfaFDAJIAAAgGFIAAEAgPEMCwBJAAEAAExDAggAAIxn2k+HkgACAAAYhgQQAAAYz7Q1gDSAAADAeGwDAwAAAK9GAggAAIxnWABIAggAAGAaEkAAAGA81gACAADAq5EAAgAA45EAAgAAwKvRAAIAAONZLO57uWLWrFkKDg52erVr185x3G63a9asWYqIiFBoaKj69u2rlJQUl78vU8AAAMB4JWkKuH79+lq4cKHjva+vr+PPSUlJWrhwoaZOnaqgoCDNnTtXsbGxWr9+vfz9/Qt9DxJAAACAEsTX11c2m83xqly5sqTf0r/k5GTFxcWpS5cuatCggaZNm6YLFy5o7dq1Lt2DBhAAABjPnVPAOTk5ysjIcHrl5ORcsZaffvpJERER6tixo4YMGaIjR45IklJTU5WWlqaIiAjHuVarVS1bttSOHTtc+r5MAQMAALhRYmKiZs+e7TQ2aNAgxcfHFzg3NDRU06ZNU1BQkE6dOqW5c+cqOjpaa9euVVpamiQpICDA6TOBgYE6duyYSzXRAAIAAOO5cw3ggAEDFBsb6zRmtVove25kZKTT+2bNmumuu+7S6tWr1bRpU0kFa7Xb7S7XxBQwAACAG1mtVvn7+zu9rtQA/lG5cuXUoEED/fjjj7LZbJKk9PR0p3NOnTqlwMBAl2qiAQQAAMYrKdvA/FFOTo4OHjwom82mGjVqyGazadOmTU7Ht23bprCwMJeuyxQwAABACTFt2jT95S9/UbVq1XT69GnNnTtXGRkZioqKksViUUxMjBITExUUFKTatWsrMTFRfn5+6t69u0v3oQEEAADGKyn7AJ44cUJDhw7V2bNnValSJTVr1kwrVqxQ9erVJUn9+/dXdna2EhISdO7cOTVt2lQLFixwaQ9ASbLYi7JysIQrGzbI0yUAcJMz22Zf/SQANyQ/D8ZSLSd95rZrbxvVwW3XLioSQAAAYLwSEgBeNzSAAADAeCVlCvh64SlgAAAAw5AAAgAA4xkWAJIAAgAAmIYEEAAAGI81gAAAAPBqJIAAAMB4hgWAJIAAAACmIQEEAADGM20NIA0gAAAwnmH9H1PAAAAApiEBBAAAxjNtCpgEEAAAwDAkgAAAwHgkgAAAAPBqJIAAAMB4hgWAJIAAAACmIQEEAADGM20NIA0gAAAwnmH9H1PAAAAApiEBBAAAxjNtCpgEEAAAwDAkgAAAwHiGBYAkgAAAAKYhAQQAAMbzMSwCJAEEAAAwDAkgAAAwnmEBIA0gAAAA28AAAADAq5EAAgAA4/mYFQCSAAIAAJiGBBAAABiPNYAAAADwaiSAAADAeIYFgCSAAAAApiEBBAAAxrPIrAiQBhAAABiPbWAAAADg1UgAAQCA8dgGBgAAAF6NBBAAABjPsACQBBAAAMA0JIAAAMB4PoZFgCSAAAAAhrnmBjAvL0979+7VuXPniqMeAACA685icd+rJHK5AZw0aZLefvttSb81fw8//LCioqLUoUMHbdmypdgLBAAAcDeLxeK2V0nkcgP44YcfqmHDhpKkTz/9VKmpqfrggw8UExOjl19+udgLBAAAQPFyuQE8c+aMbDabJOnzzz9X165dVadOHf3tb3/T/v37i71AAAAAd2MK+CoCAwN14MAB5eXl6csvv1Tbtm0lSRcuXJCvr2+xFwgAAIDi5fI2MD179tTgwYNls9lksVjUrl07SdI333yj2267rdgLBAAAcDfTtoFxuQGMj49X/fr1deLECXXt2lVWq1WS5Ovrq/79+xd7gQAAACheRdoIumvXrgXGoqKirrkYAAAATzAr/ytkA5icnFzoC8bExBS5GAAAALhfoRrARYsWFepiFouFBhAAANxwSup+fe5SqAZw48aN7q4DAADAY3zM6v+K/lNwOTk5OnTokHJzc4uzHgAAALiZyw1gVlaWRo4cqWbNmql79+46fvy4JGnixImaP39+sRcIAADgbvwU3FW89NJL2rdvn5KTk1WmTBnHeJs2bbRu3bpiLQ4AAADFz+VtYD755BO9/PLLatasmdN4vXr1dPjw4eKqCwAA4LopoUGd27icAJ4+fVoBAQEFxrOyskpszAkAAID/cbkBDAkJ0WeffVZgfMWKFQVSQQAAgBuBaWsAXZ4CHjp0qB5//HEdOHBAeXl5Sk5O1oEDB7Rz504tXrzYHTUCAACgGLmcADZv3lxLly7VhQsXVKtWLW3atEkBAQFatmyZmjRp4o4aAQAA3MrH4r5XSVSk3wIODg7WtGnTirsWAAAAjyipU7XuUqQGMC8vTx9//LEOHjwoi8WiunXrqlOnTipVqkiXAwAAwHXkcse2f/9+PfXUU0pPT1edOnUkSUlJSapUqZLmzp2r4ODgYi8SAADAnczK/4rQAI4ePVr16tXTqlWrVKFCBUnSuXPn9Pzzz2vMmDFavnx5sRcJAACA4uNyA7hv3z6n5k+SKlSooCFDhuhvf/tbsRYHAABwPfgYtgbQ5aeA69Spo/T09ALjp06dUu3atYulKAAAAEiJiYkKDg7WpEmTHGN2u12zZs1SRESEQkND1bdvX6WkpLh03UI1gBkZGY7X0KFDNWnSJK1fv14nTpzQiRMntH79ek2ePFnDhw937VsBAACUABaL+15FtWvXLi1fvrzA8xVJSUlauHChxowZo5UrVyowMFCxsbHKyMgo9LULNQXcokULp8ej7Xa7Bg8e7Biz2+2SpLi4OO3du7fQNwcAAEBB58+f1zPPPKOJEydq7ty5jnG73a7k5GTFxcWpS5cukqRp06apbdu2Wrt2raKjowt1/UI1gMnJyUUoHQAA4Mbgzn0Ac3JylJOT4zRmtVpltVqv+Jnx48crMjJSbdu2dWoAU1NTlZaWpoiICKdrtWzZUjt27CjeBrBVq1aFuhgAAACcJSYmavbs2U5jgwYNUnx8/GXPf//99/Xdd99p5cqVBY6lpaVJkgICApzGAwMDdezYsULXVOSdm7OysnTs2DFdvHjRabxhw4ZFvSQAAIBHuPMh4AEDBig2NtZp7Erp3/HjxzVp0iQtWLBAZcqUueI1/5hYXlqOV1guN4CnT5/WiBEj9MUXX1z2OGsAAQDAjcad28Bcbbr39/bs2aNTp06pZ8+ejrG8vDxt27ZNS5Ys0fr16yVJ6enpqlKliuOcU6dOKTAwsNA1ubwNzKRJk3Tu3DktX75cfn5+eu211zR16lTVrl3baY4aAAAArrnjjju0Zs0arV692vFq0qSJ7rvvPq1evVo1a9aUzWbTpk2bHJ/JycnRtm3bFBYWVuj7uJwAbtmyRa+++qpCQ0NlsVh06623ql27dvL391diYqI6dOjg6iUBAAA8qqTsA+3v768GDRo4jZUrV04VK1Z0jMfExCgxMVFBQUGqXbu2EhMT5efnp+7duxf6Pi43gJmZmapcubIkqWLFijp9+rTq1KmjBg0a6LvvvnP1cgAAAHBB//79lZ2drYSEBJ07d05NmzbVggUL5O/vX+hruNwA1qlTRz/88INq1Kihhg0bavny5apRo4aWLVsmm83m6uUAAAA8zp3bwFyrxYsXO723WCyKj4+/4lPEheFyA/jII484HkEeNGiQ+vXrpzVr1qh06dKaOnVqkQsBAADA9WGxu/rc8B9kZWXp0KFDqlatmmNq2NNSz2R7ugQAbhIx7mNPlwDATX58pfBr2Ipb/Lvu28VkVlQjt127qIq8D+AlZcuWVePGjYujFgAAAFwHhWoAp0yZUugLjhgxosjFAAAAeEJJXgPoDoVqAAv7dK9pf3kAAMA7+BjWwhSqAfzj0ycAAAC4cV3zGkAAAIAbnWkJoMs/BQcAAIAbGwkgAAAwnmnPMZAAAgAAGIYEEAAAGI81gIWwevVqRUdHKyIiQkePHpUkLVq0SBs2bCjW4gAAAFD8XG4A33rrLU2dOlWRkZH69ddflZ+fL0m6+eab9cYbbxR7gQAAAO5msbjvVRK53AC++eabmjhxop588kn5+Pzv402aNNH+/fuLtTgAAIDrwcdicdurJHK5AUxNTVWjRgV/1NhqtSorK6tYigIAAID7uNwA1qhRQ3v37i0w/sUXX6hevXrFUhQAAMD15OPGV0nk8lPA/fr10/jx45WTkyNJ2rVrl9auXav58+dr4sSJxV4gAAAAipfLDWCvXr2Ul5en6dOnKysrS8OGDdMtt9yikSNH6t5773VHjQAAAG5VQpfquU2R9gF84IEH9MADD+j06dOy2+0KCAgo7roAAADgJte0EXTlypWLqw4AAACPKalP67qLyw1gx44d//T38j755JNrKggAAADu5XID+Mgjjzi9z83N1Xfffad///vf6tevX7EVBgAAcL0YFgBeewN4yZIlS7R79+5rLggAAOB647eAi+jOO+/Uhx9+WFyXAwAAgJtc00Mgv7d+/XpVrFixuC4HAABw3fAQyFX06NHD6SEQu92u9PR0nT59WmPHji3W4gAAAFD8XG4AO3fu7PTeYrGocuXKatWqlerWrVtshQEAAFwvhgWArjWAubm5ql69uiIiImSz2dxVEwAAANzIpYdASpUqpXHjxjl+BxgAAMAb+Fjc9yqJXH4KODQ0VHv37nVHLQAAALgOXF4D+NBDD2nq1Kk6ceKEGjdurLJlyzodb9iwYbEVBwAAcD1YVEKjOjcpdAM4YsQIjRo1SkOGDJEkTZw40XHMYrHIbrfLYrGQDgIAgBtOSZ2qdZdCN4CrV6/W8OHD+a1fAACAG1yhG0C73S5Jql69utuKAQAA8ATTEkCXHgKxmLZJDgAAgBdy6SGQu++++6pN4NatW6+pIAAAgOvNtJDLpQYwPj5e5cuXd1ctAAAAuA5cagDvvfdeBQQEuKsWAAAAj2AN4BWYFo0CAAB4K5efAgYAAPA2puVchW4A9+3b5846AAAAPMbHsA7Q5d8CBgAAwI3N5d8CBgAA8DY8BAIAAACvRgIIAACMZ9gSQBJAAAAA05AAAgAA4/nIrAiQBBAAAMAwJIAAAMB4pq0BpAEEAADGYxsYAAAAeDUSQAAAYDx+Cg4AAABejQQQAAAYz7AAkAQQAADANCSAAADAeKwBBAAAgFcjAQQAAMYzLACkAQQAADBtStS07wsAAGA8EkAAAGA8i2FzwCSAAAAAhiEBBAAAxjMr/yMBBAAAMA4JIAAAMB4bQQMAAMCrkQACAADjmZX/0QACAAAY90sgTAEDAAAYhgYQAAAYz2KxuO3lirfeekv33XefmjdvrubNm6tPnz76/PPPHcftdrtmzZqliIgIhYaGqm/fvkpJSXH5+9IAAgAAlBBVq1bV8OHDtWrVKq1atUp33HGHBg4c6GjykpKStHDhQo0ZM0YrV65UYGCgYmNjlZGR4dJ9aAABAIDxfNz4ysnJUUZGhtMrJyfnsnV07NhRkZGRqlOnjurUqaMhQ4aoXLly2rlzp+x2u5KTkxUXF6cuXbqoQYMGmjZtmi5cuKC1a9e6/H0BAADgJomJiQoPD3d6JSYmXvVzeXl5ev/995WZmamwsDClpqYqLS1NERERjnOsVqtatmypHTt2uFQTTwEDAADjubpWzxUDBgxQbGys05jVar3i+d9//72io6OVnZ2tcuXKac6cOapXr57++9//SpICAgKczg8MDNSxY8dcqokGEAAAwI2sVuufNnx/VKdOHa1evVq//PKLPvroIz333HN68803Hcf/2Kza7XaXa6IBBAAAxitJ2wBarVbVrl1bkhQSEqJvv/1WycnJ6t+/vyQpPT1dVapUcZx/6tQpBQYGunQP1gACAACUYHa7XTk5OapRo4ZsNps2bdrkOJaTk6Nt27YpLCzMpWuSAAIAAOO5cw2gK2bMmKE777xTVatW1fnz57Vu3Tpt3bpVr732miwWi2JiYpSYmKigoCDVrl1biYmJ8vPzU/fu3V26Dw0gAAAwXkmZEk1PT9ezzz6rkydPqnz58goODtZrr72mdu3aSZL69++v7OxsJSQk6Ny5c2ratKkWLFggf39/l+5jsRdl5WAJl3om29MlAHCTiHEfe7oEAG7y4yuupVjF6Z1vjrvt2j2bVnPbtYuKBBAAABivpEwBXy8lJfEEAADAdUICCAAAjGdW/kcCCAAAYBwSQAAAYDzDlgCSAAIAAJiGBBAAABjPx7BVgDSAAADAeEwBAwAAwKuRAAIAAONZDJsCJgEEAAAwDAkgAAAwHmsAAQAA4NVIAAEAgPFM2waGBBAAAMAwJIAAAMB4pq0BpAEEAADGM60BZAoYAADAMCSAAADAeGwEDQAAAK9GAggAAIznY1YASAIIAABgGhJAAABgPNYAAgAAwKuRAAIAAOOZtg8gDSAAADAeU8AAAADwaiSAAADAeGwDAwAAAK9GAggAAIzHGkAAAAB4NRJA3BB27diu5W8uUsr3e3UqPU0J0/6piMiOTuf89MMhJc15Wbt2/Ef59nwF1amrFya9qFuqVvNQ1QCuZnDXBhp8TwOnsbRfLqjlCxsKnDv5gRA91K62xr+zRws+/+F6lQhDsA0MUAJlZWWpbv1gde3eQ+NGDC1w/FjqET094BHdc1+UHun/lG7yL6/DPx6S1Wr1QLUAXPH98V/08Jwtjvd5+fYC53QJuUXNalfUibMXrmdpgNeiAcQNoXXb9mrdtv0Vj78+b5Zat22vAfH/aw5vrV7jepQG4Brl5dmV9mv2FY/fUsFPCX9ropi5W7TwiVbXsTKYxLAAkAYQN778/Hxt+eoL9Xk4Vs89HacD+/eqarXqevCRxwtMEwMoeYJsN2nL+M7Kyc3Xzp/O6B9rv9eRU5mSfpuWe/nhZpq/8ZBSTmR4uFJ4Mx/D5oBL9EMgx48f14gRIzxdBkq4s2dOKyszU8uSX1fLO9pp2iuJiujQSeOeH6Jv/rvd0+UB+BM7fzqjoUt2KmbuFj2/bJds5f30zuC2qliutCTpyU51lZtv10LW/AHFqkQ3gOfOndPq1as9XQZKuPz8fElS2zv/or892Ff1GjTUgzH9dEe7O7Xm3RUerg7An/lsb5rWf3NC3x//VZv2pyt2/lZJUq9WNdSkRgXFRtbR8CU7PVskjGBx46sk8ugU8CeffPKnx48cOXKdKsGNrELFSvL1LaXaQXWdxmsF3abd3+zwUFUAiiIrJ0/7jv+qOrabZLdLAf5l9NW4To7jpXx9NKrH7Xosso4ixm/0YKXAjc2jDeDAgQNlsVhktxd84usSi2Fz8nBd6dKlFXx7Yx05/KPTeOqRn3RLNbaAAW4kVl8f1bvFX9sOntY721L17/3pTseT41rr3e2pensLAQGKmWHthkcbQJvNprFjx6pz586XPb5371717NnzOleFkigrM1NHUw873p84dlQH9u9T+Zsr6Jaq1dTn749qwuhnFNqsuZqFt9K2zZv09b8/14w5r3uwagBXM/L+Rvpk9886eiZLgeXLaFCX+vL3K6VVW1N1NvOizmZedDo/Ny9fab9k69DJ8x6qGPAOHm0AGzdurD179lyxAbxaOghzfL93j4YN7Od4P/eV6ZKkLt3+qufGTFREh04a/NwLWvrG65r98jTVrBWkcVNmKKRZc0+VDKAQqlX008xHmqvSTVadzsjRjp/OKGrGJh09k+Xp0mAY034KzmL3YIe1fft2ZWZm6s4777zs8czMTO3evVutWrm271PqmSvvJwXgxhYx7mNPlwDATX58pbvH7r3l4Dm3Xbt13Qpuu3ZReTQBbNGixZ8eL1eunMvNHwAAgKtMe+SAjaABAIDxDOv/SvY+gAAAACh+JIAAAACGRYAkgAAAAIYhAQQAAMYzbRsYEkAAAADDkAACAADjmbYNDAkgAACAYUgAAQCA8QwLAGkAAQAATOsAmQIGAAAwDAkgAAAwHtvAAAAAwKuRAAIAAOOxDQwAAAC8GgkgAAAwnmEBIAkgAACAaUgAAQAADIsAaQABAIDx2AYGAAAAXo0EEAAAGI9tYAAAAODVSAABAIDxDAsASQABAABMQwIIAABgWARIAggAAFBCJCYmqlevXgoLC1ObNm301FNP6dChQ07n2O12zZo1SxEREQoNDVXfvn2VkpLi0n1oAAEAgPEsbvzPFVu3btXf//53rVixQgsXLlReXp769eunzMxMxzlJSUlauHChxowZo5UrVyowMFCxsbHKyMgo9H1oAAEAAEqI119/XT179lT9+vXVsGFDTZkyRceOHdOePXsk/Zb+JScnKy4uTl26dFGDBg00bdo0XbhwQWvXri30fWgAAQCA8SwW971ycnKUkZHh9MrJySlUXb/++qskqUKFCpKk1NRUpaWlKSIiwnGO1WpVy5YttWPHjkJ/XxpAAABgPIsbX4mJiQoPD3d6JSYmXrUmu92uKVOmKDw8XA0aNJAkpaWlSZICAgKczg0MDFR6enqhvy9PAQMAALjRgAEDFBsb6zRmtVqv+rnx48dr//79euuttwocs/zhp0vsdrtLNdEAAgAAuHEbGKvVWqiG7/cmTJigjRs36s0331TVqlUd4zabTZKUnp6uKlWqOMZPnTqlwMDAQl+fKWAAAIASwm63a/z48froo4/0xhtvqGbNmk7Ha9SoIZvNpk2bNjnGcnJytG3bNoWFhRX6PiSAAADAeK5u1+IuCQkJWrt2rV599VXddNNNjjV/5cuXl5+fnywWi2JiYpSYmKigoCDVrl1biYmJ8vPzU/fu3Qt9HxpAAACAEmLp0qWSpL59+zqNT5kyRT179pQk9e/fX9nZ2UpISNC5c+fUtGlTLViwQP7+/oW+j8Xu6qrBG0DqmWxPlwDATSLGfezpEgC4yY+vFD7BKm7fn8i8+klFFFy1nNuuXVSsAQQAADAMU8AAAMB4JWMF4PVDAwgAAGBYB8gUMAAAgGFIAAEAgPFKyjYw1wsJIAAAgGFIAAEAgPEsZgWAJIAAAACmIQEEAADGMywAJAEEAAAwDQkgAACAYREgDSAAADAe28AAAADAq5EAAgAA47ENDAAAALwaCSAAADCeYQEgCSAAAIBpSAABAAAMiwBJAAEAAAxDAggAAIxn2j6ANIAAAMB4bAMDAAAAr0YCCAAAjGdYAEgCCAAAYBoSQAAAYDzWAAIAAMCrkQACAAAYtgqQBBAAAMAwJIAAAMB4pq0BpAEEAADGM6z/YwoYAADANCSAAADAeKZNAZMAAgAAGIYEEAAAGM9i2CpAEkAAAADDkAACAACYFQCSAAIAAJiGBBAAABjPsACQBhAAAIBtYAAAAODVSAABAIDx2AYGAAAAXo0EEAAAwKwAkAQQAADANCSAAADAeIYFgCSAAAAApiEBBAAAxjNtH0AaQAAAYDy2gQEAAIBXIwEEAADGM20KmAQQAADAMDSAAAAAhqEBBAAAMAxrAAEAgPFYAwgAAACvRgIIAACMZ9o+gDSAAADAeEwBAwAAwKuRAAIAAOMZFgCSAAIAAJiGBBAAAMCwCJAEEAAAwDAkgAAAwHimbQNDAggAAGAYEkAAAGA89gEEAACAVyMBBAAAxjMsAKQBBAAAMK0DZAoYAADAMDSAAADAeBY3/ueqbdu2KS4uThEREQoODtaGDRucjtvtds2aNUsREREKDQ1V3759lZKS4tI9aAABAABKkMzMTAUHB2vMmDGXPZ6UlKSFCxdqzJgxWrlypQIDAxUbG6uMjIxC34M1gAAAwHglaRuYyMhIRUZGXvaY3W5XcnKy4uLi1KVLF0nStGnT1LZtW61du1bR0dGFugcJIAAAgBvl5OQoIyPD6ZWTk1Oka6WmpiotLU0RERGOMavVqpYtW2rHjh2Fvo5XJoA1KpXxdAkA3OTHV7p7ugQAXsjPjR3RrFmJmj17ttPYoEGDFB8f7/K10tLSJEkBAQFO44GBgTp27Fihr+OVDSAAAEBJMWDAAMXGxjqNWa3Wa7qm5Q9z1na73aXP0wACAAC4kdVqveaG7xKbzSZJSk9PV5UqVRzjp06dUmBgYKGvwxpAAACAG0SNGjVks9m0adMmx1hOTo62bdumsLCwQl+HBBAAAKAEOX/+vA4fPux4n5qaqr1796pChQq69dZbFRMTo8TERAUFBal27dpKTEyUn5+funcv/Bppi93VSWMAAAC4zZYtWxQTE1NgPCoqSlOnTpXdbtfs2bO1fPlynTt3Tk2bNtWYMWPUoEGDQt+DBhAAAMAwrAEEAAAwDA0gAACAYWgAAQAADEMDCAAAYBgaQNzQlixZoo4dOyokJEQ9e/bU9u3bPV0SgGu0bds2xcXFKSIiQsHBwdqwYYOnSwK8Dg0gbljr1q3TlClT9OSTT2r16tUKDw9X//79XfotRAAlT2ZmpoKDgzVmzBhPlwJ4LbaBwQ2rd+/euv3225WQkOAYu+eee9S5c2cNGzbMg5UBKC7BwcGaM2eOOnfu7OlSAK9CAogbUk5Ojvbs2aOIiAin8Xbt2mnHjh0eqgoAgBsDDSBuSGfOnFFeXp4CAgKcxgMDA5WWluahqgAAuDHQAOKGZrFYnN7b7fYCYwAAwBkNIG5IlSpVkq+vr9LT053GT506pcDAQA9VBQDAjYEGEDckq9Wqxo0ba9OmTU7jX331lcLCwjxUFQAAN4ZSni4AKKrY2Fg9++yzatKkicLCwrR8+XIdP35c0dHRni4NwDU4f/68Dh8+7HifmpqqvXv3qkKFCrr11ls9WBngPdgGBje0JUuW6PXXX9fJkyfVoEEDjRgxQi1btvR0WQCuwZYtWxQTE1NgPCoqSlOnTvVARYD3oQEEAAAwDGsAAQAADEMDCAAAYBgaQAAAAMPQAAIAABiGBhAAAMAwNIAAAACGoQEEAAAwDA0gAACAYWgAAVyzWbNm6f7773e8f/755/XUU09d9zpSU1MVHBysvXv3XvGcjh07atGiRYW+5jvvvKMWLVpcc23BwcHasGHDNV8HAIoDvwUMeKnnn39e7777riSpVKlSqlq1qrp06aL4+HiVK1fOrfceNWqUCvsjQ6mpqerUqZNWr16tRo0aubUuAMBvaAABL9a+fXtNmTJFubm52r59u0aPHq3MzEwlJCQUOPfixYsqXbp0sdy3fPnyxXIdAIB7MAUMeDGr1SqbzaZq1arpvvvu03333adPPvlE0v+mbVeuXKlOnTopJCREdrtdv/76q1544QW1adNGzZs3V0xMjPbt2+d03fnz56tt27YKCwvTyJEjlZ2d7XT8j1PA+fn5mj9/vu666y41adJEHTp00Ny5cyVJnTp1kiT16NFDwcHB6tu3r+Nzq1at0j333KOQkBB17dpVS5YscbrPrl271KNHD4WEhKhnz55/OvV7JQsXLtR9992nZs2aKTIyUuPGjdP58+cLnLdhwwbdfffdCgkJUWxsrI4fP+50fOPGjerZs6dCQkLUqVMnzZ49W7m5uZe9Z05OjsaPH6+IiAiFhISoY8eOSkxMdLl2ACgqEkDAIH5+frp48aLj/eHDh/XBBx9o1qxZ8vH57d+DTzzxhCpUqKD58+erfPnyWr58uR555BF9+OGHqlixotatW6eZM2dq7NixCg8P17/+9S8tXrxYNWvWvOJ9X3rpJb399tsaMWKEwsPDdfLkSf3www+SpLffflu9e/fWokWLVK9ePUcKuWLFCs2cOVNjxoxRo0aNtHfvXr3wwgsqV66coqKilJmZqQEDBuiOO+7Q9OnTlZqaqkmTJrn8d2KxWDRq1ChVr15dqampSkhI0PTp0zVu3DjHORcuXNDcuXM1depUlS5dWgkJCRoyZIiWLVsmSfryyy/1zDPPaPTo0WrRooUOHz6sF154QZI0aNCgAvdcvHixNm7cqH/+85+qVq2ajh8/rhMnTrhcOwAUFQ0gYIhdu3ZpzZo1atOmjWPs4sWLmj59uipXrixJ+vrrr7V//359/fXXslqtkqTnnntOGzZs0Icffqg+ffooOTlZvXr1Uu/evSVJQ4YM0ddff10gBbwkIyNDycnJGjNmjKKioiRJtWrVcjxYceneFStWlM1mc3zu1Vdf1fPPP68uXbpIkmrWrKkDBw5o+fLlioqK0po1a5Sfn6/JkyerbNmyql+/vk6cOOHUuBXGo48+6vhzzZo19fTTT2vcuHFO17l48aLGjBmjpk2bSpKmTp2qbt26adeuXQoNDdW8efP0xBNPOL7fpetMnz79sg3g8ePHVbt2bYWHh8tisah69eou1QwA14oGEPBin332mcLCwpSbm6vc3Fx16tTJkUxJ0q233upowCRpz549yszMVOvWrZ2uc+HCBR0+fFiSdPDgQUVHRzsdb9asmbZs2XLZGg4dOqScnBzdcccdha779OnTOn78uEaNGuVUb25urmN94cGDBxUcHKyyZcs6joeFhRX6Hpds3rxZiYmJOnDggDIyMpSXl6fs7GxlZmY6HpYpVaqUmjRp4vhM3bp1dfPNN+vgwYMKDQ3Vnj179O2332revHmOcy5dJysry6lGSYqKitJjjz2mrl27qn379urQoYMiIiJcrh0AiooGEPBirVu31rhx41SqVClVqVKlwEMef2xM8vPzZbPZtHjx4gLXKuqDHWXKlHH5M/n5+ZKkCRMmOFK3Sy5NVRf2KeM/c/ToUT3xxBOKjo7W008/rQoVKug///mPRo0aVWD9nsViKfD5S2P5+fmKj493pJW/d7nv37hxY33yySf64osv9NVXX2nw4MFq27atZs6cec3fCQAKgwYQ8GJly5ZV7dq1C31+48aNlZ6eLl9fX9WoUeOy59StW1c7d+5Ujx49HGPffPPNFa8ZFBQkPz8/bd68+bLrBC81pXl5eY6xwMBA3XLLLTpy5Ij++te/Xva69erV03vvvacLFy7Iz89PkrRz586rfUUnu3fvVl5enp5//nlHY/nBBx8UOC83N1e7d+9WaGiopN9SzV9++UW33XabJOn222/XDz/84NLftb+/v7p166Zu3brp7rvv1uOPP66zZ8+qYsWKLn0HACgKGkAADm3btlWzZs00cOBADR8+XHXq1NHJkyf1+eefq3PnzgoJCVFMTIyee+45NWnSROHh4VqzZo1SUlKu+BBImTJl1L9/f02fPl2lS5dW8+bNdfr0aaWkpKh3794KCAiQn5+fvvzyS1WtWlVlypRR+fLlFR8fr4kTJ8rf31933nmncnJytHv3bv3yyy+KjY1V9+7d9fLLL2vUqFF68skndfToUS1YsMCl71urVi3l5uZq8eLF6tixo/7zn/84Huz4vdKlS2vChAkaPXq0SpUqpQkTJqhZs2aOhnDgwIGKi4tTtWrV1LVrV/n4+Oj777/X999/ryFDhhS43qJFi2Sz2dSwYUP5+Pho/fr1stlsuvnmm12qHwCKigYQgIPFYtH8+fP1z3/+UyNHjtSZM2cUGBioFi1aKDAwUJLUrVs3HT58WC+++KKys7N1991368EHH9S///3vK173qaeekq+vr2bOnKmTJ0/KZrM51hGWKlVKo0eP1pw5czRz5ky1aNFCixcvVu/eveXn56fXX39d06dPV7ly5dSgQQM98sgjkqSbbrpJ8+bN09ixY9WjRw/Vq1dPw4cPV3x8fKG/b6NGjTRixAglJSVpxowZatGihYYOHarnnnvO6Tw/Pz/1799fw4YN04kTJxQeHq7Jkyc7jrdv317z5s3TnDlz9Nprr6lUqVK67bbbHA/K/FG5cuWUlJSkn376ST4+PgoJCdH8+fMdKSQAuJvFXhwLaQAAAHDD4J+bAAAAhqEBBAAAMAwNIAAAgGFoAAEAAAxDAwgAAGAYGkAAAADD0AACAAAYhgYQAADAMDSAAAAAhqEBBAAAMAwNIAAAgGH+H89A5s4walWzAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
