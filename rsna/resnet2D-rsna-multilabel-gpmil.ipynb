{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04ce7fc16269637",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827de11a1d9590d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:48.269950Z",
     "start_time": "2025-02-17T17:21:46.653243Z"
    }
   },
   "outputs": [],
   "source": [
    "from sched import scheduler\n",
    "!pip install gpytorch torchsummary iterative-stratification optuna pytorch_metric_learning wandb\n",
    "!pip install torch pydicom pandas scikit-learn scikit-image numpy opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a33c97468126c29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:49.979008Z",
     "start_time": "2025-02-17T17:21:48.275434Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from pytorch_metric_learning import losses\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, \\\n",
    "    multilabel_confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import models.mil_resnet as MILModels\n",
    "from utils import hard_negative_mining as hnm\n",
    "import gpytorch\n",
    "from layers.gaussian_process import SingletaskGPModel, PGLikelihood\n",
    "from utils.early_stopping import EarlyStoppingForOptimization, EarlyStopping\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a37479f6e74e822",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.003276Z",
     "start_time": "2025-02-17T17:21:50.001696Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b411feb08f174a",
   "metadata": {},
   "source": [
    "# Configurations\n",
    "## GPU Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bc308439eee7c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.086457Z",
     "start_time": "2025-02-17T17:21:50.055840Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize GPU Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af9c65019e61153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.163025Z",
     "start_time": "2025-02-17T17:21:50.145061Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f07b41df278477",
   "metadata": {},
   "source": [
    "## Seed Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "389bfe8198c54df2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.205159Z",
     "start_time": "2025-02-17T17:21:50.187853Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c5af8335d4fd7c",
   "metadata": {},
   "source": [
    "## Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efb1cdf72f6905c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.258291Z",
     "start_time": "2025-02-17T17:21:50.233415Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"../config.yaml\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Accessing constants from config\n",
    "HEIGHT = config['height']\n",
    "WIDTH = config['width']\n",
    "CHANNELS = config['channels']\n",
    "\n",
    "TRAIN_BATCH_SIZE = config['train_batch_size']\n",
    "VALID_BATCH_SIZE = config['valid_batch_size']\n",
    "TEST_BATCH_SIZE = config['test_batch_size']\n",
    "TEST_SIZE = config['test_size']\n",
    "VALID_SIZE = config['valid_size']\n",
    "\n",
    "TRAINING_TYPE = config['training_type']\n",
    "DATA_REDUNDANCY = config['data_redundancy']\n",
    "GP_MODEL = config['gp_model']\n",
    "GP_KERNEL = config['kernel_type']\n",
    "MODEL_TYPE = config['model_type']\n",
    "CONTRASTIVE_LEARNING = config['contrastive_learning']\n",
    "\n",
    "MAX_SLICES = config['max_slices']\n",
    "SHAPE = tuple(config['shape'])\n",
    "\n",
    "NUM_EPOCHS = config['num_epochs']\n",
    "LEARNING_RATE = config['learning_rate']\n",
    "LEARNING_RATE_NGD = config['learning_rate_ngd']\n",
    "INDUCING_POINTS = config['inducing_points']\n",
    "THRESHOLD = config['threshold']\n",
    "\n",
    "NUM_CLASSES = config['num_classes']\n",
    "\n",
    "TARGET_LABELS = config['target_labels']\n",
    "\n",
    "MODEL_PATH = config['model_path']\n",
    "LIKELIHOOD_PATH = config['likelihood_path']\n",
    "DEVICE = config['device']\n",
    "\n",
    "PROJECTION_LOCATION = config['projection_location']\n",
    "PROJECTION_HIDDEN_DIM = config['projection_hidden_dim']\n",
    "PROJECTION_OUTPUT_DIM = config['projection_output_dim']\n",
    "\n",
    "ATTENTION_HIDDEN_DIM = config['attention_hidden_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cef7e185bd55c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.314967Z",
     "start_time": "2025-02-17T17:21:50.281927Z"
    }
   },
   "outputs": [],
   "source": [
    "KAGGLE = os.path.exists(('kaggle/input'))\n",
    "REMOTE_SERVER = os.path.exists(('/workspace/rsna-ich-mil'))\n",
    "ROOT_DIR = None\n",
    "\n",
    "if KAGGLE:\n",
    "    DATA_DIR = ROOT_DIR + 'rsna-mil-training/'\n",
    "    DICOM_DIR = DATA_DIR\n",
    "    CSV_PATH = DICOM_DIR + 'training_1000_scan_subset.csv'\n",
    "elif REMOTE_SERVER:\n",
    "    DATA_DIR = '/root/rsna-ich-mil/'\n",
    "    DICOM_DIR = DATA_DIR\n",
    "    if DATA_REDUNDANCY:\n",
    "        CSV_PATH = DATA_DIR + 'training_dataset_1150_redundancy.csv'\n",
    "    else:\n",
    "        CSV_PATH = '/workspace/training_dataset_1150.csv'\n",
    "    print('Running on remote server.')\n",
    "else:\n",
    "    DATA_DIR = '../rsna-ich-mil/'\n",
    "    DICOM_DIR = DATA_DIR\n",
    "    if DATA_REDUNDANCY:\n",
    "        CSV_PATH = './data_analyze/training_dataset_1150_redundancy.csv'\n",
    "    else:\n",
    "        CSV_PATH = './data_analyze/training_dataset_1150.csv'\n",
    "    print(f'CSV Path: {CSV_PATH}')\n",
    "\n",
    "patient_scan_labels = pd.read_csv(CSV_PATH, nrows=1150)\n",
    "# patient_scan_labels = pd.read_csv(CSV_PATH)\n",
    "dicom_dir = DICOM_DIR if KAGGLE else DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c85475b0541e387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.350401Z",
     "start_time": "2025-02-17T17:21:50.328436Z"
    }
   },
   "outputs": [],
   "source": [
    "patient_scan_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d276ee1c956192",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd63c1d38007ac61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.410995Z",
     "start_time": "2025-02-17T17:21:50.394014Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_dataset(patient_scan_labels, test_size=TEST_SIZE, val_size=VALID_SIZE, random_state=42):\n",
    "    # Extract the labels from the DataFrame\n",
    "    labels = patient_scan_labels['patient_label']\n",
    "    if test_size > 0:\n",
    "        # First, split off the test set\n",
    "        train_val_labels, test_labels = train_test_split(\n",
    "            patient_scan_labels,\n",
    "            test_size=test_size,\n",
    "            stratify=labels,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        # Calculate the validation size relative to the train_val set\n",
    "        val_size_adjusted = val_size / (1 - test_size)\n",
    "\n",
    "        # Split the train_val set into train and validation sets\n",
    "        train_labels, val_labels = train_test_split(\n",
    "            train_val_labels,\n",
    "            test_size=val_size_adjusted,\n",
    "            stratify=train_val_labels['patient_label'],\n",
    "            random_state=random_state\n",
    "        )\n",
    "    else:\n",
    "        train_labels, val_labels = train_test_split(\n",
    "            patient_scan_labels,\n",
    "            test_size=val_size,\n",
    "            stratify=labels,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        test_labels = None\n",
    "\n",
    "    return train_labels, val_labels, test_labels\n",
    "\n",
    "def split_dataset_for_multilabel(patient_scan_labels, test_size=0.15, val_size=VALID_SIZE, random_state=42):\n",
    "    # Extract the labels from the DataFrame\n",
    "    labels = patient_scan_labels[['patient_any', 'patient_epidural', 'patient_intraparenchymal',\n",
    "                                  'patient_intraventricular', 'patient_subarachnoid', 'patient_subdural']].values\n",
    "\n",
    "    if test_size > 0:\n",
    "        # First split: train + test\n",
    "        msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "        train_idx, test_idx = next(msss.split(patient_scan_labels, labels))\n",
    "\n",
    "        train_labels = patient_scan_labels.iloc[train_idx]\n",
    "        test_labels = patient_scan_labels.iloc[test_idx]\n",
    "\n",
    "        # Second split: train + validation\n",
    "        msss_val = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=val_size, random_state=random_state)\n",
    "        train_idx, val_idx = next(msss_val.split(train_labels, labels[train_idx]))\n",
    "\n",
    "        train_labels_final = train_labels.iloc[train_idx]\n",
    "        val_labels = train_labels.iloc[val_idx]\n",
    "\n",
    "    else:\n",
    "        # Only split into train and validation if test_size is 0\n",
    "        msss_val = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=val_size, random_state=random_state)\n",
    "        train_idx, val_idx = next(msss_val.split(patient_scan_labels, labels))\n",
    "\n",
    "        train_labels_final = patient_scan_labels.iloc[train_idx]\n",
    "        val_labels = patient_scan_labels.iloc[val_idx]\n",
    "        test_labels = None\n",
    "\n",
    "    return train_labels_final, val_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3226128a0da50755",
   "metadata": {},
   "source": [
    "## Dataset Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fed4ff069d88fca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.460190Z",
     "start_time": "2025-02-17T17:21:50.436240Z"
    }
   },
   "outputs": [],
   "source": [
    "class DatasetAugmentor:\n",
    "    def __init__(self, height, width, levels=2, seed=None):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.levels = levels  # Dynamic number of levels\n",
    "        self.seed = seed\n",
    "        self.params = []\n",
    "\n",
    "        # Create different levels of transforms based on the number of levels specified\n",
    "        for i in range(levels):\n",
    "            factor = (i + 1) / levels\n",
    "            self.params.append(\n",
    "                self._create_transform(\n",
    "                    degrees=int(15 * factor),\n",
    "                    translate_range=(0.2 * factor, 0.2 * factor),\n",
    "                    scale_range=(1 - 0.2 * factor, 1 + 0.2 * factor),\n",
    "                    brightness_range=0.2 * factor,\n",
    "                    contrast_range=0.2 * factor,\n",
    "                    blur_sigma_range=(0.5 * factor, 1.0 * factor),\n",
    "                    apply_elastic=(i >= levels // 2),\n",
    "                    level_name=f'level_{i + 1}'\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def _sample_value(self, value_range):\n",
    "        if isinstance(value_range, tuple):\n",
    "            random.seed(self.seed)\n",
    "            return random.uniform(value_range[0], value_range[1])\n",
    "        return value_range\n",
    "\n",
    "    def _create_transform(self, degrees, translate_range, scale_range, brightness_range, contrast_range,\n",
    "                          blur_sigma_range, apply_elastic, level_name):\n",
    "        print(f\"Creating '{level_name}' transform with parameters:\")\n",
    "        sampled_values = {\n",
    "            \"degrees\": abs(self._sample_value((-degrees, degrees))),\n",
    "            \"translate\": (abs(self._sample_value(translate_range[0])), abs(self._sample_value(translate_range[1]))),\n",
    "            \"scale\": self._sample_value(scale_range),\n",
    "            \"brightness\": self._sample_value(brightness_range),\n",
    "            \"contrast\": self._sample_value(contrast_range),\n",
    "            \"blur_sigma\": self._sample_value(blur_sigma_range),\n",
    "            \"apply_elastic\": apply_elastic\n",
    "        }\n",
    "\n",
    "        print(sampled_values)\n",
    "        return sampled_values\n",
    "\n",
    "    def apply_transform(self, image, level):\n",
    "        params = self.params[level]\n",
    "        transform = self._get_transform(params, channels=image.shape[0])\n",
    "        return transform(image)\n",
    "\n",
    "    def _get_transform(self, params, channels=3):\n",
    "        transform_list = [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomAffine(degrees=params[\"degrees\"], translate=params[\"translate\"],\n",
    "                                    scale=(params[\"scale\"], params[\"scale\"])),\n",
    "            transforms.ColorJitter(brightness=params[\"brightness\"], contrast=params[\"contrast\"]),\n",
    "            transforms.GaussianBlur(kernel_size=(3, 3), sigma=params[\"blur_sigma\"]),\n",
    "            transforms.RandomApply([transforms.ElasticTransform()] if params[\"apply_elastic\"] else [], p=0.3),\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(self.height),\n",
    "            # transforms.Compose([transforms.ToImage(), transforms.ToDtype(torch.float32, scale=True)])\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "\n",
    "        return transforms.Compose(transform_list)\n",
    "\n",
    "    def _channel_shuffle(self, tensor):\n",
    "        torch.manual_seed(self.seed)\n",
    "        channels = tensor.shape[0]\n",
    "        indices = torch.randperm(channels)\n",
    "        return tensor[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17559ec86a6d7e5d",
   "metadata": {},
   "source": [
    "## Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "638bfe32475d4cf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.569411Z",
     "start_time": "2025-02-17T17:21:50.486586Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset_generators.RSNA_Dataset import MedicalScanDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17ba8c33a5b0e113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.591868Z",
     "start_time": "2025-02-17T17:21:50.572250Z"
    }
   },
   "outputs": [],
   "source": [
    "class TrainDatasetGenerator(MedicalScanDataset):\n",
    "    \"\"\"Dataset class for training medical scan data.\"\"\"\n",
    "    def __init__(self, data_dir, patient_scan_labels, augmentor=None):\n",
    "        super().__init__(data_dir, patient_scan_labels, augmentor)\n",
    "\n",
    "\n",
    "class TestDatasetGenerator(MedicalScanDataset):\n",
    "    \"\"\"Dataset class for testing medical scan data.\"\"\"\n",
    "    def __init__(self, data_dir, patient_scan_labels, augmentor=None):\n",
    "        super().__init__(data_dir, patient_scan_labels, augmentor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a74c9cafe700df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.640066Z",
     "start_time": "2025-02-17T17:21:50.616847Z"
    }
   },
   "outputs": [],
   "source": [
    "augmentor = DatasetAugmentor(HEIGHT, WIDTH, levels=2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2329e7da154e7ba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.782552Z",
     "start_time": "2025-02-17T17:21:50.661102Z"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset = TrainDatasetGenerator(dicom_dir, patient_scan_labels, augmentor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a0e8e7d9949c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.837363Z",
     "start_time": "2025-02-17T17:21:50.820285Z"
    }
   },
   "outputs": [],
   "source": [
    "len(original_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e6442f44018f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.937818Z",
     "start_time": "2025-02-17T17:21:50.865483Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y, z, _ = original_dataset[0]\n",
    "print(x.shape, y.shape, z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e3831832ebcfe75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:50.966660Z",
     "start_time": "2025-02-17T17:21:50.949450Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_loader(dicom_dir, patient_scan_labels, batch_size=TRAIN_BATCH_SIZE):\n",
    "    original_dataset = TrainDatasetGenerator(dicom_dir, patient_scan_labels, augmentor=None)\n",
    "    return DataLoader(original_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True,\n",
    "                      drop_last=True)\n",
    "\n",
    "def get_test_loader(dicom_dir, patient_scan_labels, batch_size=TEST_BATCH_SIZE):\n",
    "    test_dataset = TestDatasetGenerator(dicom_dir, patient_scan_labels, augmentor=None)\n",
    "    return DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc97374c2af6d64",
   "metadata": {},
   "source": [
    "# Utils\n",
    "## Augment batch for CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54c6d481ec68b7b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:51.007710Z",
     "start_time": "2025-02-17T17:21:50.990297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Version 2: Avg time taken: 0.05 seconds for 1 augmentation (w ResizedCrop)\n",
    "def augment_batch(batch_images):\n",
    "    if CHANNELS == 1:\n",
    "        batch_size, num_instances, channels, height, width = batch_images.shape\n",
    "    else:\n",
    "        batch_size, num_instances, height, width, channels = batch_images.shape\n",
    "\n",
    "    # Define augmentation transformations using GPU-compatible operations\n",
    "    aug_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop((height, width), scale=(0.8, 1.1)),\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4)], p=0.6),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.Compose([transforms.ToImage(), transforms.ToDtype(torch.float32, scale=True)]),\n",
    "    ])\n",
    "\n",
    "    # Apply transformations directly on the tensor without converting to PIL\n",
    "    augmented_batch = torch.empty_like(batch_images)  # Preallocate memory for augmented images\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        for j in range(num_instances):\n",
    "            if CHANNELS == 1:\n",
    "                augmented_batch[i, j] = aug_transform(batch_images[i, j])\n",
    "            else:\n",
    "                augmented_batch[i, j] = aug_transform(batch_images[i, j].permute(2, 0, 1)).permute(1, 2, 0)\n",
    "\n",
    "    return augmented_batch.cuda()  # Move the augmented batch to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678537611fbb8e3",
   "metadata": {},
   "source": [
    "## NTXentLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56ebdfa34632acbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:51.059278Z",
     "start_time": "2025-02-17T17:21:51.034783Z"
    }
   },
   "outputs": [],
   "source": [
    "class NTXentLoss(losses.NTXentLoss):\n",
    "    def __init__(self, temperature, **kwargs):\n",
    "        super().__init__(temperature=temperature, **kwargs)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, embeddings, labels=None, hard_pairs=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "        if labels == None:\n",
    "            # Self-supervised labels\n",
    "            batch_size = feature_vectors_normalized.size(0) // 2  # Assuming equal size for both embeddings\n",
    "            labels = torch.cat([torch.arange(batch_size), torch.arange(batch_size)], dim=0)\n",
    "\n",
    "        # Compute logits\n",
    "        logits = torch.div(\n",
    "            torch.matmul(\n",
    "                feature_vectors_normalized, torch.transpose(feature_vectors_normalized, 0, 1)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "\n",
    "        if labels == None:\n",
    "            return losses.NTXentLoss(temperature=self.temperature)(logits, torch.squeeze(labels))\n",
    "        if hard_pairs == None:\n",
    "            return losses.SupConLoss(temperature=self.temperature)(logits, torch.squeeze(labels))\n",
    "        return losses.SupConLoss(temperature=self.temperature)(logits, torch.squeeze(labels), hard_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3bff18aa94ccf5",
   "metadata": {},
   "source": [
    "# Training and Validation\n",
    "## Metrics Calculation\n",
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e37f682a8aaac35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:51.097822Z",
     "start_time": "2025-02-17T17:21:51.079764Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, labels, average='weighted'):\n",
    "    if NUM_CLASSES == 1:\n",
    "        return {\n",
    "            \"accuracy\": accuracy_score(labels, predictions),\n",
    "            \"precision\": precision_score(labels, predictions, average=average),\n",
    "            \"recall\": recall_score(labels, predictions, average=average),\n",
    "            \"f1\": f1_score(labels, predictions, average=average),\n",
    "            \"auc\": roc_auc_score(labels, predictions),\n",
    "            \"cohen_kappa\": cohen_kappa_score(labels, predictions)\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"accuracy\": accuracy_score(labels, predictions),\n",
    "            \"precision\": precision_score(labels, predictions, average='samples'),\n",
    "            \"recall\": recall_score(labels, predictions, average='samples'),\n",
    "            \"f1\": f1_score(labels, predictions, average='samples'),\n",
    "            \"auc\": roc_auc_score(labels, predictions),\n",
    "            \"cohen_kappa\": cohen_kappa_score(labels, predictions)\n",
    "        }\n",
    "\n",
    "def print_epoch_stats(epoch, num_epochs, phase, loss, metrics):\n",
    "    \"\"\"Print statistics for an epoch.\"\"\"\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - {phase.capitalize()}:\")\n",
    "    print(f\"Loss: {loss:.4f}, Accuracy: {metrics['accuracy']:.4f}, \"\n",
    "          f\"Precision: {metrics['precision']:.4f}, Recall: {metrics['recall']:.4f}, \"\n",
    "          f\"F1: {metrics['f1']:.4f}, AUC: {metrics['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7332fde37dac6987",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aaf3081e1ffe2c",
   "metadata": {},
   "source": [
    "### Training Phase 1: CNN + ATT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf02a694b73c3669",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:51.146172Z",
     "start_time": "2025-02-17T17:21:51.124175Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_phase_1(model, data_loader, criterion_cl, criterion_bce, optimizer, scheduler, device):\n",
    "    total_loss = 0.0\n",
    "    alpha = 0.5\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "        batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_labels = batch_patient_labels if NUM_CLASSES == 1 else batch_multi_labels\n",
    "\n",
    "        if CONTRASTIVE_LEARNING:\n",
    "            aug_data_1 = augment_batch(batch_data)\n",
    "            aug_data_2 = augment_batch(batch_data)\n",
    "            batch_data = torch.cat([aug_data_1, aug_data_2], dim=0)\n",
    "            train_labels = torch.cat([train_labels, train_labels], dim=0)\n",
    "\n",
    "            outputs, cnn_features, attention_weights = model(batch_data)\n",
    "            miner_func = hnm.ExamplePairMiner()\n",
    "            hard_pairs = miner_func(outputs, train_labels)\n",
    "            loss = criterion_cl(outputs, labels=train_labels, hard_pairs=hard_pairs) * alpha + \\\n",
    "                     criterion_bce(outputs, train_labels) * (1 - alpha)\n",
    "            loss = loss.mean()\n",
    "            preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "        else:\n",
    "            outputs, cnn_features, attention_weights = model(batch_data)\n",
    "            loss = criterion_bce(outputs, train_labels)\n",
    "            loss = loss.mean()\n",
    "            preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "        predictions.extend(preds.cpu().detach().numpy())\n",
    "        labels.extend(train_labels.cpu().numpy())\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    return total_loss / len(data_loader), predictions, labels\n",
    "\n",
    "def validate_phase_1(model, data_loader, criterion_cl, criterion_bce, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    alpha = 0.5\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with (torch.inference_mode()):\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            val_labels = batch_patient_labels if NUM_CLASSES == 1 else batch_multi_labels\n",
    "\n",
    "            if CONTRASTIVE_LEARNING:\n",
    "                outputs, cnn_features, attention_weights = model(batch_data)\n",
    "                miner_func = hnm.ExamplePairMiner()\n",
    "                hard_pairs = miner_func(outputs, val_labels)\n",
    "                loss = criterion_cl(outputs, labels=val_labels, hard_pairs=hard_pairs) * alpha + \\\n",
    "                         criterion_bce(outputs, val_labels) * (1 - alpha)\n",
    "                loss = loss.mean()\n",
    "                preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "            else:\n",
    "                outputs, cnn_features, attention_weights = model(batch_data)\n",
    "                loss = criterion_bce(outputs, val_labels)\n",
    "                loss = loss.mean()\n",
    "                preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "            predictions.extend(preds.cpu().detach().numpy())\n",
    "            labels.extend(val_labels.cpu().numpy())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader), predictions, labels\n",
    "\n",
    "def evaluate_phase_1(model, data_loader, criterion_cl, criterion_bce, device):\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    labels = []\n",
    "\n",
    "    with (torch.inference_mode()):\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            eval_labels = batch_patient_labels if NUM_CLASSES == 1 else batch_multi_labels\n",
    "\n",
    "            if CONTRASTIVE_LEARNING:\n",
    "                outputs, cnn_features, attention_weights = model(batch_data)\n",
    "                loss = criterion_cl(outputs, labels=eval_labels) * 0.5 + criterion_bce(outputs, eval_labels) * 0.5\n",
    "                loss = loss.mean()\n",
    "                preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "            else:\n",
    "                outputs, cnn_features, attention_weights = model(batch_data)\n",
    "                loss = criterion_bce(outputs, eval_labels)\n",
    "                loss = loss.mean()\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                preds = (probs >= THRESHOLD).int()\n",
    "\n",
    "            probabilities.extend(probs.cpu().detach().numpy())\n",
    "            predictions.extend(preds.cpu().detach().numpy())\n",
    "            labels.extend(eval_labels.cpu().numpy())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return predictions, labels, probabilities\n",
    "\n",
    "def train_model_phase_1(model, train_loader, val_loader, criterion_cl, criterion_bce, optimizer, num_epochs, device):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_auc = 0.0\n",
    "    best_metrics = None\n",
    "    model.to(device)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE, steps_per_epoch=len(train_loader), epochs=num_epochs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                loss, predictions, labels = train_phase_1(model, train_loader, criterion_cl, criterion_bce,\n",
    "                                                           optimizer, scheduler, device)\n",
    "            else:\n",
    "                model.eval()\n",
    "                loss, predictions, labels = validate_phase_1(model, val_loader, criterion_cl, criterion_bce, device)\n",
    "\n",
    "            metrics = calculate_metrics(predictions, labels)\n",
    "            print_epoch_stats(epoch, num_epochs, phase, loss, metrics)\n",
    "\n",
    "            if phase == 'val' and best_auc < metrics['auc']:\n",
    "                best_auc = metrics['auc']\n",
    "                best_metrics = metrics\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f08020017b303c",
   "metadata": {},
   "source": [
    "### Training Phase 2: GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39dedb999d546a18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:51.202235Z",
     "start_time": "2025-02-17T17:21:51.173719Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, likelihoods, data_loader, criterion_cl, criterion_bce, mlls, optimizer,\n",
    "                variational_ngd_optimizer, scheduler, device):\n",
    "    total_loss = 0.0\n",
    "    alpha = 0.5\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    model.train()\n",
    "    likelihoods.train()\n",
    "\n",
    "    for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "        batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if GP_MODEL == 'single_task':\n",
    "            if NUM_CLASSES != 1:\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    variational_ngd_optimizer[i].zero_grad()\n",
    "            else:\n",
    "                variational_ngd_optimizer.zero_grad()\n",
    "\n",
    "        if TRAINING_TYPE == 'end_to_end':\n",
    "            if CONTRASTIVE_LEARNING:\n",
    "                aug_data_1 = augment_batch(batch_data)\n",
    "                aug_data_2 = augment_batch(batch_data)\n",
    "                batch_data = torch.cat([aug_data_1, aug_data_2], dim=0)\n",
    "                batch_labels = torch.cat([batch_labels, batch_labels], dim=0)\n",
    "                batch_multi_labels = torch.cat([batch_multi_labels, batch_multi_labels], dim=0)\n",
    "                batch_patient_labels = torch.cat([batch_patient_labels, batch_patient_labels], dim=0)\n",
    "\n",
    "            outputs, gp_outputs, att_outputs = model(batch_data)\n",
    "\n",
    "            if GP_MODEL == 'single_task' and NUM_CLASSES != 1:\n",
    "                loss = 0\n",
    "                gp_loss = 0\n",
    "                ntx_loss = 0\n",
    "\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    gp_loss += -mlls[i](gp_outputs[i], batch_multi_labels[:, i])\n",
    "\n",
    "                if CONTRASTIVE_LEARNING:\n",
    "                    miner_func = hnm.ExamplePairMiner()\n",
    "                    hard_pairs = miner_func(outputs, batch_multi_labels)\n",
    "                    ntx_loss = criterion_cl(outputs, labels=batch_multi_labels, hard_pairs=hard_pairs)\n",
    "                    loss = 0.3 * criterion_bce(outputs, batch_multi_labels) + 0.3 * gp_loss + ntx_loss * 0.4\n",
    "                else:\n",
    "                    loss = 0.5 * criterion_bce(outputs, batch_multi_labels) + 0.5 * gp_loss\n",
    "\n",
    "                loss = loss.mean()\n",
    "\n",
    "                # probs = [likelihoods[i](gp_outputs[i]).probs for i in range(NUM_CLASSES)]\n",
    "                probs = [torch.sigmoid(outputs[:, i]) for i in range(NUM_CLASSES)]\n",
    "                probabilities = torch.stack(probs, dim=1)\n",
    "                preds = (probabilities >= THRESHOLD).int()\n",
    "\n",
    "            elif GP_MODEL == 'single_task' and NUM_CLASSES == 1:\n",
    "                if CONTRASTIVE_LEARNING:\n",
    "                    miner_func = hnm.ExamplePairMiner()\n",
    "                    hard_pairs = miner_func(outputs, batch_patient_labels)\n",
    "                    ntx_loss = criterion_cl(outputs, labels=batch_patient_labels, hard_pairs=hard_pairs)\n",
    "                    # loss = 0.3 * criterion_bce(outputs.squeeze(-1), batch_patient_labels) + 0.3 * mlls(gp_outputs, batch_patient_labels) + ntx_loss * 0.4\n",
    "                    loss = ntx_loss * 0.5 + 0.5 * criterion_bce(outputs.squeeze(-1), batch_patient_labels)\n",
    "                    loss = loss.mean()\n",
    "                    loss += -mlls(gp_outputs, batch_patient_labels) * 0.5\n",
    "                else:\n",
    "                    # loss = -mlls(gp_outputs, batch_patient_labels) * 0.5 + 0.5 * criterion_bce(outputs.squeeze(-1), batch_patient_labels)\n",
    "                    loss = -mlls(gp_outputs, batch_patient_labels)\n",
    "\n",
    "                loss = loss.mean()\n",
    "                preds = likelihoods(gp_outputs).probs >= THRESHOLD\n",
    "                # preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "            predictions.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            if GP_MODEL == 'single_task':\n",
    "                if NUM_CLASSES != 1:\n",
    "                    for i in range(NUM_CLASSES):\n",
    "                        variational_ngd_optimizer[i].step()\n",
    "                else:\n",
    "                    variational_ngd_optimizer.step()\n",
    "\n",
    "        if NUM_CLASSES == 1:\n",
    "            labels.extend(batch_patient_labels.cpu().numpy())\n",
    "        else:\n",
    "            labels.extend(batch_multi_labels.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(data_loader), predictions, labels\n",
    "\n",
    "\n",
    "def validate(model, likelihoods, data_loader, criterion_cl, criterion_bce, mlls, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    likelihoods.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    alpha = 0.5\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with (torch.inference_mode()):\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in tqdm(data_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                outputs, gp_outputs, att_outputs = model(batch_data)\n",
    "                if GP_MODEL == 'single_task':\n",
    "                    loss = 0\n",
    "                    if NUM_CLASSES != 1:\n",
    "                        for i in range(NUM_CLASSES):\n",
    "                            loss += -mlls[i](gp_outputs[i], batch_multi_labels[:, i])\n",
    "\n",
    "                        loss.mean()\n",
    "                        loss += 0.5 * criterion_bce(outputs, batch_multi_labels)\n",
    "                        total_loss += loss.item()\n",
    "\n",
    "                        probabilities = torch.stack([likelihoods[i](gp_outputs[i]).probs for i in range(NUM_CLASSES)],\n",
    "                                                    dim=1)\n",
    "                        preds = (probabilities >= THRESHOLD).int()\n",
    "                    else:\n",
    "                        loss = -mlls(gp_outputs, batch_patient_labels) * 0.5 + 0.5 * criterion_bce(outputs.squeeze(-1),\n",
    "                                                                                                   batch_patient_labels)\n",
    "                        # loss = -mlls(gp_outputs, batch_patient_labels)\n",
    "                        loss = loss.mean()\n",
    "                        total_loss += loss.item()\n",
    "                        preds = likelihoods(gp_outputs).probs >= THRESHOLD\n",
    "                        # preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "\n",
    "                predictions.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "            if NUM_CLASSES == 1:\n",
    "                labels.extend(batch_patient_labels.cpu().numpy())\n",
    "            else:\n",
    "                labels.extend(batch_multi_labels.cpu().numpy())\n",
    "    return total_loss / len(data_loader), predictions, labels\n",
    "\n",
    "\n",
    "def train_model(model, likelihoods, train_loader, val_loader, criterion_cl, criterion_bce, optimizer, num_epochs,\n",
    "                learning_rate, device='cuda'):\n",
    "    \"\"\"Train the model and return the best model based on validation accuracy.\"\"\"\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    likelihoods.train()\n",
    "\n",
    "    # Initialize Early Stopping\n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "\n",
    "    if GP_MODEL == 'single_task':\n",
    "        if NUM_CLASSES != 1:\n",
    "            mlls = [\n",
    "                gpytorch.mlls.VariationalELBO(likelihoods[i], model.gp_layers[i], num_data=len(train_loader.dataset))\n",
    "                for\n",
    "                i in range(NUM_CLASSES)]\n",
    "            mlls = [mll.to(device) for mll in mlls]\n",
    "\n",
    "            variational_ngd_optimizer = [\n",
    "                gpytorch.optim.NGD(model.gp_layers[i].variational_parameters(), num_data=len(train_loader.dataset),\n",
    "                                   lr=LEARNING_RATE_NGD) for i in range(NUM_CLASSES)]\n",
    "        else:\n",
    "            mlls = gpytorch.mlls.VariationalELBO(likelihoods, model.gp_layers, num_data=len(train_loader.dataset))\n",
    "            mlls = mlls.to(device)\n",
    "            variational_ngd_optimizer = gpytorch.optim.NGD(model.gp_layers.variational_parameters(),\n",
    "                                                           num_data=len(train_loader.dataset),\n",
    "                                                           lr=LEARNING_RATE_NGD)\n",
    "\n",
    "    # scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=len(train_loader), epochs=num_epochs)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-5)\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "    best_likelihood_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_predictions, train_labels = train_epoch(model, likelihoods, train_loader, criterion_cl,\n",
    "                                                                  criterion_bce,\n",
    "                                                                  mlls, optimizer, variational_ngd_optimizer,\n",
    "                                                                  scheduler, device)\n",
    "        train_metrics = calculate_metrics(train_predictions, train_labels)\n",
    "        print_epoch_stats(epoch, num_epochs, \"train\", train_loss, train_metrics)\n",
    "\n",
    "        wandb.log({\n",
    "            \"train/loss\": train_loss,\n",
    "            \"train/accuracy\": train_metrics[\"accuracy\"],\n",
    "            \"train/precision\": train_metrics[\"precision\"],\n",
    "            \"train/recall\": train_metrics[\"recall\"],\n",
    "            \"train/f1\": train_metrics[\"f1\"],\n",
    "            \"train/auc\": train_metrics[\"auc\"],\n",
    "            \"train/cohen_kappa\": train_metrics[\"cohen_kappa\"]\n",
    "        })\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, val_predictions, val_labels = validate(model, likelihoods, val_loader, criterion_cl, criterion_bce,\n",
    "                                                         mlls,\n",
    "                                                         device)\n",
    "        val_metrics = calculate_metrics(val_predictions, val_labels)\n",
    "        print_epoch_stats(epoch, num_epochs, \"validation\", val_loss, val_metrics)\n",
    "\n",
    "        wandb.log({\n",
    "            \"val/loss\": val_loss,\n",
    "            \"val/accuracy\": val_metrics[\"accuracy\"],\n",
    "            \"val/precision\": val_metrics[\"precision\"],\n",
    "            \"val/recall\": val_metrics[\"recall\"],\n",
    "            \"val/f1\": val_metrics[\"f1\"],\n",
    "            \"val/auc\": val_metrics[\"auc\"],\n",
    "            \"val/cohen_kappa\": val_metrics[\"cohen_kappa\"]\n",
    "        })\n",
    "\n",
    "        # Early Stopping Check\n",
    "        early_stopping(val_metrics[\"auc\"], model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        # Save best model\n",
    "        if val_metrics['auc'] > best_val_accuracy:\n",
    "            best_val_accuracy = val_metrics['auc']\n",
    "            best_model_state = model.state_dict()\n",
    "            best_likelihood_state = likelihoods.state_dict()\n",
    "\n",
    "    # Load best model\n",
    "    if best_model_state and best_likelihood_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        likelihoods.load_state_dict(best_likelihood_state)\n",
    "    # Optionally log the best model to W&B (if desired)\n",
    "    print(f'Best Validation AUC: {best_val_accuracy}')\n",
    "    wandb.log_artifact(wandb.Artifact(\"best_model\", type=\"model\", metadata={\"accuracy\": best_val_accuracy}))\n",
    "\n",
    "    return model, likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb82ef6c7a8f86",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "967f6eb1fe5ef54f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:51.243399Z",
     "start_time": "2025-02-17T17:21:51.225644Z"
    }
   },
   "outputs": [],
   "source": [
    "## Model Evaluation Functions\n",
    "def evaluate_model(model, likelihoods, data_loader, device='cuda'):\n",
    "    \"\"\"Evaluate the model on the given data loader.\"\"\"\n",
    "    model = model.to(device)\n",
    "    likelihoods = likelihoods.to(device)\n",
    "    model.eval()\n",
    "    likelihoods.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in data_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                outputs, gp_outputs, att_outputs = model(batch_data)\n",
    "                if GP_MODEL == 'single_task':\n",
    "                    if NUM_CLASSES > 1:\n",
    "                        probabilities = torch.stack([likelihoods[i](gp_outputs[i]).probs for i in range(NUM_CLASSES)],\n",
    "                                                    dim=1)\n",
    "                    else:\n",
    "                        probabilities = likelihoods(gp_outputs).probs\n",
    "                    preds = (probabilities >= THRESHOLD).int()\n",
    "                    # preds = (torch.sigmoid(outputs) >= THRESHOLD).int()\n",
    "                predictions.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "            if NUM_CLASSES == 1:\n",
    "                labels.extend(batch_patient_labels.cpu().numpy())\n",
    "            else:\n",
    "                labels.extend(batch_multi_labels.cpu().numpy())\n",
    "\n",
    "            probs.extend(probabilities.cpu().detach().numpy())\n",
    "\n",
    "    return np.array(predictions), np.array(labels), np.array(probs)\n",
    "\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    \"\"\"Print the calculated metrics.\"\"\"\n",
    "    print(f\"Test Accuracy: {metrics['accuracy']:.4f}, \"\n",
    "          f\"Precision: {metrics['precision']:.4f}, \"\n",
    "          f\"Recall: {metrics['recall']:.4f}, \"\n",
    "          f\"F1: {metrics['f1']:.4f}\",\n",
    "          f\"AUC: {metrics['auc']:.4f}\",\n",
    "          f\"Cohen Kappa: {metrics['cohen_kappa']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387310f64ec783c7",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "688ee14ca4c63b43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:51.290822Z",
     "start_time": "2025-02-17T17:21:51.269920Z"
    }
   },
   "outputs": [],
   "source": [
    "## Visualization Functions\n",
    "def plot_roc_curve(model, likelihoods, data_loader, device):\n",
    "    \"\"\"Plot the ROC curve for the model predictions.\"\"\"\n",
    "    model.eval()\n",
    "    if likelihoods:\n",
    "        likelihoods.eval()\n",
    "    labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels, batch_patient_labels, batch_multi_labels in data_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_patient_labels = batch_patient_labels.float().to(device)\n",
    "            batch_multi_labels = batch_multi_labels.float().to(device)\n",
    "\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                outputs, gp_outputs, _ = model(batch_data)\n",
    "                if GP_MODEL == 'single_task':\n",
    "                    if NUM_CLASSES > 1:\n",
    "                        probabilities = torch.stack([likelihoods[i](gp_outputs[i]).probs for i in range(NUM_CLASSES)],\n",
    "                                                    dim=1)\n",
    "                    else:\n",
    "                        probabilities = likelihoods(gp_outputs).probs\n",
    "                    preds = probabilities\n",
    "\n",
    "                else:\n",
    "                    preds = torch.sigmoid(outputs)\n",
    "                predictions.extend(preds.cpu().detach().numpy())\n",
    "            else:\n",
    "                outputs, cnn_features, attention_weights = model(batch_data)\n",
    "                preds = torch.sigmoid(outputs)\n",
    "                predictions.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "            if NUM_CLASSES == 1:  # Binary classification\n",
    "                labels.extend(batch_patient_labels.cpu().numpy())\n",
    "            else:\n",
    "                labels.extend(batch_multi_labels.cpu().numpy())\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    if NUM_CLASSES == 1:\n",
    "        fpr, tpr, _ = roc_curve(labels, predictions)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    else:\n",
    "        class_name = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "        for i in range(NUM_CLASSES):\n",
    "            fpr, tpr, _ = roc_curve(labels[:, i], predictions[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, lw=2,\n",
    "                     label=f'Class {class_name[i]} (AUC = {roc_auc:.4f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(model, likelihoods, data_loader, criterion_cl, criterion_bce, device):\n",
    "    \"\"\"Plot confusion matrix for classification tasks.\"\"\"\n",
    "    if likelihoods:\n",
    "        predictions, labels, _ = evaluate_model(model, likelihoods, data_loader, device)\n",
    "    else:\n",
    "        predictions, labels, _ = evaluate_phase_1(model, data_loader, criterion_cl, criterion_bce, device)\n",
    "    if NUM_CLASSES > 1:  # Multi-label/multi-class\n",
    "        cm = multilabel_confusion_matrix(labels, predictions)\n",
    "        _, ax = plt.subplots(1, NUM_CLASSES, figsize=(15, 3))\n",
    "        for i in range(NUM_CLASSES):\n",
    "            ConfusionMatrixDisplay(cm[i]).plot(ax=ax[i])\n",
    "            ax[i].set_title(f'Class {i}')\n",
    "    else:  # Binary\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        ConfusionMatrixDisplay(cm).plot()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb67abfc34676ddc",
   "metadata": {},
   "source": [
    "# Model Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3ea64ecd34312a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:51.337180Z",
     "start_time": "2025-02-17T17:21:51.317119Z"
    }
   },
   "outputs": [],
   "source": [
    "## Data Processing Functions\n",
    "def load_model(model_class, model_path, params):\n",
    "    \"\"\"Load a trained model from a file.\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "\n",
    "    model = model_class(params)\n",
    "    try:\n",
    "        state_dict = torch.load(model_path, map_location=torch.device('cuda'), weights_only=True)\n",
    "        if not state_dict:\n",
    "            raise ValueError(f\"The state dictionary loaded from {model_path} is empty\")\n",
    "        model.load_state_dict(state_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model from {model_path}: {str(e)}\")\n",
    "        print(\"Initializing model with random weights instead.\")\n",
    "        return model  # Return the model with random initialization\n",
    "\n",
    "    return model.eval()\n",
    "\n",
    "\n",
    "def get_test_results(model, test_loader, test_labels, device=DEVICE):\n",
    "    \"\"\"Get test results including patient information.\"\"\"\n",
    "    predictions, _ = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    results = []\n",
    "    for i, row in enumerate(test_labels.itertuples(index=False)):\n",
    "        result = {col: getattr(row, col) for col in test_labels.columns}\n",
    "        result['prediction'] = predictions[i]\n",
    "        results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782c51e99ffa72cd",
   "metadata": {},
   "source": [
    "## Model Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc6077893e01344c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:51.379330Z",
     "start_time": "2025-02-17T17:21:51.362745Z"
    }
   },
   "outputs": [],
   "source": [
    "# If you need to use the Glorot (Xavier) uniform initialization\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa03f3cfc19f4215",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b4d4931b72a2e3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:21:51.430648Z",
     "start_time": "2025-02-17T17:21:51.406976Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def main(mode='train', use_cv=False, num_folds=5):\n",
    "    # os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "    current_time = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    run_name = f\"{TRAINING_TYPE}_experiment_{current_time}_{GP_MODEL}_refiner_fc_{PROJECTION_HIDDEN_DIM}_output_{PROJECTION_OUTPUT_DIM}_attention_{ATTENTION_HIDDEN_DIM}_kernel_{GP_KERNEL}_model_{MODEL_TYPE}\"\n",
    "\n",
    "    # Initialize W&B with a specific run name\n",
    "    wandb.init(project=\"MIL_Resnet_ICH\", name=run_name)\n",
    "\n",
    "    # Log hyperparameters\n",
    "    config = wandb.config\n",
    "    config.learning_rate = LEARNING_RATE\n",
    "    config.batch_size = TRAIN_BATCH_SIZE\n",
    "    config.num_epochs = NUM_EPOCHS\n",
    "\n",
    "    params = {\n",
    "        'channels': CHANNELS,  # Number of input channels (e.g., 1 for grayscale, 3 for RGB)\n",
    "        'num_classes': NUM_CLASSES,  # Number of output classes for classification\n",
    "        'drop_prob': 0.5,  # Dropout probability\n",
    "        'inducing_points': INDUCING_POINTS,  # Number of inducing points for the Gaussian Process layer\n",
    "        'projection_location': PROJECTION_LOCATION,  # Choose from 'after_resnet', 'after_attention', or 'after_gp'\n",
    "        'projection_hidden_dim': PROJECTION_HIDDEN_DIM,  # Hidden dimension size for the projection head\n",
    "        'projection_output_dim': PROJECTION_OUTPUT_DIM,  # Output dimension size for the projection head\n",
    "        'attention_hidden_dim': ATTENTION_HIDDEN_DIM,  # Hidden dimension size for the attention head\n",
    "        'gp_model': GP_MODEL,\n",
    "        'kernel_type': GP_KERNEL,\n",
    "        'model_type': MODEL_TYPE,\n",
    "        'contrastive_learning': CONTRASTIVE_LEARNING\n",
    "    }\n",
    "\n",
    "    if use_cv == False:\n",
    "        if NUM_CLASSES == 1:\n",
    "            train_labels, val_labels, test_labels = split_dataset(patient_scan_labels, test_size=0.0)\n",
    "        else:\n",
    "            train_labels, val_labels, test_labels = split_dataset_for_multilabel(patient_scan_labels, test_size=0.0)\n",
    "            \n",
    "        test_dir = './data_analyze/testing_dataset_150_redundancy.csv' if DATA_REDUNDANCY else \\\n",
    "                    './data_analyze/testing_dataset_150.csv'\n",
    "        test_labels = pd.read_csv(test_dir)\n",
    "\n",
    "        train_loader = get_train_loader(dicom_dir, train_labels, batch_size=TRAIN_BATCH_SIZE)\n",
    "        val_loader = get_train_loader(dicom_dir, val_labels, batch_size=VALID_BATCH_SIZE)\n",
    "        test_loader = get_test_loader(dicom_dir, test_labels, batch_size=TEST_BATCH_SIZE)\n",
    "\n",
    "        if TRAINING_TYPE == 'end_to_end':\n",
    "            if GP_MODEL == 'single_task':\n",
    "                model = MILModels.CNN_ATT_GP_Multilabel(params)\n",
    "\n",
    "                if NUM_CLASSES != 1:\n",
    "                    likelihood = nn.ModuleList([PGLikelihood() for _ in range(NUM_CLASSES)])\n",
    "                else:\n",
    "                    likelihood = PGLikelihood()\n",
    "                    # likelihood = gpytorch.likelihoods.BernoulliLikelihood()\n",
    "                optimizer = optim.Adam([\n",
    "                    {'params': model.parameters(), 'lr': config.learning_rate},\n",
    "                    {'params': likelihood.parameters(), 'lr': config.learning_rate}\n",
    "                ])\n",
    "        elif TRAINING_TYPE == 'cnn_att':\n",
    "            model = MILModels.CNN_Attention(params)\n",
    "            likelihood = None\n",
    "            optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "        criterion_cl = NTXentLoss(0.5)\n",
    "        if NUM_CLASSES == 1:\n",
    "            pos_weights = torch.tensor([0.5]).to(DEVICE)\n",
    "        else:\n",
    "            pos_weights = torch.tensor([0.5] * NUM_CLASSES).to(DEVICE)\n",
    "        criterion_bce = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "\n",
    "        if mode == 'train':\n",
    "            wandb.watch(model)  # Watch the model to log gradients and parameters\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                # model.apply(init_weights)\n",
    "                trained_model, likelihood = train_model(model, likelihood, train_loader, val_loader, criterion_cl,\n",
    "                                                        criterion_bce, optimizer, config.num_epochs, config.learning_rate, DEVICE)\n",
    "                predictions, labels, _ = evaluate_model(trained_model, likelihood, test_loader, DEVICE)\n",
    "            else:\n",
    "                print(\"Training Phase 1: CNN + ATT\")\n",
    "                trained_model, _ = train_model_phase_1(model, train_loader, val_loader, criterion_cl, criterion_bce,\n",
    "                                                        optimizer, config.num_epochs, DEVICE)\n",
    "                predictions, labels, _ = evaluate_phase_1(trained_model, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "\n",
    "            metrics = calculate_metrics(predictions, labels, average='binary')\n",
    "            wandb.log(metrics)\n",
    "            print_metrics(metrics)\n",
    "\n",
    "            plot_roc_curve(trained_model, likelihood, test_loader, DEVICE)\n",
    "            plot_confusion_matrix(trained_model, likelihood, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "            torch.save(trained_model.state_dict(), MODEL_PATH)\n",
    "            if likelihood:\n",
    "                torch.save(likelihood.state_dict(), LIKELIHOOD_PATH)\n",
    "        else:\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                if GP_MODEL == 'single_task':\n",
    "                    trained_model = load_model(MILModels.CNN_ATT_GP_Multilabel, MODEL_PATH, params)\n",
    "                    predictions, labels, probs = evaluate_model(trained_model, likelihood, test_loader, DEVICE)\n",
    "            else:\n",
    "                trained_model = load_model(MILModels.CNN_Attention, MODEL_PATH, params)\n",
    "                predictions, labels, probs = evaluate_phase_1(trained_model, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "\n",
    "            metrics = calculate_metrics(predictions, labels)\n",
    "            wandb.log(metrics)\n",
    "            print_metrics(metrics)\n",
    "\n",
    "            plot_roc_curve(trained_model, likelihood, test_loader, DEVICE)\n",
    "            plot_confusion_matrix(trained_model, likelihood, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "\n",
    "            print(\"\\nProbabilities for each row in the test set:\")\n",
    "            for i, prob in enumerate(probs):\n",
    "                if NUM_CLASSES == 1:\n",
    "                    is_correct = predictions[i] == labels[i]\n",
    "                    print(\n",
    "                        f\"Row {i + 1}: Probs: {prob.item():.4f} | Prediction: {predictions[i]} | Label: {labels[i]} | Result: {'True' if is_correct else 'False'}\")\n",
    "                else:\n",
    "                    is_correct = np.array_equal(predictions[i], labels[i])\n",
    "                    print(\n",
    "                        f\"Row {i + 1}: Probs: {prob.tolist()} | Prediction: {predictions[i].tolist()} | Label: {labels[i].tolist()} | Result: {'True' if is_correct else 'False'}\")\n",
    "\n",
    "    else:\n",
    "        if NUM_CLASSES == 1:\n",
    "            trainval_labels, test_labels, _ = split_dataset(\n",
    "                patient_scan_labels,\n",
    "                val_size=TEST_SIZE,\n",
    "                test_size=0.0\n",
    "            )\n",
    "            test_labels = pd.read_csv('./data_analyze/testing_dataset_150_redundancy.csv')\n",
    "        else:\n",
    "            trainval_labels, test_labels, _ = split_dataset_for_multilabel(\n",
    "                patient_scan_labels,\n",
    "                val_size=TEST_SIZE,\n",
    "                test_size=0.0\n",
    "            )\n",
    "\n",
    "        # Setup CV using trainval data\n",
    "        kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "        fold_metrics = []\n",
    "\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kf.split(trainval_labels)):\n",
    "            print(f\"\\nFold {fold_idx + 1}/{num_folds}\")\n",
    "\n",
    "            # Create fold splits\n",
    "            train_labels_fold = trainval_labels.iloc[train_idx]\n",
    "            val_labels_fold = trainval_labels.iloc[val_idx]\n",
    "\n",
    "            # Create data loaders\n",
    "            train_loader = get_train_loader(dicom_dir, train_labels_fold, TRAIN_BATCH_SIZE)\n",
    "            val_loader = get_train_loader(dicom_dir, val_labels_fold, VALID_BATCH_SIZE)\n",
    "            test_loader = get_test_loader(dicom_dir, test_labels, TEST_BATCH_SIZE)\n",
    "\n",
    "            # Initialize model\n",
    "            if GP_MODEL == 'single_task':\n",
    "                model = MILModels.CNN_ATT_GP_Multilabel(params)\n",
    "                if NUM_CLASSES != 1:\n",
    "                    likelihood = nn.ModuleList([PGLikelihood() for _ in range(NUM_CLASSES)])\n",
    "                else:\n",
    "                    likelihood = PGLikelihood()\n",
    "                optimizer = optim.Adam([\n",
    "                    {'params': model.parameters(), 'lr': config.learning_rate},\n",
    "                    {'params': likelihood.parameters(), 'lr': config.learning_rate}\n",
    "                ])\n",
    "\n",
    "\n",
    "            if NUM_CLASSES == 1:\n",
    "                pos_weights = torch.tensor([5.0]).to(DEVICE)\n",
    "            else:\n",
    "                pos_weights = torch.tensor([5.0] * NUM_CLASSES).to(DEVICE)\n",
    "            criterion_bce = nn.BCEWithLogitsLoss(pos_weight=pos_weights) # Weighted BCE Loss\n",
    "            criterion_cl = NTXentLoss(0.5) # Contrastive Learning Loss\n",
    "\n",
    "            # Train model\n",
    "            wandb.init(project=\"MIL_Resnet_ICH\", name=f\"{run_name}_fold_{fold_idx + 1}\")\n",
    "            wandb.watch(model)\n",
    "            trained_model, likelihood = train_model(model, likelihood, train_loader, val_loader, criterion_cl,\n",
    "                                                    criterion_bce,\n",
    "                                                    optimizer, config.num_epochs, config.learning_rate, DEVICE)\n",
    "\n",
    "            # Evaluate model\n",
    "            if TRAINING_TYPE == 'end_to_end':\n",
    "                predictions, labels, _ = evaluate_model(trained_model, likelihood, test_loader, DEVICE)\n",
    "            else:\n",
    "                predictions, labels, _ = evaluate_phase_1(trained_model, test_loader, criterion_cl, criterion_bce, DEVICE)\n",
    "            metrics = calculate_metrics(predictions, labels)\n",
    "\n",
    "            # Log metrics\n",
    "            wandb.log(metrics)\n",
    "            print_metrics(metrics)\n",
    "            fold_metrics.append(metrics)\n",
    "\n",
    "            plot_roc_curve(trained_model, likelihood, test_loader, DEVICE)\n",
    "            plot_confusion_matrix(trained_model, likelihood, test_loader, DEVICE)\n",
    "\n",
    "            # Save model\n",
    "            torch.save(trained_model.state_dict(), f\"{MODEL_PATH}_fold_{fold_idx + 1}\")\n",
    "            if likelihood:\n",
    "                torch.save(likelihood.state_dict(), f\"{LIKELIHOOD_PATH}_fold_{fold_idx + 1}\")\n",
    "\n",
    "        # Calculate average metrics across all folds\n",
    "        avg_metrics = {}\n",
    "        for metric in fold_metrics[0].keys():\n",
    "            avg_metrics[metric] = np.mean([fold[metric] for fold in fold_metrics])\n",
    "        print(\"\\nAverage Metrics Across All Folds:\")\n",
    "        print_metrics(avg_metrics)\n",
    "        wandb.log(avg_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e68015552ccdc6",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf2cee20d2c1862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:26:05.859059Z",
     "start_time": "2025-02-17T17:21:51.465588Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(mode='train', use_cv=False, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f67acea19fa3408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:26:05.909147Z",
     "start_time": "2025-02-17T17:26:05.885288Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torchsummary\n",
    "#\n",
    "# class VGG(nn.Module):\n",
    "#     def __init__(self, input_channels=3):\n",
    "#         super(VGG, self).__init__()\n",
    "#\n",
    "#         self.features = nn.Sequential(\n",
    "#             # Conv1\n",
    "#             nn.Conv2d(input_channels, 16, kernel_size=5, padding=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#\n",
    "#             # Conv2\n",
    "#             nn.Conv2d(16, 32, kernel_size=3, padding=0),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Dropout(0.3),\n",
    "#\n",
    "#             # Conv3\n",
    "#             nn.Conv2d(32, 32, kernel_size=3, padding=0),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#\n",
    "#             # Conv4\n",
    "#             nn.Conv2d(32, 32, kernel_size=3, padding=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#\n",
    "#             # Conv5\n",
    "#             nn.Conv2d(32, 32, kernel_size=3, padding=0),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Dropout(0.3),\n",
    "#\n",
    "#             # Conv6\n",
    "#             nn.Conv2d(32, 32, kernel_size=3, padding=0),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "#\n",
    "#         self.flatten = nn.Flatten()\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = self.flatten(x)\n",
    "#         return x\n",
    "#\n",
    "# # Instantiate the model\n",
    "# model = VGG(input_channels=1)\n",
    "#\n",
    "# # If you need to use the Glorot (Xavier) uniform initialization\n",
    "# def init_weights(m):\n",
    "#     if type(m) == nn.Conv2d:\n",
    "#         torch.nn.init.xavier_uniform_(m.weight)\n",
    "#\n",
    "# model.apply(init_weights)\n",
    "#\n",
    "# # # Test the model with a sample input\n",
    "# # input_tensor = torch.randn(1, 1, 512, 512)\n",
    "# # output = model(input_tensor)\n",
    "# # print(f\"Output shape: {output.shape}\")\n",
    "#\n",
    "# # # Print the model architecture\n",
    "# model_info = torchsummary.summary(model, (1, 512, 512), device='cpu')\n",
    "# print(model_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
