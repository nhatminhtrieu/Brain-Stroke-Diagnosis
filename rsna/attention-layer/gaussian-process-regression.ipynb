{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Gaussian Process Regression",
   "id": "f209e4025ae6a04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Lib",
   "id": "d70d19872e59ff76"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-10T13:06:57.879822Z",
     "start_time": "2024-11-10T13:06:56.613152Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "\n",
    "from torch.xpu import device\n",
    "from torchvision import models\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "\n",
    "import gpytorch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:06:57.899868Z",
     "start_time": "2024-11-10T13:06:57.882372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set a fixed seed value\n",
    "seed_value = 42\n",
    "# Set the random seed for Python's built-in random module\n",
    "random.seed(seed_value)\n",
    "# Set the random seed for NumPy\n",
    "np.random.seed(seed_value)\n",
    "# Set the random seed for PyTorch\n",
    "torch.manual_seed(seed_value)\n",
    "\n",
    "# If using CUDA, set the seed for GPU as well (if applicable)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed_value)"
   ],
   "id": "1528b20ed70ed96b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789122112/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:06:57.930629Z",
     "start_time": "2024-11-10T13:06:57.928886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ],
   "id": "4f4c876574f979c4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preparation",
   "id": "2d81384bfb1df2a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:06:57.998901Z",
     "start_time": "2024-11-10T13:06:57.992614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DatasetGenerator:\n",
    "    def __init__(self, mnist_data, n_bags=1000, min_instances=3, max_instances=5):\n",
    "        self.mnist_data = mnist_data\n",
    "        self.n_bags = n_bags\n",
    "        self.min_instances = min_instances\n",
    "        self.max_instances = max_instances\n",
    "        self.empty_image = torch.zeros(1, 28, 28)  # Create an empty image tensor (1x28x28)\n",
    "\n",
    "    def create_bags(self):\n",
    "        bags = []\n",
    "        labels = []\n",
    "        \n",
    "        for _ in range(self.n_bags):\n",
    "            # Randomly choose a number of instances for the bag\n",
    "            n_instances = np.random.randint(self.min_instances, self.max_instances + 1)\n",
    "            \n",
    "            # Randomly select instances from the dataset\n",
    "            bag_indices = np.random.choice(len(self.mnist_data), n_instances, replace=False)\n",
    "            bag_images = [self.mnist_data[i][0] for i in bag_indices]\n",
    "            \n",
    "            # Determine the label: 1 if any instance is '9', else 0\n",
    "            label = 1 if any(self.mnist_data[i][1] == 9 for i in bag_indices) else 0\n",
    "            \n",
    "            # Convert images to tensors and pad to ensure exactly 7 instances\n",
    "            bag_images_tensors = [ToTensor()(img) for img in bag_images]\n",
    "            while len(bag_images_tensors) < 7:\n",
    "                bag_images_tensors.append(self.empty_image)  # Pad with empty image\n",
    "            \n",
    "            bags.append(torch.stack(bag_images_tensors))\n",
    "            labels.append(label)\n",
    "\n",
    "        return bags, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_bags\n",
    "\n",
    "class TrainDatasetGenerator(DatasetGenerator):\n",
    "    def __init__(self, mnist_data, n_bags=1000):\n",
    "        super().__init__(mnist_data, n_bags)\n",
    "\n",
    "class TestDatasetGenerator(DatasetGenerator):\n",
    "    def __init__(self, mnist_data, n_bags=500):  # Example: fewer bags for testing\n",
    "        super().__init__(mnist_data, n_bags)"
   ],
   "id": "281273ab749216c9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load MNIST dataset",
   "id": "fc33f943a56bb7c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:06:58.891298Z",
     "start_time": "2024-11-10T13:06:58.043431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load MNIST dataset\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True)\n",
    "\n",
    "# Create training dataset generator and generate bags\n",
    "train_generator = TrainDatasetGenerator(mnist_dataset)\n",
    "train_bags, train_labels = train_generator.create_bags()\n",
    "train_loader = DataLoader(list(zip(train_bags, train_labels)), batch_size=32, shuffle=True)\n",
    "\n",
    "# Create test dataset generator and generate bags\n",
    "test_generator = TestDatasetGenerator(mnist_dataset)\n",
    "test_bags, test_labels = test_generator.create_bags()\n",
    "test_loader = DataLoader(list(zip(test_bags, test_labels)), batch_size=16, shuffle=True)"
   ],
   "id": "3c7eb60ea8a0e888",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define the GP Model with GPyTorch",
   "id": "e247bc25a169366d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PG Likelihood Function",
   "id": "9aa9aa80d63042a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:06:58.902779Z",
     "start_time": "2024-11-10T13:06:58.900368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PGLikelihood(gpytorch.likelihoods._OneDimensionalLikelihood):\n",
    "    # this method effectively computes the expected log likelihood\n",
    "    # contribution to Eqn (10) in Reference [1].\n",
    "    def expected_log_prob(self, target, input, *args, **kwargs):\n",
    "        mean, variance = input.mean, input.variance\n",
    "        # Compute the expectation E[f_i^2]\n",
    "        raw_second_moment = variance + mean.pow(2)\n",
    "\n",
    "        # Translate targets to be -1, 1\n",
    "        target = target.to(mean.dtype).mul(2.).sub(1.)\n",
    "\n",
    "        # We detach the following variable since we do not want\n",
    "        # to differentiate through the closed-form PG update.\n",
    "        c = raw_second_moment.detach().sqrt()\n",
    "        # Compute mean of PG auxiliary variable omega: 0.5 * Expectation[omega]\n",
    "        # See Eqn (11) and Appendix A2 and A3 in Reference [1] for details.\n",
    "        half_omega = 0.25 * torch.tanh(0.5 * c) / c\n",
    "\n",
    "        # Expected log likelihood\n",
    "        res = 0.5 * target * mean - half_omega * raw_second_moment\n",
    "        # Sum over data points in mini-batch\n",
    "        res = res.sum(dim=-1)\n",
    "\n",
    "        return res\n",
    "\n",
    "    # define the likelihood\n",
    "    def forward(self, function_samples):\n",
    "        return torch.distributions.Bernoulli(logits=function_samples)\n",
    "\n",
    "    # define the marginal likelihood using Gauss Hermite quadrature\n",
    "    def marginal(self, function_dist):\n",
    "        prob_lambda = lambda function_samples: self.forward(function_samples).probs\n",
    "        probs = self.quadrature(prob_lambda, function_dist)\n",
    "        return torch.distributions.Bernoulli(probs=probs)"
   ],
   "id": "ea56bf4eb6e1c32e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### GP Model",
   "id": "55fc2ca5e0451170"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:06:58.941772Z",
     "start_time": "2024-11-10T13:06:58.936955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        variational_distribution = gpytorch.variational.NaturalVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super(GPModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ],
   "id": "a350d715658021a9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:06:58.992488Z",
     "start_time": "2024-11-10T13:06:58.985439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "M = 30\n",
    "inducing_points = torch.linspace(-2., 2., M).unsqueeze(-1).expand(-1, 784)\n",
    "# inducing_points = torch.randn(M, 1)\n",
    "model = GPModel(inducing_points)\n",
    "model.covar_module.base_kernel.lengthscale = 0.2\n",
    "likelihood = PGLikelihood()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "likelihood = likelihood.to(device)"
   ],
   "id": "37a707bc7994a06b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set up optimizer",
   "id": "9499551276b431f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:06:59.041772Z",
     "start_time": "2024-11-10T13:06:59.034986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "variational_ngd_optimizer = gpytorch.optim.NGD(model.variational_parameters(), num_data=train_generator.__len__())\n",
    "\n",
    "parameters_optimizer = torch.optim.Adam([\n",
    "    {'params': model.hyperparameters()},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=0.01)"
   ],
   "id": "ed5e1b67d919a34",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training the model",
   "id": "f159f7b5d3c3569a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:06:59.288111Z",
     "start_time": "2024-11-10T13:06:59.089807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, train_labels.__len__())\n",
    "epochs_iter = tqdm.tqdm(range(100), desc=\"Epoch\")\n",
    "\n",
    "for i in epochs_iter:\n",
    "    minibatch_iter = tqdm.tqdm(train_loader, desc=\"Minibatch\", leave=False)\n",
    "    \n",
    "    for minibatch, labels in minibatch_iter:\n",
    "        minibatch, labels = minibatch.to(device), labels.to(device)\n",
    "        # print(f'Shape of minibatch: {minibatch.shape}')\n",
    "        minibatch = minibatch.view(-1, 1 * 28 * 28)\n",
    "        def closure():\n",
    "            parameters_optimizer.zero_grad()\n",
    "            output = model(minibatch)\n",
    "            loss = -mll(output, labels)\n",
    "            return loss\n",
    "        \n",
    "        parameters_optimizer.step(closure)\n",
    "        \n",
    "        def closure():\n",
    "            variational_ngd_optimizer.zero_grad()\n",
    "            output = model(minibatch)\n",
    "            loss = -mll(output, labels)\n",
    "            return loss\n",
    "        \n",
    "        variational_ngd_optimizer.step(closure)"
   ],
   "id": "1a790033a40e0001",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Minibatch:   0%|          | 0/32 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]   \u001B[A\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (224) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 23\u001B[0m\n\u001B[1;32m     20\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mmll(output, labels)\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss\n\u001B[0;32m---> 23\u001B[0m \u001B[43mparameters_optimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mclosure\u001B[39m():\n\u001B[1;32m     26\u001B[0m     variational_ngd_optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/optim/optimizer.py:484\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    479\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    480\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    481\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    482\u001B[0m             )\n\u001B[0;32m--> 484\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    485\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    487\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/optim/optimizer.py:89\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     87\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     88\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 89\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     91\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/torch/optim/adam.py:205\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m closure \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39menable_grad():\n\u001B[0;32m--> 205\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_groups:\n\u001B[1;32m    208\u001B[0m     params_with_grad: List[Tensor] \u001B[38;5;241m=\u001B[39m []\n",
      "Cell \u001B[0;32mIn[10], line 20\u001B[0m, in \u001B[0;36mclosure\u001B[0;34m()\u001B[0m\n\u001B[1;32m     18\u001B[0m parameters_optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     19\u001B[0m output \u001B[38;5;241m=\u001B[39m model(minibatch)\n\u001B[0;32m---> 20\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[43mmll\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/module.py:31\u001B[0m, in \u001B[0;36mModule.__call__\u001B[0;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[Tensor, Distribution, LinearOperator]:\n\u001B[0;32m---> 31\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(outputs, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [_validate_module_outputs(output) \u001B[38;5;28;01mfor\u001B[39;00m output \u001B[38;5;129;01min\u001B[39;00m outputs]\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/mlls/variational_elbo.py:77\u001B[0m, in \u001B[0;36mVariationalELBO.forward\u001B[0;34m(self, variational_dist_f, target, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, variational_dist_f, target, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     64\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    Computes the Variational ELBO given :math:`q(\\mathbf f)` and :math:`\\mathbf y`.\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;124;03m    Calling this function will call the likelihood's :meth:`~gpytorch.likelihoods.Likelihood.expected_log_prob`\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;124;03m    :return: Variational ELBO. Output shape corresponds to batch shape of the model/input data.\u001B[39;00m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvariational_dist_f\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/mlls/_approximate_mll.py:58\u001B[0m, in \u001B[0;36m_ApproximateMarginalLogLikelihood.forward\u001B[0;34m(self, approximate_dist_f, target, **kwargs)\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# Get likelihood term and KL term\u001B[39;00m\n\u001B[1;32m     57\u001B[0m num_batch \u001B[38;5;241m=\u001B[39m approximate_dist_f\u001B[38;5;241m.\u001B[39mevent_shape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m---> 58\u001B[0m log_likelihood \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_log_likelihood_term\u001B[49m\u001B[43m(\u001B[49m\u001B[43mapproximate_dist_f\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdiv(num_batch)\n\u001B[1;32m     59\u001B[0m kl_divergence \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mvariational_strategy\u001B[38;5;241m.\u001B[39mkl_divergence()\u001B[38;5;241m.\u001B[39mdiv(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_data \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta)\n\u001B[1;32m     61\u001B[0m \u001B[38;5;66;03m# Add any additional registered loss terms\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/gpytorch/mlls/variational_elbo.py:61\u001B[0m, in \u001B[0;36mVariationalELBO._log_likelihood_term\u001B[0;34m(self, variational_dist_f, target, **kwargs)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_log_likelihood_term\u001B[39m(\u001B[38;5;28mself\u001B[39m, variational_dist_f, target, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 61\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlikelihood\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpected_log_prob\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariational_dist_f\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msum(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[0;32mIn[6], line 20\u001B[0m, in \u001B[0;36mPGLikelihood.expected_log_prob\u001B[0;34m(self, target, input, *args, **kwargs)\u001B[0m\n\u001B[1;32m     17\u001B[0m half_omega \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.25\u001B[39m \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39mtanh(\u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m c) \u001B[38;5;241m/\u001B[39m c\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Expected log likelihood\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmean\u001B[49m \u001B[38;5;241m-\u001B[39m half_omega \u001B[38;5;241m*\u001B[39m raw_second_moment\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Sum over data points in mini-batch\u001B[39;00m\n\u001B[1;32m     22\u001B[0m res \u001B[38;5;241m=\u001B[39m res\u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (32) must match the size of tensor b (224) at non-singleton dimension 0"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing",
   "id": "2f335ac711535b06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for minibatch, labels in test_loader:\n",
    "        minibatch, labels = minibatch.to(device), labels.to(device)\n",
    "        \n",
    "        with gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\n",
    "            output = model(minibatch)\n",
    "            preds = likelihood(output).probs.mean > 0.5\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ],
   "id": "c4f66f9ebc272efb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## References",
   "id": "2db22aff1804c76d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4df57fb562f27b27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ea1d788308df0188"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e5f0c40356de74c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
