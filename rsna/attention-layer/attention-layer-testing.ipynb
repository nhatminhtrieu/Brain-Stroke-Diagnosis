{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Attention Layer",
   "id": "4a63a61a889046d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Lib",
   "id": "8ef192d740d3f9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:16:48.596861Z",
     "start_time": "2024-10-16T16:16:48.594257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.xpu import device\n",
    "from torchvision import models\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "\n",
    "import gpytorch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ],
   "id": "743be51811c9768d",
   "outputs": [],
   "execution_count": 282
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:16:48.613949Z",
     "start_time": "2024-10-16T16:16:48.600081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set a fixed seed value\n",
    "seed_value = 40\n",
    "# Set the random seed for Python's built-in random module\n",
    "random.seed(seed_value)\n",
    "# Set the random seed for NumPy\n",
    "np.random.seed(seed_value)\n",
    "# Set the random seed for PyTorch\n",
    "torch.manual_seed(seed_value)\n",
    "\n",
    "# If using CUDA, set the seed for GPU as well (if applicable)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed_value)"
   ],
   "id": "6b8e1153f8ca7340",
   "outputs": [],
   "execution_count": 283
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:16:48.648764Z",
     "start_time": "2024-10-16T16:16:48.644537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ],
   "id": "590e5508bccbb47b",
   "outputs": [],
   "execution_count": 284
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preparation",
   "id": "9d7ae223d9dfa27d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:16:48.707807Z",
     "start_time": "2024-10-16T16:16:48.693646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DatasetGenerator:\n",
    "    def __init__(self, mnist_data, n_bags=1000, min_instances=3, max_instances=5):\n",
    "        self.mnist_data = mnist_data\n",
    "        self.n_bags = n_bags\n",
    "        self.min_instances = min_instances\n",
    "        self.max_instances = max_instances\n",
    "        self.empty_image = torch.zeros(1, 28, 28)  # Create an empty image tensor (1x28x28)\n",
    "\n",
    "    def create_bags(self):\n",
    "        bags = []\n",
    "        labels = []\n",
    "        \n",
    "        for _ in range(self.n_bags):\n",
    "            # Randomly choose a number of instances for the bag\n",
    "            n_instances = np.random.randint(self.min_instances, self.max_instances + 1)\n",
    "            \n",
    "            # Randomly select instances from the dataset\n",
    "            bag_indices = np.random.choice(len(self.mnist_data), n_instances, replace=False)\n",
    "            bag_images = [self.mnist_data[i][0] for i in bag_indices]\n",
    "            \n",
    "            # Determine the label: 1 if any instance is '9', else 0\n",
    "            label = 1 if any(self.mnist_data[i][1] == 9 for i in bag_indices) else 0\n",
    "            \n",
    "            # Convert images to tensors and pad to ensure exactly 7 instances\n",
    "            bag_images_tensors = [ToTensor()(img) for img in bag_images]\n",
    "            while len(bag_images_tensors) < 7:\n",
    "                bag_images_tensors.append(self.empty_image)  # Pad with empty image\n",
    "            \n",
    "            bags.append(torch.stack(bag_images_tensors))\n",
    "            labels.append(label)\n",
    "\n",
    "        return bags, labels\n",
    "\n",
    "class TrainDatasetGenerator(DatasetGenerator):\n",
    "    def __init__(self, mnist_data, n_bags=1000):\n",
    "        super().__init__(mnist_data, n_bags)\n",
    "\n",
    "class TestDatasetGenerator(DatasetGenerator):\n",
    "    def __init__(self, mnist_data, n_bags=500):  # Example: fewer bags for testing\n",
    "        super().__init__(mnist_data, n_bags)"
   ],
   "id": "b0c74e22e200f87c",
   "outputs": [],
   "execution_count": 285
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:16:49.627756Z",
     "start_time": "2024-10-16T16:16:48.750660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load MNIST dataset\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True)\n",
    "\n",
    "# Create training dataset generator and generate bags\n",
    "train_generator = TrainDatasetGenerator(mnist_dataset)\n",
    "train_bags, train_labels = train_generator.create_bags()\n",
    "train_loader = DataLoader(list(zip(train_bags, train_labels)), batch_size=32, shuffle=True)\n",
    "\n",
    "# Create test dataset generator and generate bags\n",
    "test_generator = TestDatasetGenerator(mnist_dataset)\n",
    "test_bags, test_labels = test_generator.create_bags()\n",
    "test_loader = DataLoader(list(zip(test_bags, test_labels)), batch_size=16, shuffle=True)"
   ],
   "id": "a04b09c68297d96f",
   "outputs": [],
   "execution_count": 286
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Attention Layer",
   "id": "222827e790c53375"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:16:49.637781Z",
     "start_time": "2024-10-16T16:16:49.636454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# class SelfAttention(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(SelfAttention, self).__init__()\n",
    "#         self.input_dim = input_dim\n",
    "#         self.query = nn.Linear(input_dim, input_dim)\n",
    "#         self.key = nn.Linear(input_dim, input_dim)\n",
    "#         self.value = nn.Linear(input_dim, input_dim)\n",
    "#         self.softmax = nn.Softmax(dim=2)\n",
    "# \n",
    "#     def forward(self, x):  # x.shape (batch_size, seq_length, input_dim)\n",
    "#         queries = self.query(x)\n",
    "#         keys = self.key(x)\n",
    "#         values = self.value(x)\n",
    "# \n",
    "#         score = torch.bmm(queries, keys.transpose(1, 2)) / (self.input_dim ** 0.5)\n",
    "#         attention = self.softmax(score)\n",
    "#         weighted = torch.bmm(attention, values)\n",
    "#         return weighted, attention"
   ],
   "id": "5fd7e2264f02a74b",
   "outputs": [],
   "execution_count": 287
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:16:49.684083Z",
     "start_time": "2024-10-16T16:16:49.680087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            # nn.ReLU(),\n",
    "            # nn.PReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_instances, feature_dim)\n",
    "        attention_weights = self.attention(x)\n",
    "        weights = F.softmax(attention_weights, dim=1)\n",
    "        return (x * weights).sum(dim=1), weights.squeeze(-1)"
   ],
   "id": "a0c5dbb8cfefc24c",
   "outputs": [],
   "execution_count": 288
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Gaussian Process Layer",
   "id": "184e116b03eebef0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:16:49.737480Z",
     "start_time": "2024-10-16T16:16:49.729864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super(GPModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ],
   "id": "dbf94e502c230128",
   "outputs": [],
   "execution_count": 289
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MIL Model",
   "id": "60671b87cb13ea1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:16:49.792563Z",
     "start_time": "2024-10-16T16:16:49.781002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MILResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MILResNet18, self).__init__()\n",
    "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        self.resnet.fc = nn.Identity()\n",
    "        self.attention = AttentionLayer(input_dim=512)\n",
    "        self.classifier = nn.Linear(512 + 1, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Define inducing points for the GP layer\n",
    "        # inducing_points = torch.randn(250, 512)\n",
    "        inducing_points = torch.full((512, 512), 1e-20)  \n",
    "        self.gp_layer = GPModel(inducing_points)\n",
    "\n",
    "    def forward(self, bags):\n",
    "        batch_size, num_instances = bags.size(0), bags.size(1)\n",
    "        bags_flattened = bags.view(-1, *bags.shape[2:])\n",
    "        \n",
    "        features = self.resnet(bags_flattened)\n",
    "        features = features.view(batch_size, num_instances, -1)\n",
    "        attended_features, attended_weights = self.attention(features)\n",
    "        \n",
    "        attended_features_reshaped = attended_features.view(-1, 512)\n",
    "        gp_output = self.gp_layer(attended_features_reshaped)\n",
    "        gp_mean = gp_output.mean.view(batch_size, -1)\n",
    "        \n",
    "        combine_features = torch.cat((attended_features, gp_mean), dim=1)\n",
    "        outputs = torch.sigmoid(self.classifier(combine_features))\n",
    "        return outputs, attended_weights"
   ],
   "id": "68ab01e85b8a8e07",
   "outputs": [],
   "execution_count": 290
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Process",
   "id": "1e9c93e0734c3f8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loss Function",
   "id": "7dca4a53c8cf6042"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:16:49.894474Z",
     "start_time": "2024-10-16T16:16:49.888908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combined_loss(outputs, gp_distribution, target, alpha=0.5):\n",
    "    # Cross-Entropy Loss for CNN outputs\n",
    "    bce_loss = nn.BCELoss()(outputs.squeeze(), target.float())\n",
    "    kl_divergence = gp_distribution.variational_strategy.kl_divergence()\n",
    "    total_loss = (1 - alpha) * bce_loss + alpha * kl_divergence\n",
    "    \n",
    "    return total_loss"
   ],
   "id": "a1fdc800f3638c7b",
   "outputs": [],
   "execution_count": 292
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training Loop",
   "id": "14baa8180e2ba67d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:16:52.471386Z",
     "start_time": "2024-10-16T16:16:49.946733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, dataloader, epochs=5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        all_labels = []\n",
    "        all_outputs = []\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch_images, batch_labels in dataloader:\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs, attended_weights = model(batch_images.float())\n",
    "            loss = combined_loss(outputs.squeeze(), model.gp_layer, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Collect outputs and labels for metrics calculation\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "            all_outputs.extend((outputs.squeeze().cpu().detach().numpy() > 0.5).astype(int))  # Binarize outputs\n",
    "\n",
    "        # Calculate metrics\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = accuracy_score(all_labels, all_outputs)\n",
    "        recall = recall_score(all_labels, all_outputs)\n",
    "        precision = precision_score(all_labels, all_outputs)\n",
    "        f1 = f1_score(all_labels, all_outputs)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, '\n",
    "              f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f},F1 Score: {f1:.4f}')\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MILResNet18()\n",
    "model.to(device)\n",
    "\n",
    "train(model, train_loader)"
   ],
   "id": "48899664dd45f891",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.2538, Accuracy: 0.7860, Precision: 0.7246, Recall: 0.4886,F1 Score: 0.5837\n",
      "Epoch [2/5], Loss: 0.1294, Accuracy: 0.9060, Precision: 0.8763, Recall: 0.8078,F1 Score: 0.8407\n",
      "Epoch [3/5], Loss: 0.0650, Accuracy: 0.9540, Precision: 0.9454, Recall: 0.9023,F1 Score: 0.9233\n",
      "Epoch [4/5], Loss: 0.0750, Accuracy: 0.9490, Precision: 0.9129, Recall: 0.9218,F1 Score: 0.9173\n",
      "Epoch [5/5], Loss: 0.0481, Accuracy: 0.9650, Precision: 0.9564, Recall: 0.9283,F1 Score: 0.9421\n"
     ]
    }
   ],
   "execution_count": 293
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing Process",
   "id": "cd71439a580ec535"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:16:52.734524Z",
     "start_time": "2024-10-16T16:16:52.479873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    all_attended_weights = []  # Store attended weights for visualization\n",
    "    images_to_plot = []  # Store images with label = 1\n",
    "    weights_to_plot = []  # Store attended weights for images with label = 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_images, batch_labels in dataloader:\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs, attended_weights = model(batch_images.float())\n",
    "            \n",
    "            # Collect outputs and labels for metrics calculation\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "            all_outputs.extend((outputs.squeeze().cpu().detach().numpy() > 0.5).astype(int))  # Binarize outputs\n",
    "\n",
    "            # Check for images with label = 1\n",
    "            for i in range(len(batch_labels)):\n",
    "                if batch_labels[i] == 0:\n",
    "                    images_to_plot.append(batch_images[i].cpu().numpy())\n",
    "                    weights_to_plot.append(attended_weights[i].squeeze().cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_outputs)\n",
    "    recall = recall_score(all_labels, all_outputs)\n",
    "    precision = precision_score(all_labels, all_outputs)\n",
    "    f1 = f1_score(all_labels, all_outputs)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f},F1 Score: {f1:.4f}')\n",
    "\n",
    "    # Plotting attended weights for images with label = 1\n",
    "    if images_to_plot:  # Check if there are any images to plot\n",
    "        plot_attended_weights(np.array(images_to_plot), np.array(weights_to_plot))\n",
    "\n",
    "def plot_attended_weights(images, attended_weights):\n",
    "    \"\"\"\n",
    "    Plots the original images and their corresponding attended weights in a single figure.\n",
    "\n",
    "    Args:\n",
    "        images (numpy array): A batch of input image arrays.\n",
    "        attended_weights (numpy array): The attended weights corresponding to the images.\n",
    "    \"\"\"\n",
    "    images = images[0]\n",
    "    attended_weights = attended_weights[0]\n",
    "    num_images = images.shape[0]  # Number of images to plot\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 4, 8))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(images[i].transpose(1, 2, 0))  # Change from CHW to HWC format\n",
    "        axes[i].set_title(f'Image {i + 1} - {attended_weights[i]:.4f}')\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Call the test function with your model and test loader\n",
    "test(model, test_loader)"
   ],
   "id": "4f04580fad06751e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9360, Precision: 0.8769, Recall: 0.9553,F1 Score: 0.9144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2800x800 with 7 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 294
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## References:\n",
    "[1] https://medium.com/@wangdk93/implement-self-attention-and-cross-attention-in-pytorch-1f1a366c9d4b"
   ],
   "id": "77de1738b73d62c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
