{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Attention Layer",
   "id": "4a63a61a889046d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Lib",
   "id": "8ef192d740d3f9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T16:01:48.579509Z",
     "start_time": "2024-10-11T16:01:47.232737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.xpu import device\n",
    "from torchvision import models\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ],
   "id": "743be51811c9768d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T16:01:48.605845Z",
     "start_time": "2024-10-11T16:01:48.582302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set a fixed seed value\n",
    "seed_value = 40\n",
    "\n",
    "# Set the random seed for Python's built-in random module\n",
    "random.seed(seed_value)\n",
    "\n",
    "# Set the random seed for NumPy\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Set the random seed for PyTorch\n",
    "torch.manual_seed(seed_value)\n",
    "\n",
    "# If using CUDA, set the seed for GPU as well (if applicable)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed_value)\n"
   ],
   "id": "6b8e1153f8ca7340",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T16:01:48.630084Z",
     "start_time": "2024-10-11T16:01:48.628336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ],
   "id": "590e5508bccbb47b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preparation",
   "id": "9d7ae223d9dfa27d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T16:01:48.674578Z",
     "start_time": "2024-10-11T16:01:48.670358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "class DatasetGenerator:\n",
    "    def __init__(self, mnist_data, n_bags=1000, min_instances=3, max_instances=5):\n",
    "        self.mnist_data = mnist_data\n",
    "        self.n_bags = n_bags\n",
    "        self.min_instances = min_instances\n",
    "        self.max_instances = max_instances\n",
    "        self.empty_image = torch.zeros(1, 28, 28)  # Create an empty image tensor (1x28x28)\n",
    "\n",
    "    def create_bags(self):\n",
    "        bags = []\n",
    "        labels = []\n",
    "        \n",
    "        for _ in range(self.n_bags):\n",
    "            # Randomly choose a number of instances for the bag\n",
    "            n_instances = np.random.randint(self.min_instances, self.max_instances + 1)\n",
    "            \n",
    "            # Randomly select instances from the dataset\n",
    "            bag_indices = np.random.choice(len(self.mnist_data), n_instances, replace=False)\n",
    "            bag_images = [self.mnist_data[i][0] for i in bag_indices]\n",
    "            \n",
    "            # Determine the label: 1 if any instance is '9', else 0\n",
    "            label = 1 if any(self.mnist_data[i][1] == 9 for i in bag_indices) else 0\n",
    "            \n",
    "            # Convert images to tensors and pad to ensure exactly 7 instances\n",
    "            bag_images_tensors = [ToTensor()(img) for img in bag_images]\n",
    "            while len(bag_images_tensors) < 7:\n",
    "                bag_images_tensors.append(self.empty_image)  # Pad with empty image\n",
    "            \n",
    "            bags.append(torch.stack(bag_images_tensors))\n",
    "            labels.append(label)\n",
    "\n",
    "        return bags, labels\n",
    "\n",
    "class TrainDatasetGenerator(DatasetGenerator):\n",
    "    def __init__(self, mnist_data, n_bags=1000):\n",
    "        super().__init__(mnist_data, n_bags)\n",
    "\n",
    "class TestDatasetGenerator(DatasetGenerator):\n",
    "    def __init__(self, mnist_data, n_bags=500):  # Example: fewer bags for testing\n",
    "        super().__init__(mnist_data, n_bags)"
   ],
   "id": "b0c74e22e200f87c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T16:01:49.570274Z",
     "start_time": "2024-10-11T16:01:48.721568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load MNIST dataset\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True)\n",
    "\n",
    "# Create training dataset generator and generate bags\n",
    "train_generator = TrainDatasetGenerator(mnist_dataset)\n",
    "train_bags, train_labels = train_generator.create_bags()\n",
    "train_loader = DataLoader(list(zip(train_bags, train_labels)), batch_size=32, shuffle=True)\n",
    "\n",
    "# Create test dataset generator and generate bags\n",
    "test_generator = TestDatasetGenerator(mnist_dataset)\n",
    "test_bags, test_labels = test_generator.create_bags()\n",
    "# Create DataLoader for testing\n",
    "test_loader = DataLoader(list(zip(test_bags, test_labels)), batch_size=16, shuffle=True)"
   ],
   "id": "a04b09c68297d96f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Attention Layer",
   "id": "222827e790c53375"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T16:01:49.581889Z",
     "start_time": "2024-10-11T16:01:49.579641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# class SelfAttention(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(SelfAttention, self).__init__()\n",
    "#         self.input_dim = input_dim\n",
    "#         self.query = nn.Linear(input_dim, input_dim)\n",
    "#         self.key = nn.Linear(input_dim, input_dim)\n",
    "#         self.value = nn.Linear(input_dim, input_dim)\n",
    "#         self.softmax = nn.Softmax(dim=2)\n",
    "# \n",
    "#     def forward(self, x):  # x.shape (batch_size, seq_length, input_dim)\n",
    "#         queries = self.query(x)\n",
    "#         keys = self.key(x)\n",
    "#         values = self.value(x)\n",
    "# \n",
    "#         score = torch.bmm(queries, keys.transpose(1, 2)) / (self.input_dim ** 0.5)\n",
    "#         attention = self.softmax(score)\n",
    "#         weighted = torch.bmm(attention, values)\n",
    "#         return weighted, attention\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            # nn.Tanh(),\n",
    "            # nn.ReLU(),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_instances, feature_dim)\n",
    "        attention_weights = self.attention(x)\n",
    "        weights = F.softmax(attention_weights, dim=1)\n",
    "\n",
    "        return (x * weights).sum(dim=1), weights.squeeze(-1)"
   ],
   "id": "a0c5dbb8cfefc24c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MIL-CNN Model",
   "id": "f63c6e77d47a7914"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T16:01:49.619546Z",
     "start_time": "2024-10-11T16:01:49.616407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MILResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MILResNet18, self).__init__()\n",
    "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        # Modify the first convolutional layer to accept grayscale images\n",
    "        # Change in_channels from 3 to 1\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet.fc = nn.Identity()  # Remove the final classification layer\n",
    "        # self.resnet.maxpool = nn.AdaptiveAvgPool2d((1, 1))  # Replace max pooling with average pooling\n",
    "        self.attention = AttentionLayer(input_dim=512)  # Assuming output dim from ResNet is 512\n",
    "        self.classifier = nn.Linear(512, 1)  # Binary classification\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "      \n",
    "    def forward(self, bags):\n",
    "        # bags.shape: (batch_size, num_instances, channels, height, width)\n",
    "        batch_size, num_instances = bags.size(0), bags.size(1)\n",
    "        \n",
    "        # Flatten to (batch_size * num_instances, channels, height, width)\n",
    "        bags_flattened = bags.view(-1, *bags.shape[2:])\n",
    "        \n",
    "        # Get features from ResNet\n",
    "        features = self.resnet(bags_flattened)  # Shape: (batch_size * num_instances, 512)\n",
    "\n",
    "        # Reshape back to (batch_size, num_instances, 512)\n",
    "        features = features.view(batch_size, num_instances, -1)\n",
    "\n",
    "        # Apply attention mechanism\n",
    "        attended_features, attended_weights = self.attention(features)\n",
    "\n",
    "        # Aggregate features (e.g., mean pooling)\n",
    "        # aggregated_features = attended_features.mean(dim=1)  # Shape: (batch_size, 512)\n",
    "        \n",
    "        # dropped_features = self.dropout(aggregated_features)\n",
    "        dropped_features = self.dropout(attended_features)\n",
    "        # Classify bag\n",
    "        outputs = torch.sigmoid(self.classifier(dropped_features))\n",
    "        \n",
    "        return outputs, attended_weights"
   ],
   "id": "eeb49b1fb73f9119",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Process",
   "id": "1e9c93e0734c3f8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T16:01:56.797026Z",
     "start_time": "2024-10-11T16:01:49.666454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, dataloader, epochs=20):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        all_labels = []\n",
    "        all_outputs = []\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_images, batch_labels in dataloader:\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, _ = model(batch_images.float())\n",
    "            loss = criterion(outputs.squeeze(), batch_labels.float())\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Collect outputs and labels for metrics calculation\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "            all_outputs.extend((outputs.squeeze().cpu().detach().numpy() > 0.5).astype(int))  # Binarize outputs\n",
    "            \n",
    "        # Calculate metrics\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = accuracy_score(all_labels, all_outputs)\n",
    "        precision = precision_score(all_labels, all_outputs)\n",
    "        f1 = f1_score(all_labels, all_outputs)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, '\n",
    "              f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MILResNet18()\n",
    "model.to(device)\n",
    "\n",
    "train(model, train_loader)"
   ],
   "id": "48899664dd45f891",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.5074, Accuracy: 0.7800, Precision: 0.7122, F1 Score: 0.5703\n",
      "Epoch [2/20], Loss: 0.2345, Accuracy: 0.9160, Precision: 0.8704, F1 Score: 0.8618\n",
      "Epoch [3/20], Loss: 0.1918, Accuracy: 0.9320, Precision: 0.9193, F1 Score: 0.8851\n",
      "Epoch [4/20], Loss: 0.0981, Accuracy: 0.9700, Precision: 0.9632, F1 Score: 0.9505\n",
      "Epoch [5/20], Loss: 0.0937, Accuracy: 0.9680, Precision: 0.9630, F1 Score: 0.9470\n",
      "Epoch [6/20], Loss: 0.0727, Accuracy: 0.9800, Precision: 0.9767, F1 Score: 0.9671\n",
      "Epoch [7/20], Loss: 0.0762, Accuracy: 0.9750, Precision: 0.9669, F1 Score: 0.9589\n",
      "Epoch [8/20], Loss: 0.0547, Accuracy: 0.9850, Precision: 0.9834, F1 Score: 0.9754\n",
      "Epoch [9/20], Loss: 0.0708, Accuracy: 0.9810, Precision: 0.9737, F1 Score: 0.9689\n",
      "Epoch [10/20], Loss: 0.0730, Accuracy: 0.9740, Precision: 0.9607, F1 Score: 0.9575\n",
      "Epoch [11/20], Loss: 0.0517, Accuracy: 0.9860, Precision: 0.9835, F1 Score: 0.9770\n",
      "Epoch [12/20], Loss: 0.0306, Accuracy: 0.9880, Precision: 0.9836, F1 Score: 0.9804\n",
      "Epoch [13/20], Loss: 0.0601, Accuracy: 0.9830, Precision: 0.9833, F1 Score: 0.9720\n",
      "Epoch [14/20], Loss: 0.0161, Accuracy: 0.9940, Precision: 0.9902, F1 Score: 0.9902\n",
      "Epoch [15/20], Loss: 0.0030, Accuracy: 1.0000, Precision: 1.0000, F1 Score: 1.0000\n",
      "Epoch [16/20], Loss: 0.0019, Accuracy: 1.0000, Precision: 1.0000, F1 Score: 1.0000\n",
      "Epoch [17/20], Loss: 0.0415, Accuracy: 0.9920, Precision: 0.9934, F1 Score: 0.9869\n",
      "Epoch [18/20], Loss: 0.0542, Accuracy: 0.9840, Precision: 0.9866, F1 Score: 0.9736\n",
      "Epoch [19/20], Loss: 0.0456, Accuracy: 0.9830, Precision: 0.9618, F1 Score: 0.9726\n",
      "Epoch [20/20], Loss: 0.0323, Accuracy: 0.9860, Precision: 0.9741, F1 Score: 0.9773\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing Process",
   "id": "cd71439a580ec535"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T16:01:57.112519Z",
     "start_time": "2024-10-11T16:01:56.817440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    all_attended_weights = []  # Store attended weights for visualization\n",
    "    images_to_plot = []  # Store images with label = 1\n",
    "    weights_to_plot = []  # Store attended weights for images with label = 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_images, batch_labels in dataloader:\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs, attended_weights = model(batch_images.float())\n",
    "\n",
    "            # Collect outputs and labels for metrics calculation\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "            all_outputs.extend((outputs.squeeze().cpu().detach().numpy() > 0.5).astype(int))  # Binarize outputs\n",
    "\n",
    "            # Check for images with label = 1\n",
    "            for i in range(len(batch_labels)):\n",
    "                if batch_labels[i] == 1:\n",
    "                    images_to_plot.append(batch_images[i].cpu().numpy())\n",
    "                    weights_to_plot.append(attended_weights[i].squeeze().cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_outputs)\n",
    "    precision = precision_score(all_labels, all_outputs)\n",
    "    f1 = f1_score(all_labels, all_outputs)\n",
    "\n",
    "    print(f'Test Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "    # Plotting attended weights for images with label = 1\n",
    "    if images_to_plot:  # Check if there are any images to plot\n",
    "        plot_attended_weights(np.array(images_to_plot), np.array(weights_to_plot))\n",
    "\n",
    "def plot_attended_weights(images, attended_weights):\n",
    "    \"\"\"\n",
    "    Plots the original images and their corresponding attended weights in a single figure.\n",
    "\n",
    "    Args:\n",
    "        images (numpy array): A batch of input image arrays.\n",
    "        attended_weights (numpy array): The attended weights corresponding to the images.\n",
    "    \"\"\"\n",
    "    images = images[0]\n",
    "    attended_weights = attended_weights[0]\n",
    "    num_images = images.shape[0]  # Number of images to plot\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 4, 8))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Display the input image\n",
    "        axes[i].imshow(images[i].transpose(1, 2, 0))  # Change from CHW to HWC format\n",
    "        axes[i].set_title(f'Image {i + 1} - {attended_weights[i]:.4f}')\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "        # Plot attention weights as a bar chart\n",
    "        # axes[1, i].bar(range(attended_weights.shape[1]), attended_weights[i], color='orange', alpha=0.7)\n",
    "        # axes[1, i].set_ylim(0, 1)  # Assuming weights are normalized between 0 and 1\n",
    "        # axes[1, i].set_ylabel('Attention Weight')\n",
    "        # axes[1, i].set_xlabel('Feature Index')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Call the test function with your model and test loader\n",
    "test(model, test_loader)"
   ],
   "id": "4f04580fad06751e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9640, Precision: 1.0000, F1 Score: 0.9471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2800x800 with 7 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## References:\n",
    "[1] https://medium.com/@wangdk93/implement-self-attention-and-cross-attention-in-pytorch-1f1a366c9d4b"
   ],
   "id": "77de1738b73d62c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
