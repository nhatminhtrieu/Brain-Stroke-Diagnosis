{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Attention Layer",
   "id": "4a63a61a889046d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Lib",
   "id": "8ef192d740d3f9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:13:11.610738Z",
     "start_time": "2024-10-08T03:13:10.652383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.xpu import device\n",
    "from torchvision import models\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ],
   "id": "743be51811c9768d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preparation",
   "id": "9d7ae223d9dfa27d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:13:11.621071Z",
     "start_time": "2024-10-08T03:13:11.617198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "class DatasetGenerator:\n",
    "    def __init__(self, mnist_data, n_bags=1000, min_instances=3, max_instances=5):\n",
    "        self.mnist_data = mnist_data\n",
    "        self.n_bags = n_bags\n",
    "        self.min_instances = min_instances\n",
    "        self.max_instances = max_instances\n",
    "        self.empty_image = torch.empty(1, 28, 28)  # Create an empty image tensor (1x28x28)\n",
    "\n",
    "    def create_bags(self):\n",
    "        bags = []\n",
    "        labels = []\n",
    "        \n",
    "        for _ in range(self.n_bags):\n",
    "            # Randomly choose a number of instances for the bag\n",
    "            n_instances = np.random.randint(self.min_instances, self.max_instances + 1)\n",
    "            \n",
    "            # Randomly select instances from the dataset\n",
    "            bag_indices = np.random.choice(len(self.mnist_data), n_instances, replace=False)\n",
    "            bag_images = [self.mnist_data[i][0] for i in bag_indices]\n",
    "            \n",
    "            # Determine the label: 1 if any instance is '9', else 0\n",
    "            label = 1 if any(self.mnist_data[i][1] == 9 for i in bag_indices) else 0\n",
    "            \n",
    "            # Convert images to tensors and pad to ensure exactly 7 instances\n",
    "            bag_images_tensors = [ToTensor()(img) for img in bag_images]\n",
    "            while len(bag_images_tensors) < 7:\n",
    "                bag_images_tensors.append(self.empty_image)  # Pad with empty image\n",
    "            \n",
    "            bags.append(torch.stack(bag_images_tensors))\n",
    "            labels.append(label)\n",
    "\n",
    "        return bags, labels\n",
    "\n",
    "class TrainDatasetGenerator(DatasetGenerator):\n",
    "    def __init__(self, mnist_data, n_bags=1000):\n",
    "        super().__init__(mnist_data, n_bags)\n",
    "\n",
    "class TestDatasetGenerator(DatasetGenerator):\n",
    "    def __init__(self, mnist_data, n_bags=500):  # Example: fewer bags for testing\n",
    "        super().__init__(mnist_data, n_bags)"
   ],
   "id": "b0c74e22e200f87c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:13:12.510041Z",
     "start_time": "2024-10-08T03:13:11.666401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load MNIST dataset\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True)\n",
    "\n",
    "# Create training dataset generator and generate bags\n",
    "train_generator = TrainDatasetGenerator(mnist_dataset)\n",
    "train_bags, train_labels = train_generator.create_bags()\n",
    "\n",
    "# Create DataLoader for training\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(list(zip(train_bags, train_labels)), batch_size=32, shuffle=True)\n",
    "\n",
    "# Create test dataset generator and generate bags\n",
    "test_generator = TestDatasetGenerator(mnist_dataset)\n",
    "test_bags, test_labels = test_generator.create_bags()\n",
    "\n",
    "# Create DataLoader for testing\n",
    "test_loader = DataLoader(list(zip(test_bags, test_labels)), batch_size=32, shuffle=False)"
   ],
   "id": "a04b09c68297d96f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Attention Layer",
   "id": "222827e790c53375"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:13:12.537300Z",
     "start_time": "2024-10-08T03:13:12.534271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x):  # x.shape (batch_size, seq_length, input_dim)\n",
    "        queries = self.query(x)\n",
    "        keys = self.key(x)\n",
    "        values = self.value(x)\n",
    "\n",
    "        score = torch.bmm(queries, keys.transpose(1, 2)) / (self.input_dim ** 0.5)\n",
    "        attention = self.softmax(score)\n",
    "        weighted = torch.bmm(attention, values)\n",
    "        return weighted\n"
   ],
   "id": "a0c5dbb8cfefc24c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MIL-CNN Model",
   "id": "f63c6e77d47a7914"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:13:12.558672Z",
     "start_time": "2024-10-08T03:13:12.555364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MILResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MILResNet18, self).__init__()\n",
    "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        # Modify the first convolutional layer to accept grayscale images\n",
    "        # Change in_channels from 3 to 1\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet.fc = nn.Identity()  # Remove the final classification layer\n",
    "        self.attention = SelfAttention(input_dim=512)  # Assuming output dim from ResNet is 512\n",
    "        self.classifier = nn.Linear(512, 1)  # Binary classification\n",
    "\n",
    "    def forward(self, bags):\n",
    "        # bags.shape: (batch_size, num_instances, channels, height, width)\n",
    "        batch_size, num_instances = bags.size(0), bags.size(1)\n",
    "        \n",
    "        # Flatten to (batch_size * num_instances, channels, height, width)\n",
    "        bags_flattened = bags.view(-1, *bags.shape[2:])\n",
    "        \n",
    "        # Get features from ResNet\n",
    "        features = self.resnet(bags_flattened)  # Shape: (batch_size * num_instances, 512)\n",
    "\n",
    "        # Reshape back to (batch_size, num_instances, 512)\n",
    "        features = features.view(batch_size, num_instances, -1)\n",
    "\n",
    "        # Apply attention mechanism\n",
    "        attended_features = self.attention(features)\n",
    "\n",
    "        # Aggregate features (e.g., mean pooling)\n",
    "        aggregated_features = attended_features.mean(dim=1)  # Shape: (batch_size, 512)\n",
    "        # Classify bag\n",
    "        outputs = torch.sigmoid(self.classifier(aggregated_features))\n",
    "        \n",
    "        return outputs\n"
   ],
   "id": "eeb49b1fb73f9119",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Process",
   "id": "1e9c93e0734c3f8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:13:15.582025Z",
     "start_time": "2024-10-08T03:13:12.602643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "\n",
    "def train(model, dataloader, epochs=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        all_labels = []\n",
    "        all_outputs = []\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_images, batch_labels in dataloader:\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_images.float())\n",
    "            loss = criterion(outputs.squeeze(), batch_labels.float())\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Collect outputs and labels for metrics calculation\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "            all_outputs.extend((outputs.squeeze().cpu().detach().numpy() > 0.5).astype(int))  # Binarize outputs\n",
    "            \n",
    "        # Calculate metrics\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = accuracy_score(all_labels, all_outputs)\n",
    "        precision = precision_score(all_labels, all_outputs)\n",
    "        f1 = f1_score(all_labels, all_outputs)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, '\n",
    "              f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "### Testing Function\n",
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_images, batch_labels in dataloader:\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_images.float())\n",
    "            \n",
    "            # Collect outputs and labels for metrics calculation\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "            all_outputs.extend((outputs.squeeze().cpu().detach().numpy() > 0.5).astype(int))  # Binarize outputs\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_outputs)\n",
    "    precision = precision_score(all_labels, all_outputs)\n",
    "    f1 = f1_score(all_labels, all_outputs)\n",
    "\n",
    "    print(f'Test Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MILResNet18()\n",
    "model.to(device)\n",
    "# Train the model\n",
    "train(model, train_loader)\n",
    "# Test the model\n",
    "test(model, test_loader)"
   ],
   "id": "48899664dd45f891",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7951, Accuracy: 0.6580, Precision: 0.5652, F1 Score: 0.4062\n",
      "Epoch [2/10], Loss: 0.3888, Accuracy: 0.8520, Precision: 0.8486, F1 Score: 0.7843\n",
      "Epoch [3/10], Loss: 0.2651, Accuracy: 0.9080, Precision: 0.9342, F1 Score: 0.8663\n",
      "Epoch [4/10], Loss: 0.1544, Accuracy: 0.9500, Precision: 0.9443, F1 Score: 0.9313\n",
      "Epoch [5/10], Loss: 0.1215, Accuracy: 0.9580, Precision: 0.9632, F1 Score: 0.9418\n",
      "Epoch [6/10], Loss: 0.1082, Accuracy: 0.9770, Precision: 0.9860, F1 Score: 0.9683\n",
      "Epoch [7/10], Loss: 0.1572, Accuracy: 0.9510, Precision: 0.9444, F1 Score: 0.9328\n",
      "Epoch [8/10], Loss: 0.0893, Accuracy: 0.9730, Precision: 0.9698, F1 Score: 0.9632\n",
      "Epoch [9/10], Loss: 0.0614, Accuracy: 0.9810, Precision: 0.9808, F1 Score: 0.9741\n",
      "Epoch [10/10], Loss: 0.0654, Accuracy: 0.9790, Precision: 0.9677, F1 Score: 0.9717\n",
      "Test Accuracy: 0.9360, Precision: 0.9854, F1 Score: 0.8940\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## References:\n",
    "[1] https://medium.com/@wangdk93/implement-self-attention-and-cross-attention-in-pytorch-1f1a366c9d4b"
   ],
   "id": "77de1738b73d62c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
