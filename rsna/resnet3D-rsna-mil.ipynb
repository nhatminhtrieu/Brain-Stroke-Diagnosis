{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9399351,"sourceType":"datasetVersion","datasetId":5705276}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Library","metadata":{}},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pydicom\nfrom tqdm import tqdm\nfrom skimage.transform import resize\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:52.640108Z","start_time":"2024-09-19T07:49:51.802073Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:00.374277Z","iopub.execute_input":"2024-09-19T08:36:00.374825Z","iopub.status.idle":"2024-09-19T08:36:00.426416Z","shell.execute_reply.started":"2024-09-19T08:36:00.374771Z","shell.execute_reply":"2024-09-19T08:36:00.425354Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Init GPU","metadata":{}},{"cell_type":"code","source":"# Initialize GPU Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\nelse:\n    print(\"No GPU available. Training will run on CPU.\")\n\nprint(device)","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:52.676763Z","start_time":"2024-09-19T07:49:52.643620Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:00.428158Z","iopub.execute_input":"2024-09-19T08:36:00.428456Z","iopub.status.idle":"2024-09-19T08:36:00.475426Z","shell.execute_reply.started":"2024-09-19T08:36:00.428424Z","shell.execute_reply":"2024-09-19T08:36:00.474478Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"GPU: Tesla P100-PCIE-16GB is available.\ncuda\n","output_type":"stream"}]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:52.720895Z","start_time":"2024-09-19T07:49:52.709311Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:00.476652Z","iopub.execute_input":"2024-09-19T08:36:00.477051Z","iopub.status.idle":"2024-09-19T08:36:00.525833Z","shell.execute_reply.started":"2024-09-19T08:36:00.477007Z","shell.execute_reply":"2024-09-19T08:36:00.524827Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Config Info","metadata":{}},{"cell_type":"code","source":"# Constants\nHEIGHT = 224\nWIDTH = 224\nCHANNELS = 3\n\nTRAIN_BATCH_SIZE = 8\nVALID_BATCH_SIZE = 4\nTEST_BATCH_SIZE = 4\nTEST_SIZE = 0.15\nVALID_SIZE = 0.15\n\nMAX_SLICES = 60\nSHAPE = (HEIGHT, WIDTH, CHANNELS)\n\nNUM_EPOCHS = 50\n","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:52.775282Z","start_time":"2024-09-19T07:49:52.755445Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:00.528473Z","iopub.execute_input":"2024-09-19T08:36:00.528858Z","iopub.status.idle":"2024-09-19T08:36:00.572216Z","shell.execute_reply.started":"2024-09-19T08:36:00.528815Z","shell.execute_reply":"2024-09-19T08:36:00.571386Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Kaggle and local switch\nimport os\n\nKAGGLE = os.path.exists('/kaggle')\nprint(\"Running on Kaggle\" if KAGGLE else \"Running locally\")\n\nDATA_DIR = '/kaggle/input/rsna-mil-training/' if KAGGLE else '../rsna-mil-training/'\nDICOM_DIR = DATA_DIR + 'rsna-mil-training'\nCSV_PATH = DATA_DIR + 'training_1000_scan_subset.csv' if KAGGLE else './data_analyze/training_1000_scan_subset.csv'\n\ndicom_dir = DICOM_DIR if KAGGLE else DATA_DIR\n# Load patient scan labels\npatient_scan_labels = pd.read_csv(CSV_PATH)","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:52.829856Z","start_time":"2024-09-19T07:49:52.815730Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:00.573433Z","iopub.execute_input":"2024-09-19T08:36:00.573838Z","iopub.status.idle":"2024-09-19T08:36:00.626370Z","shell.execute_reply.started":"2024-09-19T08:36:00.573793Z","shell.execute_reply":"2024-09-19T08:36:00.625288Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Running on Kaggle\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"def correct_dcm(dcm):\n    x = dcm.pixel_array + 1000\n    px_mode = 4096\n    x[x>=px_mode] = x[x>=px_mode] - px_mode\n    dcm.PixelData = x.tobytes()\n    dcm.RescaleIntercept = -1000\n\ndef window_image(dcm, window_center, window_width):    \n    if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):\n        correct_dcm(dcm)\n    img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n    \n    # Resize\n    img = cv2.resize(img, SHAPE[:2], interpolation = cv2.INTER_LINEAR)\n   \n    img_min = window_center - window_width // 2\n    img_max = window_center + window_width // 2\n    img = np.clip(img, img_min, img_max)\n    return img\n\ndef bsb_window(dcm):\n    brain_img = window_image(dcm, 40, 80)\n    subdural_img = window_image(dcm, 80, 200)\n    soft_img = window_image(dcm, 40, 380)\n    \n    brain_img = (brain_img - 0) / 80\n    subdural_img = (subdural_img - (-20)) / 200\n    soft_img = (soft_img - (-150)) / 380\n    \n    bsb_img = np.stack([brain_img, subdural_img, soft_img], axis=-1)\n    return bsb_img.astype(np.float16)","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:52.866672Z","start_time":"2024-09-19T07:49:52.855491Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:00.627735Z","iopub.execute_input":"2024-09-19T08:36:00.628141Z","iopub.status.idle":"2024-09-19T08:36:00.678179Z","shell.execute_reply.started":"2024-09-19T08:36:00.628097Z","shell.execute_reply":"2024-09-19T08:36:00.677243Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def preprocess_slice(slice, target_size=(HEIGHT, WIDTH)):\n    # Check if type of slice is dicom \n    if (type(slice) == np.ndarray):\n        slice = resize(slice, target_size, anti_aliasing=True)\n        brain_window = apply_windowing(slice, window=(40, 80))\n        subdural_window = apply_windowing(slice, window=(80, 200))\n        bone_window = apply_windowing(slice, window=(600, 2800))\n        \n        multichannel_slice = np.stack([brain_window, subdural_window, bone_window], axis=-1)\n        return multichannel_slice.astype(np.float16)\n    else:\n        slice = bsb_window(slice)\n        return slice.astype(np.float16)\n\ndef apply_windowing(slice, window):\n    window_width, window_level = window\n    lower_bound = window_level - window_width // 2\n    upper_bound = window_level + window_width // 2\n    \n    windowed_slice = np.clip(slice, lower_bound, upper_bound)\n    windowed_slice = (windowed_slice - lower_bound) / (upper_bound - lower_bound)\n    return windowed_slice","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:52.918451Z","start_time":"2024-09-19T07:49:52.907421Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:00.679290Z","iopub.execute_input":"2024-09-19T08:36:00.679596Z","iopub.status.idle":"2024-09-19T08:36:00.726342Z","shell.execute_reply.started":"2024-09-19T08:36:00.679564Z","shell.execute_reply":"2024-09-19T08:36:00.725447Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def read_dicom_folder(folder_path):\n    slices = []\n    for filename in sorted(os.listdir(folder_path))[:MAX_SLICES]:  # Limit to MAX_SLICES\n        if filename.endswith(\".dcm\"):\n            file_path = os.path.join(folder_path, filename)\n            ds = pydicom.dcmread(file_path)\n            slices.append(ds)\n            \n    # Sort slices by images position (z-coordinate) in ascending order\n    slices = sorted(slices, key=lambda x: float(x.ImagePositionPatient[2]))\n    \n    # Pad with black images if necessary\n    while len(slices) < MAX_SLICES:\n        slices.append(np.zeros_like(slices[0].pixel_array))\n    \n    return slices[:MAX_SLICES]  # Ensure we return exactly MAX_SLICES","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:52.962882Z","start_time":"2024-09-19T07:49:52.952249Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:00.727936Z","iopub.execute_input":"2024-09-19T08:36:00.728555Z","iopub.status.idle":"2024-09-19T08:36:00.773932Z","shell.execute_reply.started":"2024-09-19T08:36:00.728512Z","shell.execute_reply":"2024-09-19T08:36:00.773031Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Split Dataset","metadata":{}},{"cell_type":"code","source":"def split_dataset(patient_scan_labels, test_size=TEST_SIZE, val_size=VALID_SIZE, random_state=42):\n    \"\"\"\n    Split the dataset into training, validation, and testing sets while maintaining the same ratio of labels.\n\n    Args:\n        patient_scan_labels (pd.DataFrame): The DataFrame containing patient scan labels.\n        test_size (float): The proportion of the dataset to include in the test split.\n        val_size (float): The proportion of the training set to include in the validation split.\n        random_state (int): The seed used by the random number generator.\n\n    Returns:\n        Tuple: train_labels, val_labels, test_labels\n    \"\"\"\n    # If any of the hemorrhage indicators is 1, the label is 1, otherwise 0\n    patient_scan_labels['label'] = patient_scan_labels[['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']].any(axis=1).astype(int)\n\n    # Extract the labels from the DataFrame\n    labels = patient_scan_labels['label']\n\n    # First, split off the test set\n    train_val_labels, test_labels = train_test_split(\n        patient_scan_labels, \n        test_size=test_size, \n        stratify=labels, \n        random_state=random_state\n    )\n\n    # Calculate the validation size relative to the train_val set\n    val_size_adjusted = val_size / (1 - test_size)\n\n    # Split the train_val set into train and validation sets\n    train_labels, val_labels = train_test_split(\n        train_val_labels, \n        test_size=val_size_adjusted, \n        stratify=train_val_labels['label'], \n        random_state=random_state\n    )\n\n    return train_labels, val_labels, test_labels","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:53.011596Z","start_time":"2024-09-19T07:49:53.000512Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:00.775266Z","iopub.execute_input":"2024-09-19T08:36:00.775605Z","iopub.status.idle":"2024-09-19T08:36:00.822735Z","shell.execute_reply.started":"2024-09-19T08:36:00.775573Z","shell.execute_reply":"2024-09-19T08:36:00.821943Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def process_patient_data(dicom_dir, row):\n    patient_id = row['patient_id'].replace('ID_', '')\n    study_instance_uid = row['study_instance_uid'].replace('ID_', '')\n    \n    folder_name = f\"{patient_id}_{study_instance_uid}\"\n    folder_path = os.path.join(dicom_dir, folder_name)\n    \n    if os.path.exists(folder_path):\n        slices = read_dicom_folder(folder_path)\n        \n        # Vì đã có dòng stack rồi nên có thể dòng này không cần thiết\n        preprocessed_slices = [preprocess_slice(slice) for slice in slices]\n        \n        # Thêm chiều depth\n        preprocessed_slices = np.stack(preprocessed_slices, axis=0)  # (depth, height, width, channels)\n        preprocessed_slices = np.transpose(preprocessed_slices, (3, 0, 1, 2))  # (channels, depth, height, width)\n        \n        label = 1 if row[['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']].any() else 0\n        \n        return preprocessed_slices, label\n    else:\n        print(f\"Folder not found: {folder_path}\")\n        return None, None","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:53.058309Z","start_time":"2024-09-19T07:49:53.046935Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:00.825802Z","iopub.execute_input":"2024-09-19T08:36:00.826120Z","iopub.status.idle":"2024-09-19T08:36:00.872151Z","shell.execute_reply.started":"2024-09-19T08:36:00.826087Z","shell.execute_reply":"2024-09-19T08:36:00.871228Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class TrainDatasetGenerator(Dataset):\n    \"\"\"\n    A custom dataset class for training data.\n    \"\"\"\n    def __init__(self, data_dir, patient_scan_labels):\n        self.data_dir = data_dir\n        self.patient_scan_labels = patient_scan_labels\n\n    def __len__(self):\n        return len(self.patient_scan_labels)\n\n    def __getitem__(self, idx):\n        row = self.patient_scan_labels.iloc[idx]\n        preprocessed_slices, label = process_patient_data(self.data_dir, row)\n        \n        if preprocessed_slices is not None:\n            # Convert the list of numpy arrays to a single numpy array\n            preprocessed_slices = np.array(preprocessed_slices)  # Convert to numpy array\n            return torch.tensor(preprocessed_slices, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n        else:\n            return None, None  # Handle the case where the folder is not found\n\nclass TestDatasetGenerator(Dataset):\n    \"\"\"\n    A custom dataset class for testing data.\n    \"\"\"\n    def __init__(self, data_dir, patient_scan_labels):\n        self.data_dir = data_dir\n        self.patient_scan_labels = patient_scan_labels\n\n    def __len__(self):\n        return len(self.patient_scan_labels)\n\n    def __getitem__(self, idx):\n        row = self.patient_scan_labels.iloc[idx]\n        preprocessed_slices, label = process_patient_data(self.data_dir, row)\n        \n        if preprocessed_slices is not None:\n            # Convert the list of numpy arrays to a single numpy array\n            preprocessed_slices = np.array(preprocessed_slices)  # Convert to numpy array\n            return torch.tensor(preprocessed_slices, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n        else:\n            return None, None  # Handle the case where the folder is not found","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:53.102886Z","start_time":"2024-09-19T07:49:53.091382Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:00.873170Z","iopub.execute_input":"2024-09-19T08:36:00.873449Z","iopub.status.idle":"2024-09-19T08:36:00.922218Z","shell.execute_reply.started":"2024-09-19T08:36:00.873419Z","shell.execute_reply":"2024-09-19T08:36:00.921147Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def get_train_loader(dicom_dir, patient_scan_labels, batch_size=TRAIN_BATCH_SIZE, shuffle=True):\n    train_dataset = TrainDatasetGenerator(dicom_dir, patient_scan_labels)\n    return DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4, pin_memory=True)\n\ndef get_test_loader(dicom_dir, patient_scan_labels, batch_size=TEST_BATCH_SIZE):\n    test_dataset = TestDatasetGenerator(dicom_dir, patient_scan_labels)\n    return DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:53.157864Z","start_time":"2024-09-19T07:49:53.138509Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:00.923514Z","iopub.execute_input":"2024-09-19T08:36:00.924160Z","iopub.status.idle":"2024-09-19T08:36:00.969768Z","shell.execute_reply.started":"2024-09-19T08:36:00.924115Z","shell.execute_reply":"2024-09-19T08:36:00.968805Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## CNN Feature Extractor","metadata":{}},{"cell_type":"code","source":"class ChannelAttention(nn.Module):\n    def __init__(self, in_channels, reduction=16):\n        super(ChannelAttention, self).__init__()\n        self.fc1 = nn.Linear(in_channels, in_channels // reduction, bias=False).to(device)\n        self.fc2 = nn.Linear(in_channels // reduction, in_channels, bias=False).to(device)\n\n    def forward(self, x):\n        batch_size, channels, _, _, _ = x.size()\n    \n        avg_pool = F.adaptive_avg_pool3d(x, 1).view(batch_size, channels)\n        max_pool = F.adaptive_max_pool3d(x, 1).view(batch_size, channels)\n\n        avg_out = self.fc2(F.relu(self.fc1(avg_pool)))\n        max_out = self.fc2(F.relu(self.fc1(max_pool)))\n\n        out = torch.sigmoid(avg_out + max_out).view(batch_size, channels, 1, 1, 1)\n        return out * x","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:53.209098Z","start_time":"2024-09-19T07:49:53.189263Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:00.970939Z","iopub.execute_input":"2024-09-19T08:36:00.971309Z","iopub.status.idle":"2024-09-19T08:36:01.017922Z","shell.execute_reply.started":"2024-09-19T08:36:00.971261Z","shell.execute_reply":"2024-09-19T08:36:01.017100Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock3D(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock3D, self).__init__()\n        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm3d(out_channels)\n        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm3d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm3d(out_channels)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        \n        # Apply channel attention methods\n        out = ChannelAttention(out.size(1))(out)\n        \n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:53.263907Z","start_time":"2024-09-19T07:49:53.242416Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:01.018934Z","iopub.execute_input":"2024-09-19T08:36:01.019266Z","iopub.status.idle":"2024-09-19T08:36:01.067606Z","shell.execute_reply.started":"2024-09-19T08:36:01.019225Z","shell.execute_reply":"2024-09-19T08:36:01.066710Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# class ResNet3D_MIL(nn.Module):\n#     def __init__(self, block, num_blocks, num_classes=2):\n#         super(ResNet3D_MIL, self).__init__()\n#         self.in_channels = 64\n# \n#         self.conv1 = nn.Conv3d(3, 64, kernel_size=7, stride=(1, 2, 2), padding=3, bias=False)\n#         self.bn1 = nn.BatchNorm3d(64)\n#         self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n# \n#         self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n#         self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n#         self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n#         self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n# \n#         self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n#         self.fc = nn.Linear(512, num_classes)\n#         \n#         self.dropout = nn.Dropout(0.25)\n# \n#     def _make_layer(self, block, out_channels, num_blocks, stride):\n#         strides = [stride] + [1] * (num_blocks - 1)\n#         layers = []\n#         for stride in strides:\n#             layers.append(block(self.in_channels, out_channels, stride))\n#             self.in_channels = out_channels\n#         return nn.Sequential(*layers)\n# \n#     def forward(self, x):\n#         # x shape: (batch_size, num_instances, channels, depth, height, width)\n#         batch_size, c, d, h, w = x.size()\n#         x = x.view(batch_size, c, d, h, w)\n# \n#         out = F.relu(self.bn1(self.conv1(x)))\n#         out = self.maxpool(out)\n# \n#         out = self.layer1(out)\n#         out = self.dropout(out)\n#         out = self.layer2(out)\n#         out = self.dropout(out)\n#         out = self.layer3(out)\n#         out = self.dropout(out)\n#         out = self.layer4(out)\n# \n#         out = self.avgpool(out)\n#         out = out.view(out.size(0), -1)\n#         out = self.dropout(out)\n#         out = self.fc(out)\n# \n#         # MIL aggregation (max pooling over instances)\n#         out = torch.max(out, dim=1)[0]\n# \n#         return out\n# \n# def ResNet3D18_MIL():\n#     return ResNet3D_MIL(ResidualBlock3D, [2, 2, 2, 2])","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:53.301474Z","start_time":"2024-09-19T07:49:53.291189Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:01.069122Z","iopub.execute_input":"2024-09-19T08:36:01.069530Z","iopub.status.idle":"2024-09-19T08:36:01.114171Z","shell.execute_reply.started":"2024-09-19T08:36:01.069482Z","shell.execute_reply":"2024-09-19T08:36:01.113220Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class ResNet3D_MIL(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=2):\n        super(ResNet3D_MIL, self).__init__()\n        self.in_channels = 16\n\n        self.conv1 = nn.Conv3d(3, 16, kernel_size=7, stride=(1, 2, 2), padding=3, bias=False)\n        self.bn1 = nn.BatchNorm3d(16)\n        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 32, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 32, num_blocks[3], stride=2)\n        self.layer5 = self._make_layer(block, 32, num_blocks[4], stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n        self.fc = nn.Linear(32, num_classes)\n        \n        self.dropout = nn.Dropout(0.25)\n\n    def _make_layer(self, block, out_channels, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_channels, out_channels, stride))\n            self.in_channels = out_channels\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        # x shape: (batch_size, num_instances, channels, depth, height, width)\n        batch_size, c, d, h, w = x.size()\n        x = x.view(batch_size, c, d, h, w)\n\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.maxpool(out)\n\n        out = self.layer1(out)\n        out = self.maxpool(out)\n        out = self.layer2(out)\n        out = self.maxpool(out)\n        out = self.layer3(out)\n        out = self.maxpool(out)\n        out = self.layer4(out)\n        out = self.maxpool(out)\n        out = self.layer5(out)\n\n        out = self.avgpool(out)\n        out = out.view(out.size(0), -1)\n        out = self.dropout(out)\n        out = self.fc(out)\n\n        # MIL aggregation (max pooling over instances)\n        out = torch.max(out, dim=1)[0]\n\n        return out\n\ndef ResNet3D18_MIL():\n    return ResNet3D_MIL(ResidualBlock3D, [2, 2, 2, 2, 2])","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:53.348944Z","start_time":"2024-09-19T07:49:53.336278Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:01.115808Z","iopub.execute_input":"2024-09-19T08:36:01.116249Z","iopub.status.idle":"2024-09-19T08:36:01.170561Z","shell.execute_reply.started":"2024-09-19T08:36:01.116207Z","shell.execute_reply":"2024-09-19T08:36:01.169683Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.001, device='cuda'):\n    model = model.to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n    \n    best_val_accuracy = 0.0\n    best_model = None\n\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0.0\n        train_predictions = []\n        train_labels = []\n\n        for batch_data, batch_labels in train_loader:\n            batch_data = batch_data.to(device)\n            batch_labels = batch_labels.float().to(device)\n\n            optimizer.zero_grad()\n            outputs = model(batch_data).squeeze()\n            loss = criterion(outputs, batch_labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            train_predictions.extend((outputs > 0).cpu().numpy())\n            train_labels.extend(batch_labels.cpu().numpy())\n\n        train_accuracy = accuracy_score(train_labels, train_predictions)\n        train_precision = precision_score(train_labels, train_predictions)\n        train_recall = recall_score(train_labels, train_predictions)\n        train_f1 = f1_score(train_labels, train_predictions)\n\n        # Validation\n        model.eval()\n        val_loss = 0.0\n        val_predictions = []\n        val_labels = []\n\n        with torch.no_grad():\n            for batch_data, batch_labels in val_loader:\n                batch_data = batch_data.to(device)\n                batch_labels = batch_labels.float().to(device)\n\n                outputs = model(batch_data).squeeze()\n                loss = criterion(outputs, batch_labels)\n\n                val_loss += loss.item()\n                val_predictions.extend((outputs > 0).cpu().numpy())\n                val_labels.extend(batch_labels.cpu().numpy())\n\n        val_accuracy = accuracy_score(val_labels, val_predictions)\n        val_precision = precision_score(val_labels, val_predictions)\n        val_recall = recall_score(val_labels, val_predictions)\n        val_f1 = f1_score(val_labels, val_predictions)\n\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}\")\n        print(f\"Val Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n\n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n            best_model = model.state_dict()\n\n    # Load best model\n    model.load_state_dict(best_model)\n    return model","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:53.396321Z","start_time":"2024-09-19T07:49:53.383998Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:01.171696Z","iopub.execute_input":"2024-09-19T08:36:01.172078Z","iopub.status.idle":"2024-09-19T08:36:01.226044Z","shell.execute_reply.started":"2024-09-19T08:36:01.172034Z","shell.execute_reply":"2024-09-19T08:36:01.225144Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def test_model(model, test_loader, device='cuda'):\n    model = model.to(device)\n    model.eval()\n    test_predictions = []\n    test_labels = []\n\n    with torch.no_grad():\n        for batch_data, batch_labels in test_loader:\n            batch_data = batch_data.to(device)\n            batch_labels = batch_labels.float().to(device)\n\n            outputs = model(batch_data).squeeze()\n            test_predictions.extend((outputs > 0).cpu().numpy())\n            test_labels.extend(batch_labels.cpu().numpy())\n\n    test_accuracy = accuracy_score(test_labels, test_predictions)\n    test_precision = precision_score(test_labels, test_predictions)\n    test_recall = recall_score(test_labels, test_predictions)\n    test_f1 = f1_score(test_labels, test_predictions)\n\n    print(f\"Test Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")\n\n    return test_accuracy, test_precision, test_recall, test_f1","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:53.451363Z","start_time":"2024-09-19T07:49:53.439663Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:01.227233Z","iopub.execute_input":"2024-09-19T08:36:01.227551Z","iopub.status.idle":"2024-09-19T08:36:01.274781Z","shell.execute_reply.started":"2024-09-19T08:36:01.227519Z","shell.execute_reply":"2024-09-19T08:36:01.273799Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(model, data_loader, device):\n    model.eval()\n    all_labels = []\n    all_scores = []\n    with torch.no_grad():\n        for batch_data, batch_labels in data_loader:\n            batch_data = batch_data.to(device)\n            outputs = model(batch_data).squeeze()\n            all_scores.extend(outputs.cpu().numpy())\n            all_labels.extend(batch_labels.numpy())\n    \n    fpr, tpr, _ = roc_curve(all_labels, all_scores)\n    roc_auc = auc(fpr, tpr)\n    \n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc=\"lower right\")\n    plt.show()","metadata":{"ExecuteTime":{"end_time":"2024-09-19T07:49:53.501920Z","start_time":"2024-09-19T07:49:53.490798Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:01.275795Z","iopub.execute_input":"2024-09-19T08:36:01.276130Z","iopub.status.idle":"2024-09-19T08:36:01.324104Z","shell.execute_reply.started":"2024-09-19T08:36:01.276092Z","shell.execute_reply":"2024-09-19T08:36:01.323089Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    model = ResNet3D18_MIL()\n    \n    train_labels, val_labels, test_labels = split_dataset(patient_scan_labels, test_size=TEST_SIZE)\n    \n    train_loader = get_train_loader(dicom_dir, train_labels, batch_size=4)\n    val_loader = get_train_loader(dicom_dir, val_labels, batch_size=2)\n    test_loader = get_test_loader(dicom_dir, test_labels, batch_size=2)\n    \n    trained_model = train_model(model, train_loader, val_loader, num_epochs=50, learning_rate=0.001)\n    \n    # Save the model\n    torch.save(trained_model.state_dict(), 'trained_model.pth')\n    \n    plot_roc_curve(trained_model, test_loader, device)","metadata":{"ExecuteTime":{"end_time":"2024-09-19T08:20:36.925539Z","start_time":"2024-09-19T07:49:53.538906Z"},"execution":{"iopub.status.busy":"2024-09-19T08:36:01.325322Z","iopub.execute_input":"2024-09-19T08:36:01.325667Z","iopub.status.idle":"2024-09-19T09:13:47.809155Z","shell.execute_reply.started":"2024-09-19T08:36:01.325628Z","shell.execute_reply":"2024-09-19T09:13:47.807278Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Epoch 1/50\nTrain Loss: 123.5617, Accuracy: 0.5329, Precision: 0.4452, Recall: 0.4407, F1: 0.4429\nVal Loss: 51.4943, Accuracy: 0.5133, Precision: 0.4000, Recall: 0.3175, F1: 0.3540\nEpoch 2/50\nTrain Loss: 123.1375, Accuracy: 0.5543, Precision: 0.4647, Recall: 0.3797, F1: 0.4179\nVal Loss: 50.8636, Accuracy: 0.5533, Precision: 0.4167, Recall: 0.1587, F1: 0.2299\nEpoch 3/50\nTrain Loss: 119.4613, Accuracy: 0.5700, Precision: 0.4766, Recall: 0.2068, F1: 0.2884\nVal Loss: 51.4788, Accuracy: 0.6200, Precision: 0.5833, Recall: 0.3333, F1: 0.4242\nEpoch 4/50\nTrain Loss: 117.8398, Accuracy: 0.5857, Precision: 0.5153, Recall: 0.2847, F1: 0.3668\nVal Loss: 45.0702, Accuracy: 0.7467, Precision: 0.7193, Recall: 0.6508, F1: 0.6833\nEpoch 5/50\nTrain Loss: 117.0957, Accuracy: 0.5971, Precision: 0.5330, Recall: 0.3559, F1: 0.4268\nVal Loss: 46.9305, Accuracy: 0.6200, Precision: 0.6250, Recall: 0.2381, F1: 0.3448\nEpoch 6/50\nTrain Loss: 115.2411, Accuracy: 0.5914, Precision: 0.5195, Recall: 0.4068, F1: 0.4563\nVal Loss: 48.9461, Accuracy: 0.6533, Precision: 0.6038, Recall: 0.5079, F1: 0.5517\nEpoch 7/50\nTrain Loss: 114.0611, Accuracy: 0.6286, Precision: 0.5829, Recall: 0.4169, F1: 0.4862\nVal Loss: 48.0634, Accuracy: 0.6467, Precision: 0.6087, Recall: 0.4444, F1: 0.5138\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[40], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m get_train_loader(dicom_dir, val_labels, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     11\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m get_test_loader(dicom_dir, test_labels, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m     16\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(trained_model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrained_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[37], line 20\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, num_epochs, learning_rate, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m batch_labels \u001b[38;5;241m=\u001b[39m batch_labels\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_labels)\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[36], line 37\u001b[0m, in \u001b[0;36mResNet3D_MIL.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[1;32m     35\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(out)\n\u001b[0;32m---> 37\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(out)\n\u001b[1;32m     39\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(out)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[34], line 21\u001b[0m, in \u001b[0;36mResidualBlock3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Apply channel attention methods\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mChannelAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m(out)\n\u001b[1;32m     23\u001b[0m out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcut(x)\n\u001b[1;32m     24\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(out)\n","Cell \u001b[0;32mIn[33], line 4\u001b[0m, in \u001b[0;36mChannelAttention.__init__\u001b[0;34m(self, in_channels, reduction)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channels, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m(ChannelAttention, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1 \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(in_channels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m reduction, in_channels, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Load the model and test it on test loader and print the results of classification to a csv \n\n# Load the model\nmodel = ResNet3D18_MIL()\n# Load the trained model\nmodel.load_state_dict(torch.load('trained_model.pth'))\nmodel.eval()\n\ntest_model(model, test_loader)\n\n# Save the results to a csv file\nresults = []\nwith torch.no_grad():\n    for batch_data, batch_labels in test_loader:\n        batch_data = batch_data.to(device)\n        batch_labels = batch_labels.float().to(device)\n\n        outputs = model(batch_data).squeeze()\n        predictions = (outputs > 0).cpu().numpy()\n\n        for i in range(len(predictions)):\n            results.append({\n                'prediction': predictions[i],\n                'label': batch_labels[i].cpu().numpy()\n            })\n\nresults_df = pd.DataFrame(results)\nresults_df.to_csv('results.csv', index=False)\n\nresults_df.head()","metadata":{"ExecuteTime":{"end_time":"2024-09-19T08:20:50.210958Z","start_time":"2024-09-19T08:20:36.935310Z"},"execution":{"iopub.status.busy":"2024-09-19T09:13:47.810438Z","iopub.status.idle":"2024-09-19T09:13:47.810874Z","shell.execute_reply.started":"2024-09-19T09:13:47.810683Z","shell.execute_reply":"2024-09-19T09:13:47.810706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_first_item(dataloader):\n    first_item = next(iter(dataloader))\n    \n    images, labels = first_item[0]\n    \n    # Reshape images \n    images = images.squeeze(0)  \n    images = images.permute(1, 0, 2, 3)  \n    \n    num_images = images.size(0)  \n    \n    images = images.numpy() \n    \n    plt.figure(figsize=(15, 15))\n    \n    for i in range(num_images):\n        plt.subplot(8, 8, i + 1) \n        plt.imshow(images[i][0], cmap='gray') \n        plt.title(f'Image {i + 1}')\n        plt.axis('off')\n    \n    plt.tight_layout() \n    plt.show()\n\n# Gọi hàm với test_loader\nplot_first_item(test_loader)","metadata":{"ExecuteTime":{"end_time":"2024-09-19T08:20:53.436113Z","start_time":"2024-09-19T08:20:50.274916Z"},"execution":{"iopub.status.busy":"2024-09-19T09:13:47.812522Z","iopub.status.idle":"2024-09-19T09:13:47.812865Z","shell.execute_reply.started":"2024-09-19T09:13:47.812688Z","shell.execute_reply":"2024-09-19T09:13:47.812706Z"},"trusted":true},"execution_count":null,"outputs":[]}]}