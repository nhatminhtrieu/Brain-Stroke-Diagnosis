{
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5705276,
     "sourceId": 9399351,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Library",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "from typing import Type\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import gpytorch\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:30.317416Z",
     "iopub.execute_input": "2024-09-21T17:49:30.318238Z",
     "iopub.status.idle": "2024-09-21T17:49:34.633268Z",
     "shell.execute_reply.started": "2024-09-21T17:49:30.318197Z",
     "shell.execute_reply": "2024-09-21T17:49:34.632459Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.236553Z",
     "start_time": "2024-09-24T16:30:12.991061Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.241577Z",
     "start_time": "2024-09-24T16:30:14.239640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": "## Init GPU",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Initialize GPU Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\nelse:\n    print(\"No GPU available. Training will run on CPU.\")\n\nprint(device)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:34.634821Z",
     "iopub.execute_input": "2024-09-21T17:49:34.635253Z",
     "iopub.status.idle": "2024-09-21T17:49:34.723958Z",
     "shell.execute_reply.started": "2024-09-21T17:49:34.635218Z",
     "shell.execute_reply": "2024-09-21T17:49:34.723042Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.325966Z",
     "start_time": "2024-09-24T16:30:14.284908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 4070 SUPER is available.\n",
      "cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "%load_ext autoreload\n%autoreload 2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:34.724997Z",
     "iopub.execute_input": "2024-09-21T17:49:34.725294Z",
     "iopub.status.idle": "2024-09-21T17:49:34.769458Z",
     "shell.execute_reply.started": "2024-09-21T17:49:34.725261Z",
     "shell.execute_reply": "2024-09-21T17:49:34.768647Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.387371Z",
     "start_time": "2024-09-24T16:30:14.370501Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": "## Config Info",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Constants\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "CHANNELS = 3\n",
    "\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "TEST_BATCH_SIZE = 4\n",
    "TEST_SIZE = 0.15\n",
    "VALID_SIZE = 0.15\n",
    "\n",
    "MAX_SLICES = 60\n",
    "SHAPE = (HEIGHT, WIDTH, CHANNELS)\n",
    "\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# TARGET_LABELS = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "TARGET_LABELS = ['intraparenchymal']"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:34.772209Z",
     "iopub.execute_input": "2024-09-21T17:49:34.772795Z",
     "iopub.status.idle": "2024-09-21T17:49:34.808724Z",
     "shell.execute_reply.started": "2024-09-21T17:49:34.772761Z",
     "shell.execute_reply": "2024-09-21T17:49:34.807898Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.431652Z",
     "start_time": "2024-09-24T16:30:14.417781Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# Kaggle and local switch\n",
    "KAGGLE = os.path.exists('/kaggle')\n",
    "print(\"Running on Kaggle\" if KAGGLE else \"Running locally\")\n",
    "\n",
    "DATA_DIR = '/kaggle/input/' if KAGGLE else '../rsna-mil-training/'\n",
    "DICOM_DIR = DATA_DIR + 'rsna-mil-training-first/'\n",
    "CSV_PATH = DATA_DIR + 'training_1000_scan_subset-first.csv' if KAGGLE else './data_analyze/training_1000_scan_subset.csv'\n",
    "\n",
    "dicom_dir = DICOM_DIR if KAGGLE else DATA_DIR\n",
    "# Load patient scan labels\n",
    "patient_scan_labels = pd.read_csv(CSV_PATH)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:34.851522Z",
     "iopub.execute_input": "2024-09-21T17:49:34.851890Z",
     "iopub.status.idle": "2024-09-21T17:49:34.898494Z",
     "shell.execute_reply.started": "2024-09-21T17:49:34.851850Z",
     "shell.execute_reply": "2024-09-21T17:49:34.897585Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.486906Z",
     "start_time": "2024-09-24T16:30:14.462146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": "## Data Preprocessing",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def correct_dcm(dcm):\n    x = dcm.pixel_array + 1000\n    px_mode = 4096\n    x[x>=px_mode] = x[x>=px_mode] - px_mode\n    dcm.PixelData = x.tobytes()\n    dcm.RescaleIntercept = -1000\n\ndef window_image(dcm, window_center, window_width):    \n    if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):\n        correct_dcm(dcm)\n    img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n    \n    # Resize\n    img = cv2.resize(img, SHAPE[:2], interpolation = cv2.INTER_LINEAR)\n   \n    img_min = window_center - window_width // 2\n    img_max = window_center + window_width // 2\n    img = np.clip(img, img_min, img_max)\n    return img\n\ndef bsb_window(dcm):\n    brain_img = window_image(dcm, 40, 80)\n    subdural_img = window_image(dcm, 80, 200)\n    soft_img = window_image(dcm, 40, 380)\n    \n    brain_img = (brain_img - 0) / 80\n    subdural_img = (subdural_img - (-20)) / 200\n    soft_img = (soft_img - (-150)) / 380\n    \n    bsb_img = np.stack([brain_img, subdural_img, soft_img], axis=-1)\n    return bsb_img.astype(np.float16)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:34.899639Z",
     "iopub.execute_input": "2024-09-21T17:49:34.899918Z",
     "iopub.status.idle": "2024-09-21T17:49:34.942493Z",
     "shell.execute_reply.started": "2024-09-21T17:49:34.899887Z",
     "shell.execute_reply": "2024-09-21T17:49:34.941247Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.524202Z",
     "start_time": "2024-09-24T16:30:14.510712Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "def preprocess_slice(slice, target_size=(HEIGHT, WIDTH)):\n    # Check if type of slice is dicom or an empty numpy array\n    if (type(slice) == np.ndarray):\n        slice = resize(slice, target_size, anti_aliasing=True)\n        multichannel_slice = np.stack([slice, slice, slice], axis=-1)\n        return multichannel_slice.astype(np.float16)\n    else:\n        slice = bsb_window(slice)\n        return slice.astype(np.float16)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:34.944152Z",
     "iopub.execute_input": "2024-09-21T17:49:34.944568Z",
     "iopub.status.idle": "2024-09-21T17:49:34.988714Z",
     "shell.execute_reply.started": "2024-09-21T17:49:34.944513Z",
     "shell.execute_reply": "2024-09-21T17:49:34.987480Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.567398Z",
     "start_time": "2024-09-24T16:30:14.556052Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": "def read_dicom_folder(folder_path):\n    slices = []\n    for filename in sorted(os.listdir(folder_path))[:MAX_SLICES]:  # Limit to MAX_SLICES\n        if filename.endswith(\".dcm\"):\n            file_path = os.path.join(folder_path, filename)\n            ds = pydicom.dcmread(file_path)\n            slices.append(ds)\n            \n    # Sort slices by images position (z-coordinate) in ascending order\n    slices = sorted(slices, key=lambda x: float(x.ImagePositionPatient[2]))\n    \n    # Pad with black images if necessary\n    while len(slices) < MAX_SLICES:\n        slices.append(np.zeros_like(slices[0].pixel_array))\n    \n    return slices[:MAX_SLICES]  # Ensure we return exactly MAX_SLICES",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:34.990731Z",
     "iopub.execute_input": "2024-09-21T17:49:34.991508Z",
     "iopub.status.idle": "2024-09-21T17:49:35.039115Z",
     "shell.execute_reply.started": "2024-09-21T17:49:34.991462Z",
     "shell.execute_reply": "2024-09-21T17:49:35.038095Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.612022Z",
     "start_time": "2024-09-24T16:30:14.600214Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": "## Dataset and DataLoader",
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Splitting the Dataset"
  },
  {
   "cell_type": "code",
   "source": "def split_dataset(patient_scan_labels, test_size=TEST_SIZE, val_size=VALID_SIZE, random_state=42):\n    # If any of the hemorrhage indicators is 1, the label is 1, otherwise 0\n    patient_scan_labels['label'] = patient_scan_labels[['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']].any(axis=1).astype(int)\n\n    # Extract the labels from the DataFrame\n    labels = patient_scan_labels['label']\n\n    # First, split off the test set\n    train_val_labels, test_labels = train_test_split(\n        patient_scan_labels, \n        test_size=test_size, \n        stratify=labels, \n        random_state=random_state\n    )\n\n    # Calculate the validation size relative to the train_val set\n    val_size_adjusted = val_size / (1 - test_size)\n\n    # Split the train_val set into train and validation sets\n    train_labels, val_labels = train_test_split(\n        train_val_labels, \n        test_size=val_size_adjusted, \n        stratify=train_val_labels['label'], \n        random_state=random_state\n    )\n\n    return train_labels, val_labels, test_labels",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:35.044082Z",
     "iopub.execute_input": "2024-09-21T17:49:35.044395Z",
     "iopub.status.idle": "2024-09-21T17:49:35.086247Z",
     "shell.execute_reply.started": "2024-09-21T17:49:35.044363Z",
     "shell.execute_reply": "2024-09-21T17:49:35.085062Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.663929Z",
     "start_time": "2024-09-24T16:30:14.648066Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Processing the Data"
  },
  {
   "cell_type": "code",
   "source": [
    "def process_patient_data(dicom_dir, row, num_instances=12, depth=5):\n",
    "    patient_id = row['patient_id'].replace('ID_', '')\n",
    "    study_instance_uid = row['study_instance_uid'].replace('ID_', '')\n",
    "    \n",
    "    folder_name = f\"{patient_id}_{study_instance_uid}\"\n",
    "    folder_path = os.path.join(dicom_dir, folder_name)\n",
    "    \n",
    "    if os.path.exists(folder_path):\n",
    "        slices = read_dicom_folder(folder_path)\n",
    "        \n",
    "        # Ensure we have enough slices to create the specified instances\n",
    "        if len(slices) < depth * num_instances:\n",
    "            print(f\"Not enough slices for patient {patient_id}: found {len(slices)}, needed {depth * num_instances}\")\n",
    "            return None, None\n",
    "        \n",
    "        preprocessed_slices = [preprocess_slice(slice) for slice in slices]\n",
    "        \n",
    "        # Stack preprocessed slices into an array\n",
    "        preprocessed_slices = np.stack(preprocessed_slices, axis=0)  # (num_slices, height, width, channels)\n",
    "        \n",
    "        # Reshape to (num_instances, depth, height, width, channels)\n",
    "        reshaped_slices = preprocessed_slices[:num_instances * depth].reshape(num_instances, depth, *preprocessed_slices.shape[1:])  # (num_instances, depth, height, width, channels)\n",
    "        \n",
    "        # Labeling remains consistent  \n",
    "        label = 1 if row[['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']].any() else 0\n",
    "        \n",
    "        return reshaped_slices, label\n",
    "    \n",
    "    else:\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        return None, None"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:35.087470Z",
     "iopub.execute_input": "2024-09-21T17:49:35.087871Z",
     "iopub.status.idle": "2024-09-21T17:49:35.132772Z",
     "shell.execute_reply.started": "2024-09-21T17:49:35.087821Z",
     "shell.execute_reply": "2024-09-21T17:49:35.131784Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.717147Z",
     "start_time": "2024-09-24T16:30:14.696529Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": "class TrainDatasetGenerator(Dataset):\n    \"\"\"\n    A custom dataset class for training data.\n    \"\"\"\n    def __init__(self, data_dir, patient_scan_labels):\n        self.data_dir = data_dir\n        self.patient_scan_labels = patient_scan_labels\n\n    def __len__(self):\n        return len(self.patient_scan_labels)\n\n    def __getitem__(self, idx):\n        row = self.patient_scan_labels.iloc[idx]\n        preprocessed_slices, label = process_patient_data(self.data_dir, row)\n        \n        if preprocessed_slices is not None:\n            # Convert the list of numpy arrays to a single numpy array\n            preprocessed_slices = np.array(preprocessed_slices)  # Convert to numpy array\n            return torch.tensor(preprocessed_slices, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n        else:\n            return None, None  # Handle the case where the folder is not found\n\nclass TestDatasetGenerator(Dataset):\n    \"\"\"\n    A custom dataset class for testing data.\n    \"\"\"\n    def __init__(self, data_dir, patient_scan_labels):\n        self.data_dir = data_dir\n        self.patient_scan_labels = patient_scan_labels\n\n    def __len__(self):\n        return len(self.patient_scan_labels)\n\n    def __getitem__(self, idx):\n        row = self.patient_scan_labels.iloc[idx]\n        preprocessed_slices, label = process_patient_data(self.data_dir, row)\n        \n        if preprocessed_slices is not None:\n            # Convert the list of numpy arrays to a single numpy array\n            preprocessed_slices = np.array(preprocessed_slices)  # Convert to numpy array\n            return torch.tensor(preprocessed_slices, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n        else:\n            return None, None  # Handle the case where the folder is not found",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:35.133936Z",
     "iopub.execute_input": "2024-09-21T17:49:35.134285Z",
     "iopub.status.idle": "2024-09-21T17:49:35.184295Z",
     "shell.execute_reply.started": "2024-09-21T17:49:35.134251Z",
     "shell.execute_reply": "2024-09-21T17:49:35.183360Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.767543Z",
     "start_time": "2024-09-24T16:30:14.746317Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": "def get_train_loader(dicom_dir, patient_scan_labels, batch_size=TRAIN_BATCH_SIZE, shuffle=True):\n    train_dataset = TrainDatasetGenerator(dicom_dir, patient_scan_labels)\n    return DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4, pin_memory=True)\n\ndef get_test_loader(dicom_dir, patient_scan_labels, batch_size=TEST_BATCH_SIZE):\n    test_dataset = TestDatasetGenerator(dicom_dir, patient_scan_labels)\n    return DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:35.186353Z",
     "iopub.execute_input": "2024-09-21T17:49:35.186847Z",
     "iopub.status.idle": "2024-09-21T17:49:35.227411Z",
     "shell.execute_reply.started": "2024-09-21T17:49:35.186803Z",
     "shell.execute_reply": "2024-09-21T17:49:35.226425Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.815284Z",
     "start_time": "2024-09-24T16:30:14.796766Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": "## CNN Feature Extractor",
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Attention Layer"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.870703Z",
     "start_time": "2024-09-24T16:30:14.848641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.fc = nn.Linear(in_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_instances, feature_dim)\n",
    "        attention_weights = torch.softmax(self.fc(x), dim=1)  # Shape: (batch_size, num_instances, 1)\n",
    "        weighted_sum = torch.sum(attention_weights * x, dim=1)  # Shape: (batch_size, feature_dim)\n",
    "        return weighted_sum, attention_weights"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.939563Z",
     "start_time": "2024-09-24T16:30:14.902123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GatedAttentionLayer(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(GatedAttentionLayer, self).__init__()\n",
    "        self.fc_attention = nn.Linear(in_channels, 1)\n",
    "        self.fc_gate = nn.Linear(in_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_instances, feature_dim)\n",
    "        attention_weights = torch.softmax(self.fc_attention(x), dim=1)  # Shape: (batch_size, num_instances, 1)\n",
    "        gate_weights = torch.sigmoid(self.fc_gate(x))  # Shape: (batch_size, num_instances, 1)\n",
    "\n",
    "        gated_attention = attention_weights * gate_weights\n",
    "        weighted_sum = torch.sum(gated_attention * x, dim=1)  # Shape: (batch_size, feature_dim)\n",
    "        return weighted_sum, gated_attention"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sparse Gaussian Process Layer"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:14.978813Z",
     "start_time": "2024-09-24T16:30:14.954879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SparseGPlayer(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        inducing_points = inducing_points.to(device)\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "            inducing_points.size(0)\n",
    "        )\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super(SparseGPlayer, self).__init__(variational_strategy)\n",
    "        \n",
    "        self.mean_module = gpytorch.means.ConstantMean().to(device)\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        \n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ResNet3D Model"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Basic Block"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:15.027984Z",
     "start_time": "2024-09-24T16:30:15.007019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BasicBlock3D(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        stride: int = 1,\n",
    "        expansion: int = 1,\n",
    "        downsample: nn.Module = None,\n",
    "        dropout_rate: float = 0.25\n",
    "    ) -> None:\n",
    "        super(BasicBlock3D, self).__init__()\n",
    "        self.expansion = expansion\n",
    "        self.downsample = downsample\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size=3, \n",
    "            stride=stride, \n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout3d(dropout_rate)\n",
    "        self.conv2 = nn.Conv3d(\n",
    "            out_channels, \n",
    "            out_channels*self.expansion, \n",
    "            kernel_size=3, \n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels*self.expansion)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "        \n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### ResNet3D Model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:15.087579Z",
     "start_time": "2024-09-24T16:30:15.061439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResNet3D_MIL(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        img_channels: int,\n",
    "        num_layers: int,\n",
    "        block: Type[BasicBlock3D],\n",
    "        num_classes: int = 1,\n",
    "        dropout_rate: float = 0.25,\n",
    "        num_introducing_points = 100\n",
    "    ) -> None:\n",
    "        super(ResNet3D_MIL, self).__init__()\n",
    "        \n",
    "        if num_layers == 18:\n",
    "            layers = [2, 2, 2, 2]\n",
    "            self.expansion = 1\n",
    "        elif num_layers == 34:\n",
    "            layers = [3, 4, 6, 3]\n",
    "            self.expansion = 1\n",
    "        elif num_layers == 50:\n",
    "            layers = [3, 4, 6, 3]\n",
    "            self.expansion = 4\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported number of layers\")\n",
    "        \n",
    "        self.in_channels = 16\n",
    "        self.conv1 = nn.Conv3d(\n",
    "            in_channels=img_channels,\n",
    "            out_channels=self.in_channels,\n",
    "            kernel_size=7, \n",
    "            stride=(1, 2, 2),\n",
    "            padding=3,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm3d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 32, layers[0], stride=1, dropout_rate=dropout_rate)\n",
    "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2, dropout_rate=dropout_rate)\n",
    "        self.layer3 = self._make_layer(block, 32, layers[2], stride=2, dropout_rate=dropout_rate)\n",
    "        self.layer4 = self._make_layer(block, 32, layers[3], stride=2, dropout_rate=dropout_rate)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(32*self.expansion, num_classes)\n",
    "        \n",
    "        self.attention_layer = GatedAttentionLayer(32*self.expansion)\n",
    "        \n",
    "        # Inducing points for Sparse Gaussian Process (example size; adjust as needed)\n",
    "        inducing_points_size = num_introducing_points\n",
    "        inducing_points_tensor = torch.randn(inducing_points_size , 32).to(device)\n",
    "        # Initialize Sparse Gaussian Process model with inducing points \n",
    "        self.sparse_gp_model = SparseGPlayer(inducing_points_tensor).to(device)\n",
    "\n",
    "    def _make_layer(\n",
    "        self, \n",
    "        block: Type[BasicBlock3D],\n",
    "        out_channels: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1,\n",
    "        dropout_rate: float = 0.25\n",
    "    ) -> nn.Sequential:\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * self.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(\n",
    "                    self.in_channels, \n",
    "                    out_channels * self.expansion,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False \n",
    "                ),\n",
    "                nn.BatchNorm3d(out_channels * self.expansion),\n",
    "            )\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.in_channels, out_channels, stride, self.expansion, downsample, dropout_rate\n",
    "            )\n",
    "        )\n",
    "        self.in_channels = out_channels * self.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(\n",
    "                self.in_channels,\n",
    "                out_channels,\n",
    "                expansion=self.expansion,\n",
    "                dropout_rate=dropout_rate\n",
    "            ))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x shape: (batch_size, num_instances, channels, height, width)\n",
    "        batch_size, num_instances, d, h, w, c = x.size()\n",
    "        # print(f'x shape: {x.size()}')\n",
    "        \n",
    "        # Reshape to (batch_size * num_instances, channels, height, width)\n",
    "        out = x.view(batch_size * num_instances, c, d, h, w)\n",
    "        # print(f'x shape after view: {out.size()}')\n",
    "        \n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        # print(f'out shape after avgpool: {out.size()}')\n",
    "        \n",
    "        # Reshape back to (batch_size, num_instances, features)\n",
    "        out = out.view(batch_size, num_instances, -1)\n",
    "        # print(f'out shape after view: {out.size()}')\n",
    "        \n",
    "        # Apply attention layer\n",
    "        # out, attention_weights = self.attention_layer(out)\n",
    "        \n",
    "        out = torch.max(out, dim=1)[0]  # Take max across instances\n",
    "        \n",
    "        # # Prepare input for Sparse GP model (requires reshaping) \n",
    "        # gp_input=torch.randn(batch_size, num_instances , 32).to(device)  \n",
    "        # \n",
    "        # # Print shape of GP input\n",
    "        # print(f'GP input shape: {gp_input.size()}')\n",
    "        # \n",
    "        # gp_output=self.sparse_gp_model(gp_input)\n",
    "        # \n",
    "        # # Use GP output mean (or any other desired statistic) as additional features \n",
    "        # gp_mean_features=gp_output.mean\n",
    "        # \n",
    "        # # Print shape of out and GP mean features\n",
    "        # print(f'out shape: {out.size()}')\n",
    "        # print(f'GP mean features shape: {gp_mean_features.size()}')\n",
    "        # # Print shape gp unsqueezed\n",
    "        # print(f'GP mean features unsqueezed shape: {gp_mean_features.unsqueeze(0).size()}')\n",
    "        # \n",
    "        # # Concatenate GP features with attention output \n",
    "        # combined_out=torch.cat((out , gp_mean_features), dim=-1)\n",
    "        # \n",
    "        # # Apply final fully connected layer\n",
    "        # out = self.fc(combined_out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet3D18_MIL(img_channels: int = 3, num_classes: int = 1):\n",
    "    return ResNet3D_MIL(img_channels, 18, BasicBlock3D, num_classes)\n",
    "\n",
    "def ResNet3D34_MIL(img_channels: int = 3, num_classes: int = 1):\n",
    "    return ResNet3D_MIL(img_channels, 34, BasicBlock3D, num_classes)\n",
    "\n",
    "def ResNet3D50_MIL(img_channels: int = 3, num_classes: int = 1):\n",
    "    return ResNet3D_MIL(img_channels, 50, BasicBlock3D, num_classes)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training and Evaluation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training"
  },
  {
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS, learning_rate=LEARNING_RATE, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=len(train_loader), epochs=num_epochs)\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_predictions = []\n",
    "        train_labels = []\n",
    "\n",
    "        for batch_data, batch_labels in train_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # outputs, attentions = model(batch_data)\n",
    "            outputs = model(batch_data)\n",
    "            outputs = outputs.squeeze()\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_predictions.extend((outputs > 0).cpu().numpy())\n",
    "            train_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "        train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "        train_precision = precision_score(train_labels, train_predictions)\n",
    "        train_recall = recall_score(train_labels, train_predictions)\n",
    "        train_f1 = f1_score(train_labels, train_predictions)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_data, batch_labels in val_loader:\n",
    "                batch_data = batch_data.to(device)\n",
    "                batch_labels = batch_labels.float().to(device)\n",
    "\n",
    "                # outputs, attentions = model(batch_data)\n",
    "                outputs = model(batch_data)\n",
    "                outputs = outputs.squeeze()\n",
    "                \n",
    "                loss = criterion(outputs, batch_labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_predictions.extend((outputs > 0).cpu().numpy())\n",
    "                val_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "        val_precision = precision_score(val_labels, val_predictions)\n",
    "        val_recall = recall_score(val_labels, val_predictions)\n",
    "        val_f1 = f1_score(val_labels, val_predictions)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model)\n",
    "    return model"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:35.376948Z",
     "iopub.execute_input": "2024-09-21T17:49:35.377526Z",
     "iopub.status.idle": "2024-09-21T17:49:35.433092Z",
     "shell.execute_reply.started": "2024-09-21T17:49:35.377484Z",
     "shell.execute_reply": "2024-09-21T17:49:35.431823Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:15.148423Z",
     "start_time": "2024-09-24T16:30:15.117536Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation"
  },
  {
   "cell_type": "code",
   "source": [
    "def test_model(model, test_loader, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    test_predictions = []\n",
    "    test_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in test_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.float().to(device)\n",
    "\n",
    "            # outputs, attentions = model(batch_data)\n",
    "            outputs = model(batch_data)\n",
    "            outputs = outputs.squeeze()\n",
    "            \n",
    "            test_predictions.extend((outputs > 0).cpu().numpy())\n",
    "            test_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "    test_precision = precision_score(test_labels, test_predictions)\n",
    "    test_recall = recall_score(test_labels, test_predictions)\n",
    "    test_f1 = f1_score(test_labels, test_predictions)\n",
    "\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")\n",
    "\n",
    "    return test_accuracy, test_precision, test_recall, test_f1"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:35.434552Z",
     "iopub.execute_input": "2024-09-21T17:49:35.434931Z",
     "iopub.status.idle": "2024-09-21T17:49:35.479170Z",
     "shell.execute_reply.started": "2024-09-21T17:49:35.434875Z",
     "shell.execute_reply": "2024-09-21T17:49:35.477974Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:15.188151Z",
     "start_time": "2024-09-24T16:30:15.167217Z"
    }
   },
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ROC Curve and Confusion Matrix"
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_roc_curve(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in data_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            # outputs, attentions = model(batch_data)\n",
    "            outputs = model(batch_data)\n",
    "            outputs = outputs.squeeze()\n",
    "            \n",
    "            all_scores.extend(outputs.cpu().numpy())\n",
    "            all_labels.extend(batch_labels.numpy())\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:35.480257Z",
     "iopub.execute_input": "2024-09-21T17:49:35.480810Z",
     "iopub.status.idle": "2024-09-21T17:49:35.521559Z",
     "shell.execute_reply.started": "2024-09-21T17:49:35.480778Z",
     "shell.execute_reply": "2024-09-21T17:49:35.520725Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:15.233362Z",
     "start_time": "2024-09-24T16:30:15.215572Z"
    }
   },
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Confusion Matrix"
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_confusion_matrix(model, test_loader, device):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in test_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # outputs, attentions = model(batch_data)\n",
    "            outputs = model(batch_data)\n",
    "            outputs = outputs.squeeze()\n",
    "            \n",
    "            predictions = (outputs > 0).cpu().numpy()\n",
    "\n",
    "            y_true.extend(batch_labels.cpu().numpy())\n",
    "            y_pred.extend(predictions)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T17:49:35.522757Z",
     "iopub.execute_input": "2024-09-21T17:49:35.523059Z",
     "iopub.status.idle": "2024-09-21T17:49:35.563098Z",
     "shell.execute_reply.started": "2024-09-21T17:49:35.523028Z",
     "shell.execute_reply": "2024-09-21T17:49:35.562105Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:30:15.284809Z",
     "start_time": "2024-09-24T16:30:15.267028Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Main"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing"
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the model and test it on test loader and print the results of classification to a csv \n",
    "model = ResNet3D18_MIL()\n",
    "model.load_state_dict(torch.load('trained_model.pth', weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "train_labels, val_labels, test_labels = split_dataset(patient_scan_labels, test_size=TEST_SIZE)\n",
    "test_loader = get_test_loader(dicom_dir, test_labels, batch_size=TEST_BATCH_SIZE)\n",
    "\n",
    "test_model(model, test_loader)\n",
    "\n",
    "# Save the results to a CSV file including patient_id and study_instance_uid from test_labels\n",
    "results = []\n",
    "counter = 0  # Initialize a counter to track the index of test_labels\n",
    "with torch.no_grad():\n",
    "    for batch_data, batch_labels in test_loader:\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.float().to(device)\n",
    "\n",
    "        # Model predictions\n",
    "        outputs = model(batch_data).squeeze()\n",
    "        predictions = (outputs > 0).cpu().numpy()\n",
    "\n",
    "        # Append results with patient_id and study_instance_uid from test_labels\n",
    "        for i in range(len(predictions)):\n",
    "            patient_id = test_labels.iloc[counter]['patient_id']\n",
    "            study_instance_uid = test_labels.iloc[counter]['study_instance_uid']\n",
    "            true_label = batch_labels[i].cpu().numpy()\n",
    "\n",
    "            results.append({\n",
    "                'patient_id': patient_id,\n",
    "                'study_instance_uid': study_instance_uid,\n",
    "                'prediction': predictions[i],\n",
    "                'label': true_label\n",
    "            })\n",
    "            counter += 1  # Increment counter for each instance\n",
    "\n",
    "# Convert results to DataFrame and save as CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('results.csv', index=False)\n",
    "print(results_df.head())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T18:01:11.343297Z",
     "iopub.execute_input": "2024-09-21T18:01:11.344141Z",
     "iopub.status.idle": "2024-09-21T18:02:50.797272Z",
     "shell.execute_reply.started": "2024-09-21T18:01:11.344083Z",
     "shell.execute_reply": "2024-09-21T18:02:50.796189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Show Attention Weights and Images for a Single Patient"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to test a single patient\n",
    "def test_single_patient(model, patient_data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in patient_data:\n",
    "            batch_data = batch_data.to(device)  # Move data to device\n",
    "            outputs, gated_attention = model(batch_data)  # Get outputs and attention weights\n",
    "            outputs = outputs.squeeze()  # Remove extra dimension\n",
    "            \n",
    "            predictions = (outputs > 0).cpu().numpy()\n",
    "            \n",
    "            print(\"Predictions:\", predictions)\n",
    "            print(\"Labels: \", batch_labels.cpu().numpy())\n",
    "            # Print attention weights\n",
    "            attention_weights_np = gated_attention.cpu().numpy()  # Move to CPU for easier handling\n",
    "            print(\"Attention Weights for Slides:\")\n",
    "            \n",
    "            for i in range(attention_weights_np.shape[1]):  # Iterate over instances/slides\n",
    "                print(f'Slide {i+1}: Attention Weight: {attention_weights_np[0][i][0]}')  # Print weight for each slide\n",
    "                \n",
    "            # Plot the images\n",
    "            plot_images(batch_data[0].cpu(), batch_labels[0].cpu())\n",
    "            \n",
    "            break  # Only test one patient"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_images(images, labels):\n",
    "    print(images.shape)\n",
    "    batch_size, num_images_per_batch, height, width, channels = images.shape\n",
    "    images = images.view(batch_size * num_images_per_batch, height, width, channels)\n",
    "    \n",
    "    print(f'Images shape: {images.shape}')\n",
    "    num_images = images.size(0) \n",
    "    images = images.numpy()\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(8, 8, i + 1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.title(f'Image {i + 1}')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "    \n",
    "# Call the function with the test_loader\n",
    "test_loader = get_test_loader(dicom_dir, test_labels, batch_size=2)\n",
    "test_single_patient(model, test_loader)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-21T18:02:50.799081Z",
     "iopub.execute_input": "2024-09-21T18:02:50.799908Z",
     "iopub.status.idle": "2024-09-21T18:03:00.508242Z",
     "shell.execute_reply.started": "2024-09-21T18:02:50.799851Z",
     "shell.execute_reply": "2024-09-21T18:03:00.507293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
