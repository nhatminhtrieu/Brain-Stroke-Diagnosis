{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef01d3ac65fe2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96727873606160ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f080305895332",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f75acbe7fa20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cq500.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72266ba3054e72",
   "metadata": {},
   "source": [
    "# Details Information of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba45799f91f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dicom file and get the information based on name and Source Folder columns\n",
    "def get_dicom_info(row):\n",
    "    try:\n",
    "        src_dir = './archive/' + row['name'] + '/Unknown Study/' + row['Source Folder']\n",
    "        src_files = os.listdir(src_dir)\n",
    "        src_files = [f for f in src_files if f.endswith('.dcm')]\n",
    "        dicom_info = []\n",
    "        for f in src_files:\n",
    "            dicom = pydicom.dcmread(os.path.join(src_dir, f))\n",
    "            dicom_info.append(dicom)\n",
    "        # Arrange the dicom files based on last dimension of ImagePositionPatient, which is the z-axis\n",
    "        # Arrange the src_files based on the z-axis\n",
    "        img_pos = [float(x.ImagePositionPatient[2]) for x in dicom_info]\n",
    "        src_files = [x for _, x in sorted(zip(img_pos, src_files))]\n",
    "        dicom_info = [x for _, x in sorted(zip(img_pos, dicom_info))]\n",
    "        return src_files, [str(x.ImagePositionPatient) for x in dicom_info]\n",
    "\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Get the information of dicom files of first row\n",
    "src_file, img_pos = get_dicom_info(df.iloc[0])\n",
    "print(src_file, img_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1b29fdf2530f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "import os\n",
    "\n",
    "def plot_dicom(row):\n",
    "    src_file, img_pos = get_dicom_info(row)\n",
    "    num_images = len(src_file)\n",
    "\n",
    "    # Calculate rows needed (8 images per row)\n",
    "    rows = num_images // 8 + (1 if num_images % 10 else 0)\n",
    "\n",
    "    # Create subplots with proper spacing\n",
    "    fig, axs = plt.subplots(rows, 8, figsize=(25, 3 * rows))\n",
    "\n",
    "    # Flatten axes array for easy iteration\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i, f in enumerate(src_file):\n",
    "        # Read DICOM file\n",
    "        dicom_path = os.path.join('./archive', row['name'], 'Unknown Study', row['Source Folder'], f)\n",
    "        dicom = pydicom.dcmread(dicom_path)\n",
    "\n",
    "        # Process and plot image\n",
    "        axs[i].imshow(dicom.pixel_array, cmap='bone')\n",
    "        axs[i].set_title(f.split('.')[0], fontsize=8)  # Show filename without extension\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    # Hide empty subplots\n",
    "    for j in range(num_images, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_dicom(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52af6e61c74130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add src_files and img_pos columns to the dataframe\n",
    "# df[['filename', 'img_pos']] = df.apply(get_dicom_info, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942947ce0edf8331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cq500.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e26681d921f56",
   "metadata": {},
   "source": [
    "# Remove Redundant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d70cb0716ee1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def remove_redundant_slices(row):\n",
    "    src_files = row['filename']\n",
    "    img_pos_str = row['img_pos']\n",
    "\n",
    "    src_files = ast.literal_eval(src_files)\n",
    "    \n",
    "    # Parse image positions from string to list of coordinate lists\n",
    "    try:\n",
    "        pos_list = ast.literal_eval(img_pos_str)  # Convert string to list of \"[x,y,z]\" strings\n",
    "        z_coords = []\n",
    "        parsed_positions = []\n",
    "        \n",
    "        # Extract and validate positions\n",
    "        for pos_str in pos_list:\n",
    "            # Remove brackets and parse coordinates\n",
    "            coords = [float(c.strip()) for c in pos_str.strip('[]').split(',')]\n",
    "            if len(coords) != 3:\n",
    "                raise ValueError(f\"Invalid position format: {pos_str}\")\n",
    "            parsed_positions.append(coords)\n",
    "            z_coords.append(coords[2])\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        print(f\"Error parsing positions: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "    # Pair files with positions and sort by z-axis\n",
    "    paired_data = sorted(zip(src_files, parsed_positions, z_coords), \n",
    "                       key=lambda x: x[2])\n",
    "    src_files = [x[0] for x in paired_data]\n",
    "    z_coords = [x[2] for x in paired_data]\n",
    "    parsed_positions = [x[1] for x in paired_data]\n",
    "\n",
    "    # Handle different cases\n",
    "    num_slices = len(src_files)\n",
    "    \n",
    "    if num_slices < 10:\n",
    "        print(f\"Removing row with {num_slices} slices\")\n",
    "        return None, None\n",
    "        \n",
    "    if num_slices == 32:\n",
    "        return src_files, [str(p) for p in parsed_positions]\n",
    "\n",
    "    if num_slices > 32:\n",
    "        # Convert to numpy arrays for efficient calculations\n",
    "        z = np.array(z_coords)\n",
    "        \n",
    "        # Calculate optimal number of slices to keep (maximum 32)\n",
    "        keep_indices = [0]\n",
    "        last_z = z[0]\n",
    "        \n",
    "        for i in range(1, len(z)):\n",
    "            if (z[i] - last_z) >= 5:\n",
    "                keep_indices.append(i)\n",
    "                last_z = z[i]\n",
    "            if len(keep_indices) == 32:\n",
    "                break\n",
    "                \n",
    "        # If we didn't find enough 5mm spaced slices, take first 32\n",
    "        if len(keep_indices) < 32:\n",
    "            keep_indices = np.linspace(0, len(z)-1, 32, dtype=int).tolist()\n",
    "            \n",
    "        filtered_files = [src_files[i] for i in keep_indices]\n",
    "        filtered_pos = [str(parsed_positions[i]) for i in keep_indices]\n",
    "        \n",
    "        return filtered_files[:32], filtered_pos[:32]\n",
    "\n",
    "    return src_files, [str(p) for p in parsed_positions]\n",
    "\n",
    "# Remove redundant slices\n",
    "df[['filename', 'img_pos']] = df.apply(remove_redundant_slices, axis=1, result_type='expand')\n",
    "df.to_csv('cq500_redundancy.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
